{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEAR  Rk           Player   Tm FantPos  Age   G  GS  QBCmp  QBAtt  ...  \\\n",
      "0   2024   1   Saquon Barkley  PHI      RB   27  16  16      0      0  ...   \n",
      "1   2024   2    Derrick Henry  BAL      RB   30  17  17      0      0  ...   \n",
      "2   2024   3     Jahmyr Gibbs  DET      RB   22  17   4      0      0  ...   \n",
      "5   2024   6   Bijan Robinson  ATL      RB   22  17  17      0      0  ...   \n",
      "6   2024   7      Josh Jacobs  GNB      RB   26  17  17      0      0  ...   \n",
      "9   2024  10   Kyren Williams  LAR      RB   24  16  16      0      0  ...   \n",
      "10  2024  11       James Cook  BUF      RB   25  16  16      0      0  ...   \n",
      "13  2024  14  Jonathan Taylor  IND      RB   25  14  13      0      0  ...   \n",
      "16  2024  17    De'Von Achane  MIA      RB   23  17  16      0      0  ...   \n",
      "20  2024  21     James Conner  ARI      RB   29  16  16      0      0  ...   \n",
      "\n",
      "    RecYds    Y/R  RecTD  Fmb  FL  TotTD  14:00:00  2PP    PPR      PPR/G  \n",
      "0      278   8.42      2    2   1     15       3.0  0.0  355.3  22.206250  \n",
      "1      193  10.16      2    3   1     18       0.0  0.0  336.4  19.788235  \n",
      "2      517   9.94      4    1   1     20       0.0  0.0  362.9  21.347059  \n",
      "5      431   7.07      1    1   0     15       1.0  0.0  341.7  20.100000  \n",
      "6      342   9.50      1    4   3     16       0.0  0.0  293.1  17.241176  \n",
      "9      182   5.35      2    5   3     16       0.0  0.0  272.1  17.006250  \n",
      "10     258   8.06      2    1   0     18       0.0  0.0  266.7  16.668750  \n",
      "13     136   7.56      1    4   1     12       0.0  0.0  244.7  17.478571  \n",
      "16     592   7.59      6    1   0     12       0.0  0.0  299.9  17.641176  \n",
      "20     414   8.81      1    4   1      9       2.0  0.0  253.8  15.862500  \n",
      "\n",
      "[10 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "pro_football_focus_data = 'data/pro_football_ref.xlsx'\n",
    "model_path = 'model_path/trained_model.pth'\n",
    "\n",
    "# Load and preprocess the pro football focus data.\n",
    "df = pd.read_excel(pro_football_focus_data)\n",
    "# Filter to only include wide receivers (WR)\n",
    "df = df[df['FantPos'] == 'RB'].copy()\n",
    "df.replace([float('inf'), -float('inf')], 0, inplace=True)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Calculate points per game.\n",
    "df.loc[:, 'PPR/G'] = df['PPR'] / df['G']\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEAR  Rk   Tm FantPos  Age   G  GS  QBCmp  QBAtt  QBYds  ...  RecYds  \\\n",
      "0   2024   1  PHI      RB   27  16  16      0      0      0  ...     278   \n",
      "1   2024   2  BAL      RB   30  17  17      0      0      0  ...     193   \n",
      "2   2024   3  DET      RB   22  17   4      0      0      0  ...     517   \n",
      "5   2024   6  ATL      RB   22  17  17      0      0      0  ...     431   \n",
      "6   2024   7  GNB      RB   26  17  17      0      0      0  ...     342   \n",
      "9   2024  10  LAR      RB   24  16  16      0      0      0  ...     182   \n",
      "10  2024  11  BUF      RB   25  16  16      0      0      0  ...     258   \n",
      "13  2024  14  IND      RB   25  14  13      0      0      0  ...     136   \n",
      "16  2024  17  MIA      RB   23  17  16      0      0      0  ...     592   \n",
      "20  2024  21  ARI      RB   29  16  16      0      0      0  ...     414   \n",
      "\n",
      "      Y/R  RecTD  Fmb  FL  TotTD  14:00:00  2PP    PPR      PPR/G  \n",
      "0    8.42      2    2   1     15       3.0  0.0  355.3  22.206250  \n",
      "1   10.16      2    3   1     18       0.0  0.0  336.4  19.788235  \n",
      "2    9.94      4    1   1     20       0.0  0.0  362.9  21.347059  \n",
      "5    7.07      1    1   0     15       1.0  0.0  341.7  20.100000  \n",
      "6    9.50      1    4   3     16       0.0  0.0  293.1  17.241176  \n",
      "9    5.35      2    5   3     16       0.0  0.0  272.1  17.006250  \n",
      "10   8.06      2    1   0     18       0.0  0.0  266.7  16.668750  \n",
      "13   7.56      1    4   1     12       0.0  0.0  244.7  17.478571  \n",
      "16   7.59      6    1   0     12       0.0  0.0  299.9  17.641176  \n",
      "20   8.81      1    4   1      9       2.0  0.0  253.8  15.862500  \n",
      "\n",
      "[10 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Copy the 2024 data into separate dataframe.\n",
    "df_2024 = df[df['YEAR'] == 2024].copy()\n",
    "player_names_2024 = df_2024['Player'].reset_index(drop=True)\n",
    "df_2024 = df_2024.drop(columns=['Player'])\n",
    "\n",
    "print(df_2024.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13200\n"
     ]
    }
   ],
   "source": [
    "# Shift to represent the following year's points per game\n",
    "df['NextYearPPR/G'] = df.groupby('Player')['PPR/G'].shift(-1)\n",
    "\n",
    "# Remove rows where the target is NaN (i.e., no following year data)\n",
    "df = df[df['NextYearPPR/G'].notna()]\n",
    "\n",
    "print(df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age  Tgt  Rec  RecTD  RecYds  RushTD  RushYds      PPR/G\n",
      "999    24   46   39      0     337       2      719  10.840000\n",
      "997    24   63   49      4     234       3      612  10.211765\n",
      "10     25   38   32      2     258      16     1009  16.668750\n",
      "1509   30   29   26      5     247      10     1018  16.166667\n",
      "1702   22  124  107      6     867       7     1098  24.093750\n",
      "...   ...  ...  ...    ...     ...     ...      ...        ...\n",
      "493    26   41   27      0     154       1      432   5.475000\n",
      "1296   24   76   63      4     482       3      380  12.075000\n",
      "1639   24  104   79      3     456       0      213  10.243750\n",
      "2081   28   18    9      0      84       3      406   6.909091\n",
      "469    28   56   50      0     455       1      238   7.135294\n",
      "\n",
      "[264 rows x 8 columns]\n",
      "999      7.550000\n",
      "997     16.420000\n",
      "10      13.688235\n",
      "1509    11.875000\n",
      "1702    14.287500\n",
      "          ...    \n",
      "493     12.747059\n",
      "1296     7.368750\n",
      "1639    14.618750\n",
      "2081    10.687500\n",
      "469      8.881250\n",
      "Name: NextYearPPR/G, Length: 264, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define features and target.\n",
    "feature_names = ['Age', 'Tgt', 'Rec', 'RecTD', 'RecYds', 'RushTD', 'RushYds', 'PPR/G']\n",
    "target = 'NextYearPPR/G'\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X = df[feature_names]\n",
    "y = df[target]\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "print(f'{X_train}')\n",
    "print(f'{y_train}')\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "X_2024 = df_2024[feature_names]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_2024 = scaler.transform(X_2024)\n",
    "\n",
    "# Ensure X_train, X_val, X_test, and X_2024 are correctly shaped for LSTM\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_val = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "X_2024 = X_2024.reshape(X_2024.shape[0], 1, X_2024.shape[1])\n",
    "\n",
    "# Check to see standardized data.\n",
    "#print(f'Size {y_train.size}')\n",
    "#print(f'Size {X_val.size}')\n",
    "#print(f'Size {y_val.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnclass.simple_nn import SimpleLSTM\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# Create SimpleLTSM.\n",
    "input_size = X_train.shape[2]\n",
    "hidden_size = 32\n",
    "output_size = 1\n",
    "lstm = SimpleLSTM(input_size, hidden_size, output_size)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/350], Loss: 100.5155\n",
      "Count: 9\n",
      "Epoch [2/350], Loss: 150.1387\n",
      "Count: 18\n",
      "Epoch [3/350], Loss: 178.5220\n",
      "Count: 27\n",
      "Epoch [4/350], Loss: 141.5231\n",
      "Count: 36\n",
      "Epoch [5/350], Loss: 134.2557\n",
      "Count: 45\n",
      "Epoch [6/350], Loss: 182.0955\n",
      "Count: 54\n",
      "Epoch [7/350], Loss: 118.5887\n",
      "Count: 63\n",
      "Epoch [8/350], Loss: 130.1607\n",
      "Count: 72\n",
      "Epoch [9/350], Loss: 106.9088\n",
      "Count: 81\n",
      "Epoch [10/350], Loss: 121.9189\n",
      "Count: 90\n",
      "Epoch [11/350], Loss: 120.4822\n",
      "Count: 99\n",
      "Epoch [12/350], Loss: 128.7321\n",
      "Count: 108\n",
      "Epoch [13/350], Loss: 107.3495\n",
      "Count: 117\n",
      "Epoch [14/350], Loss: 94.3045\n",
      "Count: 126\n",
      "Epoch [15/350], Loss: 95.6247\n",
      "Count: 135\n",
      "Epoch [16/350], Loss: 191.7386\n",
      "Count: 144\n",
      "Epoch [17/350], Loss: 44.8503\n",
      "Count: 153\n",
      "Epoch [18/350], Loss: 95.9307\n",
      "Count: 162\n",
      "Epoch [19/350], Loss: 109.0004\n",
      "Count: 171\n",
      "Epoch [20/350], Loss: 115.1640\n",
      "Count: 180\n",
      "Epoch [21/350], Loss: 105.1117\n",
      "Count: 189\n",
      "Epoch [22/350], Loss: 102.4305\n",
      "Count: 198\n",
      "Epoch [23/350], Loss: 33.2707\n",
      "Count: 207\n",
      "Epoch [24/350], Loss: 117.7615\n",
      "Count: 216\n",
      "Epoch [25/350], Loss: 94.9311\n",
      "Count: 225\n",
      "Epoch [26/350], Loss: 65.1731\n",
      "Count: 234\n",
      "Epoch [27/350], Loss: 109.6742\n",
      "Count: 243\n",
      "Epoch [28/350], Loss: 69.6625\n",
      "Count: 252\n",
      "Epoch [29/350], Loss: 62.3085\n",
      "Count: 261\n",
      "Epoch [30/350], Loss: 54.9121\n",
      "Count: 270\n",
      "Epoch [31/350], Loss: 111.0525\n",
      "Count: 279\n",
      "Epoch [32/350], Loss: 123.3691\n",
      "Count: 288\n",
      "Epoch [33/350], Loss: 47.6822\n",
      "Count: 297\n",
      "Epoch [34/350], Loss: 103.0564\n",
      "Count: 306\n",
      "Epoch [35/350], Loss: 84.2192\n",
      "Count: 315\n",
      "Epoch [36/350], Loss: 23.5151\n",
      "Count: 324\n",
      "Epoch [37/350], Loss: 69.0536\n",
      "Count: 333\n",
      "Epoch [38/350], Loss: 62.5625\n",
      "Count: 342\n",
      "Epoch [39/350], Loss: 42.9052\n",
      "Count: 351\n",
      "Epoch [40/350], Loss: 63.1455\n",
      "Count: 360\n",
      "Epoch [41/350], Loss: 29.6655\n",
      "Count: 369\n",
      "Epoch [42/350], Loss: 29.2921\n",
      "Count: 378\n",
      "Epoch [43/350], Loss: 33.4984\n",
      "Count: 387\n",
      "Epoch [44/350], Loss: 29.2134\n",
      "Count: 396\n",
      "Epoch [45/350], Loss: 49.0438\n",
      "Count: 405\n",
      "Epoch [46/350], Loss: 30.7828\n",
      "Count: 414\n",
      "Epoch [47/350], Loss: 50.7521\n",
      "Count: 423\n",
      "Epoch [48/350], Loss: 19.7725\n",
      "Count: 432\n",
      "Epoch [49/350], Loss: 23.3701\n",
      "Count: 441\n",
      "Epoch [50/350], Loss: 29.4802\n",
      "Count: 450\n",
      "Epoch [51/350], Loss: 26.3358\n",
      "Count: 459\n",
      "Epoch [52/350], Loss: 7.3112\n",
      "Count: 468\n",
      "Epoch [53/350], Loss: 25.6204\n",
      "Count: 477\n",
      "Epoch [54/350], Loss: 42.4214\n",
      "Count: 486\n",
      "Epoch [55/350], Loss: 50.0466\n",
      "Count: 495\n",
      "Epoch [56/350], Loss: 15.2473\n",
      "Count: 504\n",
      "Epoch [57/350], Loss: 31.8765\n",
      "Count: 513\n",
      "Epoch [58/350], Loss: 9.7266\n",
      "Count: 522\n",
      "Epoch [59/350], Loss: 14.4452\n",
      "Count: 531\n",
      "Epoch [60/350], Loss: 12.6320\n",
      "Count: 540\n",
      "Epoch [61/350], Loss: 21.7810\n",
      "Count: 549\n",
      "Epoch [62/350], Loss: 28.2016\n",
      "Count: 558\n",
      "Epoch [63/350], Loss: 17.2776\n",
      "Count: 567\n",
      "Epoch [64/350], Loss: 10.3409\n",
      "Count: 576\n",
      "Epoch [65/350], Loss: 15.9034\n",
      "Count: 585\n",
      "Epoch [66/350], Loss: 22.9758\n",
      "Count: 594\n",
      "Epoch [67/350], Loss: 22.1953\n",
      "Count: 603\n",
      "Epoch [68/350], Loss: 9.4023\n",
      "Count: 612\n",
      "Epoch [69/350], Loss: 10.0816\n",
      "Count: 621\n",
      "Epoch [70/350], Loss: 13.3587\n",
      "Count: 630\n",
      "Epoch [71/350], Loss: 18.2464\n",
      "Count: 639\n",
      "Epoch [72/350], Loss: 12.7315\n",
      "Count: 648\n",
      "Epoch [73/350], Loss: 12.4508\n",
      "Count: 657\n",
      "Epoch [74/350], Loss: 21.6060\n",
      "Count: 666\n",
      "Epoch [75/350], Loss: 12.5870\n",
      "Count: 675\n",
      "Epoch [76/350], Loss: 16.3834\n",
      "Count: 684\n",
      "Epoch [77/350], Loss: 8.1791\n",
      "Count: 693\n",
      "Epoch [78/350], Loss: 5.4109\n",
      "Count: 702\n",
      "Epoch [79/350], Loss: 11.7281\n",
      "Count: 711\n",
      "Epoch [80/350], Loss: 19.5718\n",
      "Count: 720\n",
      "Epoch [81/350], Loss: 11.9604\n",
      "Count: 729\n",
      "Epoch [82/350], Loss: 21.9260\n",
      "Count: 738\n",
      "Epoch [83/350], Loss: 9.9386\n",
      "Count: 747\n",
      "Epoch [84/350], Loss: 15.9828\n",
      "Count: 756\n",
      "Epoch [85/350], Loss: 15.6266\n",
      "Count: 765\n",
      "Epoch [86/350], Loss: 17.6196\n",
      "Count: 774\n",
      "Epoch [87/350], Loss: 11.6395\n",
      "Count: 783\n",
      "Epoch [88/350], Loss: 14.1284\n",
      "Count: 792\n",
      "Epoch [89/350], Loss: 22.4561\n",
      "Count: 801\n",
      "Epoch [90/350], Loss: 7.3342\n",
      "Count: 810\n",
      "Epoch [91/350], Loss: 16.2782\n",
      "Count: 819\n",
      "Epoch [92/350], Loss: 20.0539\n",
      "Count: 828\n",
      "Epoch [93/350], Loss: 14.0767\n",
      "Count: 837\n",
      "Epoch [94/350], Loss: 7.6260\n",
      "Count: 846\n",
      "Epoch [95/350], Loss: 15.1761\n",
      "Count: 855\n",
      "Epoch [96/350], Loss: 18.1895\n",
      "Count: 864\n",
      "Epoch [97/350], Loss: 23.9804\n",
      "Count: 873\n",
      "Epoch [98/350], Loss: 22.4627\n",
      "Count: 882\n",
      "Epoch [99/350], Loss: 24.5966\n",
      "Count: 891\n",
      "Epoch [100/350], Loss: 16.2219\n",
      "Count: 900\n",
      "Epoch [101/350], Loss: 13.8455\n",
      "Count: 909\n",
      "Epoch [102/350], Loss: 13.1361\n",
      "Count: 918\n",
      "Epoch [103/350], Loss: 24.3808\n",
      "Count: 927\n",
      "Epoch [104/350], Loss: 16.9174\n",
      "Count: 936\n",
      "Epoch [105/350], Loss: 10.5538\n",
      "Count: 945\n",
      "Epoch [106/350], Loss: 10.0924\n",
      "Count: 954\n",
      "Epoch [107/350], Loss: 13.6947\n",
      "Count: 963\n",
      "Epoch [108/350], Loss: 22.9957\n",
      "Count: 972\n",
      "Epoch [109/350], Loss: 14.4222\n",
      "Count: 981\n",
      "Epoch [110/350], Loss: 5.8341\n",
      "Count: 990\n",
      "Epoch [111/350], Loss: 2.4712\n",
      "Count: 999\n",
      "Epoch [112/350], Loss: 31.8575\n",
      "Count: 1008\n",
      "Epoch [113/350], Loss: 17.5374\n",
      "Count: 1017\n",
      "Epoch [114/350], Loss: 8.9958\n",
      "Count: 1026\n",
      "Epoch [115/350], Loss: 12.6943\n",
      "Count: 1035\n",
      "Epoch [116/350], Loss: 11.7048\n",
      "Count: 1044\n",
      "Epoch [117/350], Loss: 19.9751\n",
      "Count: 1053\n",
      "Epoch [118/350], Loss: 14.9540\n",
      "Count: 1062\n",
      "Epoch [119/350], Loss: 13.7895\n",
      "Count: 1071\n",
      "Epoch [120/350], Loss: 5.4957\n",
      "Count: 1080\n",
      "Epoch [121/350], Loss: 27.2508\n",
      "Count: 1089\n",
      "Epoch [122/350], Loss: 15.7592\n",
      "Count: 1098\n",
      "Epoch [123/350], Loss: 9.5403\n",
      "Count: 1107\n",
      "Epoch [124/350], Loss: 22.6784\n",
      "Count: 1116\n",
      "Epoch [125/350], Loss: 21.4616\n",
      "Count: 1125\n",
      "Epoch [126/350], Loss: 18.9668\n",
      "Count: 1134\n",
      "Epoch [127/350], Loss: 15.3916\n",
      "Count: 1143\n",
      "Epoch [128/350], Loss: 16.8312\n",
      "Count: 1152\n",
      "Epoch [129/350], Loss: 5.4111\n",
      "Count: 1161\n",
      "Epoch [130/350], Loss: 11.7689\n",
      "Count: 1170\n",
      "Epoch [131/350], Loss: 15.8565\n",
      "Count: 1179\n",
      "Epoch [132/350], Loss: 8.6834\n",
      "Count: 1188\n",
      "Epoch [133/350], Loss: 23.4519\n",
      "Count: 1197\n",
      "Epoch [134/350], Loss: 9.6073\n",
      "Count: 1206\n",
      "Epoch [135/350], Loss: 32.6949\n",
      "Count: 1215\n",
      "Epoch [136/350], Loss: 10.9697\n",
      "Count: 1224\n",
      "Epoch [137/350], Loss: 11.3946\n",
      "Count: 1233\n",
      "Epoch [138/350], Loss: 25.1877\n",
      "Count: 1242\n",
      "Epoch [139/350], Loss: 6.9333\n",
      "Count: 1251\n",
      "Epoch [140/350], Loss: 12.6709\n",
      "Count: 1260\n",
      "Epoch [141/350], Loss: 17.2908\n",
      "Count: 1269\n",
      "Epoch [142/350], Loss: 2.5540\n",
      "Count: 1278\n",
      "Epoch [143/350], Loss: 20.5527\n",
      "Count: 1287\n",
      "Epoch [144/350], Loss: 26.8440\n",
      "Count: 1296\n",
      "Epoch [145/350], Loss: 8.9232\n",
      "Count: 1305\n",
      "Epoch [146/350], Loss: 14.0083\n",
      "Count: 1314\n",
      "Epoch [147/350], Loss: 28.9127\n",
      "Count: 1323\n",
      "Epoch [148/350], Loss: 25.4139\n",
      "Count: 1332\n",
      "Epoch [149/350], Loss: 29.2356\n",
      "Count: 1341\n",
      "Epoch [150/350], Loss: 8.0154\n",
      "Count: 1350\n",
      "Epoch [151/350], Loss: 29.6438\n",
      "Count: 1359\n",
      "Epoch [152/350], Loss: 7.4875\n",
      "Count: 1368\n",
      "Epoch [153/350], Loss: 16.5417\n",
      "Count: 1377\n",
      "Epoch [154/350], Loss: 25.9600\n",
      "Count: 1386\n",
      "Epoch [155/350], Loss: 18.0835\n",
      "Count: 1395\n",
      "Epoch [156/350], Loss: 8.6176\n",
      "Count: 1404\n",
      "Epoch [157/350], Loss: 6.1942\n",
      "Count: 1413\n",
      "Epoch [158/350], Loss: 9.5012\n",
      "Count: 1422\n",
      "Epoch [159/350], Loss: 8.3588\n",
      "Count: 1431\n",
      "Epoch [160/350], Loss: 6.8162\n",
      "Count: 1440\n",
      "Epoch [161/350], Loss: 23.8061\n",
      "Count: 1449\n",
      "Epoch [162/350], Loss: 8.8294\n",
      "Count: 1458\n",
      "Epoch [163/350], Loss: 19.0856\n",
      "Count: 1467\n",
      "Epoch [164/350], Loss: 4.2713\n",
      "Count: 1476\n",
      "Epoch [165/350], Loss: 6.6959\n",
      "Count: 1485\n",
      "Epoch [166/350], Loss: 11.3909\n",
      "Count: 1494\n",
      "Epoch [167/350], Loss: 15.1088\n",
      "Count: 1503\n",
      "Epoch [168/350], Loss: 5.2146\n",
      "Count: 1512\n",
      "Epoch [169/350], Loss: 13.5823\n",
      "Count: 1521\n",
      "Epoch [170/350], Loss: 10.4532\n",
      "Count: 1530\n",
      "Epoch [171/350], Loss: 19.2252\n",
      "Count: 1539\n",
      "Epoch [172/350], Loss: 14.4032\n",
      "Count: 1548\n",
      "Epoch [173/350], Loss: 29.9377\n",
      "Count: 1557\n",
      "Epoch [174/350], Loss: 8.8526\n",
      "Count: 1566\n",
      "Epoch [175/350], Loss: 12.4382\n",
      "Count: 1575\n",
      "Epoch [176/350], Loss: 12.6903\n",
      "Count: 1584\n",
      "Epoch [177/350], Loss: 15.6173\n",
      "Count: 1593\n",
      "Epoch [178/350], Loss: 14.3932\n",
      "Count: 1602\n",
      "Epoch [179/350], Loss: 11.6423\n",
      "Count: 1611\n",
      "Epoch [180/350], Loss: 18.1772\n",
      "Count: 1620\n",
      "Epoch [181/350], Loss: 13.1237\n",
      "Count: 1629\n",
      "Epoch [182/350], Loss: 19.0083\n",
      "Count: 1638\n",
      "Epoch [183/350], Loss: 14.1618\n",
      "Count: 1647\n",
      "Epoch [184/350], Loss: 7.1596\n",
      "Count: 1656\n",
      "Epoch [185/350], Loss: 13.4598\n",
      "Count: 1665\n",
      "Epoch [186/350], Loss: 10.0399\n",
      "Count: 1674\n",
      "Epoch [187/350], Loss: 3.8203\n",
      "Count: 1683\n",
      "Epoch [188/350], Loss: 12.5375\n",
      "Count: 1692\n",
      "Epoch [189/350], Loss: 20.6974\n",
      "Count: 1701\n",
      "Epoch [190/350], Loss: 11.6451\n",
      "Count: 1710\n",
      "Epoch [191/350], Loss: 10.6166\n",
      "Count: 1719\n",
      "Epoch [192/350], Loss: 10.9241\n",
      "Count: 1728\n",
      "Epoch [193/350], Loss: 13.0529\n",
      "Count: 1737\n",
      "Epoch [194/350], Loss: 20.0456\n",
      "Count: 1746\n",
      "Epoch [195/350], Loss: 14.2038\n",
      "Count: 1755\n",
      "Epoch [196/350], Loss: 6.7406\n",
      "Count: 1764\n",
      "Epoch [197/350], Loss: 9.8362\n",
      "Count: 1773\n",
      "Epoch [198/350], Loss: 8.8812\n",
      "Count: 1782\n",
      "Epoch [199/350], Loss: 14.9025\n",
      "Count: 1791\n",
      "Epoch [200/350], Loss: 8.1251\n",
      "Count: 1800\n",
      "Epoch [201/350], Loss: 8.8926\n",
      "Count: 1809\n",
      "Epoch [202/350], Loss: 8.1860\n",
      "Count: 1818\n",
      "Epoch [203/350], Loss: 10.2240\n",
      "Count: 1827\n",
      "Epoch [204/350], Loss: 5.0758\n",
      "Count: 1836\n",
      "Epoch [205/350], Loss: 16.2587\n",
      "Count: 1845\n",
      "Epoch [206/350], Loss: 10.2133\n",
      "Count: 1854\n",
      "Epoch [207/350], Loss: 10.1591\n",
      "Count: 1863\n",
      "Epoch [208/350], Loss: 10.3711\n",
      "Count: 1872\n",
      "Epoch [209/350], Loss: 12.3603\n",
      "Count: 1881\n",
      "Epoch [210/350], Loss: 13.5986\n",
      "Count: 1890\n",
      "Epoch [211/350], Loss: 5.0070\n",
      "Count: 1899\n",
      "Epoch [212/350], Loss: 11.6487\n",
      "Count: 1908\n",
      "Epoch [213/350], Loss: 15.9823\n",
      "Count: 1917\n",
      "Epoch [214/350], Loss: 6.2564\n",
      "Count: 1926\n",
      "Epoch [215/350], Loss: 22.5954\n",
      "Count: 1935\n",
      "Epoch [216/350], Loss: 3.2933\n",
      "Count: 1944\n",
      "Epoch [217/350], Loss: 12.5825\n",
      "Count: 1953\n",
      "Epoch [218/350], Loss: 15.8330\n",
      "Count: 1962\n",
      "Epoch [219/350], Loss: 20.7683\n",
      "Count: 1971\n",
      "Epoch [220/350], Loss: 14.9935\n",
      "Count: 1980\n",
      "Epoch [221/350], Loss: 22.8993\n",
      "Count: 1989\n",
      "Epoch [222/350], Loss: 31.2846\n",
      "Count: 1998\n",
      "Epoch [223/350], Loss: 8.1093\n",
      "Count: 2007\n",
      "Epoch [224/350], Loss: 14.3905\n",
      "Count: 2016\n",
      "Epoch [225/350], Loss: 6.1649\n",
      "Count: 2025\n",
      "Epoch [226/350], Loss: 6.4122\n",
      "Count: 2034\n",
      "Epoch [227/350], Loss: 13.8059\n",
      "Count: 2043\n",
      "Epoch [228/350], Loss: 12.5157\n",
      "Count: 2052\n",
      "Epoch [229/350], Loss: 27.5574\n",
      "Count: 2061\n",
      "Epoch [230/350], Loss: 6.3857\n",
      "Count: 2070\n",
      "Epoch [231/350], Loss: 4.8101\n",
      "Count: 2079\n",
      "Epoch [232/350], Loss: 23.9251\n",
      "Count: 2088\n",
      "Epoch [233/350], Loss: 5.5340\n",
      "Count: 2097\n",
      "Epoch [234/350], Loss: 20.8570\n",
      "Count: 2106\n",
      "Epoch [235/350], Loss: 19.6638\n",
      "Count: 2115\n",
      "Epoch [236/350], Loss: 31.4124\n",
      "Count: 2124\n",
      "Epoch [237/350], Loss: 9.0550\n",
      "Count: 2133\n",
      "Epoch [238/350], Loss: 11.5183\n",
      "Count: 2142\n",
      "Epoch [239/350], Loss: 21.9330\n",
      "Count: 2151\n",
      "Epoch [240/350], Loss: 20.1744\n",
      "Count: 2160\n",
      "Epoch [241/350], Loss: 20.4257\n",
      "Count: 2169\n",
      "Epoch [242/350], Loss: 11.3679\n",
      "Count: 2178\n",
      "Epoch [243/350], Loss: 6.4789\n",
      "Count: 2187\n",
      "Epoch [244/350], Loss: 17.2549\n",
      "Count: 2196\n",
      "Epoch [245/350], Loss: 10.5997\n",
      "Count: 2205\n",
      "Epoch [246/350], Loss: 10.8140\n",
      "Count: 2214\n",
      "Epoch [247/350], Loss: 5.8140\n",
      "Count: 2223\n",
      "Epoch [248/350], Loss: 17.0931\n",
      "Count: 2232\n",
      "Epoch [249/350], Loss: 4.5462\n",
      "Count: 2241\n",
      "Epoch [250/350], Loss: 36.3372\n",
      "Count: 2250\n",
      "Epoch [251/350], Loss: 14.4199\n",
      "Count: 2259\n",
      "Epoch [252/350], Loss: 23.4224\n",
      "Count: 2268\n",
      "Epoch [253/350], Loss: 11.8729\n",
      "Count: 2277\n",
      "Epoch [254/350], Loss: 7.4720\n",
      "Count: 2286\n",
      "Epoch [255/350], Loss: 17.6341\n",
      "Count: 2295\n",
      "Epoch [256/350], Loss: 10.6074\n",
      "Count: 2304\n",
      "Epoch [257/350], Loss: 17.8003\n",
      "Count: 2313\n",
      "Epoch [258/350], Loss: 15.0223\n",
      "Count: 2322\n",
      "Epoch [259/350], Loss: 13.9525\n",
      "Count: 2331\n",
      "Epoch [260/350], Loss: 19.8421\n",
      "Count: 2340\n",
      "Epoch [261/350], Loss: 8.6074\n",
      "Count: 2349\n",
      "Epoch [262/350], Loss: 3.6357\n",
      "Count: 2358\n",
      "Epoch [263/350], Loss: 13.4537\n",
      "Count: 2367\n",
      "Epoch [264/350], Loss: 18.0829\n",
      "Count: 2376\n",
      "Epoch [265/350], Loss: 14.4265\n",
      "Count: 2385\n",
      "Epoch [266/350], Loss: 9.8000\n",
      "Count: 2394\n",
      "Epoch [267/350], Loss: 16.1980\n",
      "Count: 2403\n",
      "Epoch [268/350], Loss: 5.2858\n",
      "Count: 2412\n",
      "Epoch [269/350], Loss: 17.4272\n",
      "Count: 2421\n",
      "Epoch [270/350], Loss: 6.3197\n",
      "Count: 2430\n",
      "Epoch [271/350], Loss: 10.3333\n",
      "Count: 2439\n",
      "Epoch [272/350], Loss: 5.4102\n",
      "Count: 2448\n",
      "Epoch [273/350], Loss: 30.0169\n",
      "Count: 2457\n",
      "Epoch [274/350], Loss: 1.8248\n",
      "Count: 2466\n",
      "Epoch [275/350], Loss: 8.7239\n",
      "Count: 2475\n",
      "Epoch [276/350], Loss: 12.2054\n",
      "Count: 2484\n",
      "Epoch [277/350], Loss: 12.0273\n",
      "Count: 2493\n",
      "Epoch [278/350], Loss: 16.1566\n",
      "Count: 2502\n",
      "Epoch [279/350], Loss: 11.7532\n",
      "Count: 2511\n",
      "Epoch [280/350], Loss: 1.3100\n",
      "Count: 2520\n",
      "Epoch [281/350], Loss: 19.4577\n",
      "Count: 2529\n",
      "Epoch [282/350], Loss: 4.4981\n",
      "Count: 2538\n",
      "Epoch [283/350], Loss: 12.6150\n",
      "Count: 2547\n",
      "Epoch [284/350], Loss: 7.9924\n",
      "Count: 2556\n",
      "Epoch [285/350], Loss: 8.9561\n",
      "Count: 2565\n",
      "Epoch [286/350], Loss: 16.2850\n",
      "Count: 2574\n",
      "Epoch [287/350], Loss: 5.3995\n",
      "Count: 2583\n",
      "Epoch [288/350], Loss: 7.4008\n",
      "Count: 2592\n",
      "Epoch [289/350], Loss: 23.0179\n",
      "Count: 2601\n",
      "Epoch [290/350], Loss: 17.4164\n",
      "Count: 2610\n",
      "Epoch [291/350], Loss: 12.7662\n",
      "Count: 2619\n",
      "Epoch [292/350], Loss: 31.2705\n",
      "Count: 2628\n",
      "Epoch [293/350], Loss: 11.1374\n",
      "Count: 2637\n",
      "Epoch [294/350], Loss: 7.2300\n",
      "Count: 2646\n",
      "Epoch [295/350], Loss: 20.9297\n",
      "Count: 2655\n",
      "Epoch [296/350], Loss: 4.7857\n",
      "Count: 2664\n",
      "Epoch [297/350], Loss: 2.7125\n",
      "Count: 2673\n",
      "Epoch [298/350], Loss: 12.9412\n",
      "Count: 2682\n",
      "Epoch [299/350], Loss: 8.4664\n",
      "Count: 2691\n",
      "Epoch [300/350], Loss: 9.7325\n",
      "Count: 2700\n",
      "Epoch [301/350], Loss: 12.8841\n",
      "Count: 2709\n",
      "Epoch [302/350], Loss: 5.0108\n",
      "Count: 2718\n",
      "Epoch [303/350], Loss: 6.7022\n",
      "Count: 2727\n",
      "Epoch [304/350], Loss: 14.7794\n",
      "Count: 2736\n",
      "Epoch [305/350], Loss: 10.2115\n",
      "Count: 2745\n",
      "Epoch [306/350], Loss: 5.9939\n",
      "Count: 2754\n",
      "Epoch [307/350], Loss: 6.7284\n",
      "Count: 2763\n",
      "Epoch [308/350], Loss: 14.1422\n",
      "Count: 2772\n",
      "Epoch [309/350], Loss: 20.1208\n",
      "Count: 2781\n",
      "Epoch [310/350], Loss: 5.5827\n",
      "Count: 2790\n",
      "Epoch [311/350], Loss: 7.5256\n",
      "Count: 2799\n",
      "Epoch [312/350], Loss: 8.3689\n",
      "Count: 2808\n",
      "Epoch [313/350], Loss: 12.3616\n",
      "Count: 2817\n",
      "Epoch [314/350], Loss: 7.6188\n",
      "Count: 2826\n",
      "Epoch [315/350], Loss: 11.1849\n",
      "Count: 2835\n",
      "Epoch [316/350], Loss: 15.6677\n",
      "Count: 2844\n",
      "Epoch [317/350], Loss: 9.5021\n",
      "Count: 2853\n",
      "Epoch [318/350], Loss: 13.3680\n",
      "Count: 2862\n",
      "Epoch [319/350], Loss: 9.4401\n",
      "Count: 2871\n",
      "Epoch [320/350], Loss: 12.7131\n",
      "Count: 2880\n",
      "Epoch [321/350], Loss: 3.1726\n",
      "Count: 2889\n",
      "Epoch [322/350], Loss: 11.2830\n",
      "Count: 2898\n",
      "Epoch [323/350], Loss: 14.2602\n",
      "Count: 2907\n",
      "Epoch [324/350], Loss: 13.6986\n",
      "Count: 2916\n",
      "Epoch [325/350], Loss: 19.5846\n",
      "Count: 2925\n",
      "Epoch [326/350], Loss: 8.2027\n",
      "Count: 2934\n",
      "Epoch [327/350], Loss: 10.9787\n",
      "Count: 2943\n",
      "Epoch [328/350], Loss: 11.0687\n",
      "Count: 2952\n",
      "Epoch [329/350], Loss: 11.4853\n",
      "Count: 2961\n",
      "Epoch [330/350], Loss: 11.9433\n",
      "Count: 2970\n",
      "Epoch [331/350], Loss: 22.5014\n",
      "Count: 2979\n",
      "Epoch [332/350], Loss: 13.8502\n",
      "Count: 2988\n",
      "Epoch [333/350], Loss: 5.3719\n",
      "Count: 2997\n",
      "Epoch [334/350], Loss: 11.9519\n",
      "Count: 3006\n",
      "Epoch [335/350], Loss: 7.1492\n",
      "Count: 3015\n",
      "Epoch [336/350], Loss: 13.5570\n",
      "Count: 3024\n",
      "Epoch [337/350], Loss: 10.2609\n",
      "Count: 3033\n",
      "Epoch [338/350], Loss: 6.8828\n",
      "Count: 3042\n",
      "Epoch [339/350], Loss: 19.8698\n",
      "Count: 3051\n",
      "Epoch [340/350], Loss: 4.7292\n",
      "Count: 3060\n",
      "Epoch [341/350], Loss: 22.2362\n",
      "Count: 3069\n",
      "Epoch [342/350], Loss: 15.8276\n",
      "Count: 3078\n",
      "Epoch [343/350], Loss: 11.7722\n",
      "Count: 3087\n",
      "Epoch [344/350], Loss: 17.4135\n",
      "Count: 3096\n",
      "Epoch [345/350], Loss: 11.7044\n",
      "Count: 3105\n",
      "Epoch [346/350], Loss: 18.2042\n",
      "Count: 3114\n",
      "Epoch [347/350], Loss: 12.1659\n",
      "Count: 3123\n",
      "Epoch [348/350], Loss: 10.1833\n",
      "Count: 3132\n",
      "Epoch [349/350], Loss: 11.8864\n",
      "Count: 3141\n",
      "Epoch [350/350], Loss: 6.7788\n",
      "Count: 3150\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Train the model.\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(lstm.parameters())\n",
    "\n",
    "num_epochs = 350\n",
    "count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    lstm.train() # Set model to training mode\n",
    "    for inputs, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = lstm(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    print(f'Count: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation, Total Loss: 40.2699\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "lstm.eval() # Set model to eval mode\n",
    "total_loss = 0\n",
    "for inputs, labels in val_loader:\n",
    "    # Forward pass\n",
    "    outputs = lstm(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    total_loss += loss\n",
    "print(f'Evaluation, Total Loss: {total_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 3.4108, MAE: 2.7154, R²: 0.5017\n",
      "Testing RMSE: 3.9281, MAE: 3.0760, R²: 0.5056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "y_train_pred = lstm(X_train_tensor).detach().numpy()\n",
    "y_test_pred = lstm(X_test_tensor).detach().numpy()\n",
    "\n",
    "# Get the diff values for evaluation.\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Training RMSE: {rmse_train:.4f}, MAE: {mae_train:.4f}, R²: {r2_train:.4f}')\n",
    "print(f'Testing RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}, R²: {r2_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Prediction                 Player\n",
      "0    17.025743         Saquon Barkley\n",
      "1    14.789425          Derrick Henry\n",
      "2    14.506031           Jahmyr Gibbs\n",
      "3    14.234646         Bijan Robinson\n",
      "4    14.734671            Josh Jacobs\n",
      "..         ...                    ...\n",
      "77    5.971714            Blake Corum\n",
      "78    8.246283         D'Onta Foreman\n",
      "79    7.096632         Patrick Taylor\n",
      "80    9.067770  Cordarrelle Patterson\n",
      "81   14.593166         Michael Carter\n",
      "\n",
      "[82 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Return results using model.\n",
    "predictions = lstm(torch.tensor(X_2024, dtype=torch.float32)).detach().numpy()\n",
    "predictions_df = pd.DataFrame(predictions, columns=['Prediction'])\n",
    "predictions_df['Player'] = player_names_2024\n",
    "print(f'{predictions_df}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new DataFrame to an Excel file\n",
    "file_path = 'results/simple_lstm_rb.xlsx'\n",
    "predictions_df.to_excel(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
