{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEAR  Rk           Player   Tm FantPos  Age   G  GS  QBCmp  QBAtt  ...  \\\n",
      "0   2024   1   Saquon Barkley  PHI      RB   27  16  16      0      0  ...   \n",
      "1   2024   2    Derrick Henry  BAL      RB   30  17  17      0      0  ...   \n",
      "2   2024   3     Jahmyr Gibbs  DET      RB   22  17   4      0      0  ...   \n",
      "5   2024   6   Bijan Robinson  ATL      RB   22  17  17      0      0  ...   \n",
      "6   2024   7      Josh Jacobs  GNB      RB   26  17  17      0      0  ...   \n",
      "9   2024  10   Kyren Williams  LAR      RB   24  16  16      0      0  ...   \n",
      "10  2024  11       James Cook  BUF      RB   25  16  16      0      0  ...   \n",
      "13  2024  14  Jonathan Taylor  IND      RB   25  14  13      0      0  ...   \n",
      "16  2024  17    De'Von Achane  MIA      RB   23  17  16      0      0  ...   \n",
      "20  2024  21     James Conner  ARI      RB   29  16  16      0      0  ...   \n",
      "\n",
      "      Y/R  RecTD  Fmb  FL  TotTD  14:00:00  2PP    PPR      PPR/G  Age^2  \n",
      "0    8.42      2    2   1     15       3.0  0.0  355.3  22.206250    729  \n",
      "1   10.16      2    3   1     18       0.0  0.0  336.4  19.788235    900  \n",
      "2    9.94      4    1   1     20       0.0  0.0  362.9  21.347059    484  \n",
      "5    7.07      1    1   0     15       1.0  0.0  341.7  20.100000    484  \n",
      "6    9.50      1    4   3     16       0.0  0.0  293.1  17.241176    676  \n",
      "9    5.35      2    5   3     16       0.0  0.0  272.1  17.006250    576  \n",
      "10   8.06      2    1   0     18       0.0  0.0  266.7  16.668750    625  \n",
      "13   7.56      1    4   1     12       0.0  0.0  244.7  17.478571    625  \n",
      "16   7.59      6    1   0     12       0.0  0.0  299.9  17.641176    529  \n",
      "20   8.81      1    4   1      9       2.0  0.0  253.8  15.862500    841  \n",
      "\n",
      "[10 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "pro_football_focus_data = 'data/pro_football_ref.xlsx'\n",
    "model_path = 'model_path/trained_model.pth'\n",
    "\n",
    "# Load and preprocess the pro football focus data.\n",
    "df = pd.read_excel(pro_football_focus_data)\n",
    "# Filter to only include wide receivers (WR)\n",
    "df = df[df['FantPos'] == 'RB'].copy()\n",
    "df.replace([float('inf'), -float('inf')], 0, inplace=True)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Feature engineering.\n",
    "df.loc[:, 'PPR/G'] = df['PPR'] / df['G']\n",
    "df.loc[:, 'Age^2'] = df['Age'] * df['Age']\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEAR  Rk   Tm FantPos  Age   G  GS  QBCmp  QBAtt  QBYds  ...    Y/R  \\\n",
      "0   2024   1  PHI      RB   27  16  16      0      0      0  ...   8.42   \n",
      "1   2024   2  BAL      RB   30  17  17      0      0      0  ...  10.16   \n",
      "2   2024   3  DET      RB   22  17   4      0      0      0  ...   9.94   \n",
      "5   2024   6  ATL      RB   22  17  17      0      0      0  ...   7.07   \n",
      "6   2024   7  GNB      RB   26  17  17      0      0      0  ...   9.50   \n",
      "9   2024  10  LAR      RB   24  16  16      0      0      0  ...   5.35   \n",
      "10  2024  11  BUF      RB   25  16  16      0      0      0  ...   8.06   \n",
      "13  2024  14  IND      RB   25  14  13      0      0      0  ...   7.56   \n",
      "16  2024  17  MIA      RB   23  17  16      0      0      0  ...   7.59   \n",
      "20  2024  21  ARI      RB   29  16  16      0      0      0  ...   8.81   \n",
      "\n",
      "    RecTD  Fmb  FL  TotTD  14:00:00  2PP    PPR      PPR/G  Age^2  \n",
      "0       2    2   1     15       3.0  0.0  355.3  22.206250    729  \n",
      "1       2    3   1     18       0.0  0.0  336.4  19.788235    900  \n",
      "2       4    1   1     20       0.0  0.0  362.9  21.347059    484  \n",
      "5       1    1   0     15       1.0  0.0  341.7  20.100000    484  \n",
      "6       1    4   3     16       0.0  0.0  293.1  17.241176    676  \n",
      "9       2    5   3     16       0.0  0.0  272.1  17.006250    576  \n",
      "10      2    1   0     18       0.0  0.0  266.7  16.668750    625  \n",
      "13      1    4   1     12       0.0  0.0  244.7  17.478571    625  \n",
      "16      6    1   0     12       0.0  0.0  299.9  17.641176    529  \n",
      "20      1    4   1      9       2.0  0.0  253.8  15.862500    841  \n",
      "\n",
      "[10 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Copy the 2024 data into separate dataframe.\n",
    "df_2024 = df[df['YEAR'] == 2024].copy()\n",
    "player_names_2024 = df_2024['Player'].reset_index(drop=True)\n",
    "df_2024 = df_2024.drop(columns=['Player'])\n",
    "\n",
    "print(df_2024.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13640\n"
     ]
    }
   ],
   "source": [
    "# Shift to represent the following year's points per game\n",
    "df['NextYearPPR/G'] = df.groupby('Player')['PPR/G'].shift(-1)\n",
    "\n",
    "# Remove rows where the target is NaN (i.e., no following year data)\n",
    "df = df[df['NextYearPPR/G'].notna()]\n",
    "\n",
    "print(df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age  Age^2  Tgt  Rec  RecYds  RushTD  RushYds   Y/A      PPR/G\n",
      "999    24    576   46   39     337       2      719  5.53  10.840000\n",
      "997    24    576   63   49     234       3      612  3.54  10.211765\n",
      "10     25    625   38   32     258      16     1009  4.87  16.668750\n",
      "1509   30    900   29   26     247      10     1018  5.04  16.166667\n",
      "1702   22    484  124  107     867       7     1098  5.01  24.093750\n",
      "...   ...    ...  ...  ...     ...     ...      ...   ...        ...\n",
      "493    26    676   41   27     154       1      432  3.35   5.475000\n",
      "1296   24    576   76   63     482       3      380  4.27  12.075000\n",
      "1639   24    576  104   79     456       0      213  3.33  10.243750\n",
      "2081   28    784   18    9      84       3      406  2.94   6.909091\n",
      "469    28    784   56   50     455       1      238  4.49   7.135294\n",
      "\n",
      "[264 rows x 9 columns]\n",
      "999      7.550000\n",
      "997     16.420000\n",
      "10      13.688235\n",
      "1509    11.875000\n",
      "1702    14.287500\n",
      "          ...    \n",
      "493     12.747059\n",
      "1296     7.368750\n",
      "1639    14.618750\n",
      "2081    10.687500\n",
      "469      8.881250\n",
      "Name: NextYearPPR/G, Length: 264, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define features and target.\n",
    "feature_names = ['Age', 'Age^2', 'Tgt', 'Rec', 'RushTD', 'RushYds', 'Y/A', 'PPR/G']\n",
    "target = 'NextYearPPR/G'\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X = df[feature_names]\n",
    "y = df[target]\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "print(f'{X_train}')\n",
    "print(f'{y_train}')\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "X_2024 = df_2024[feature_names]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_2024 = scaler.transform(X_2024)\n",
    "\n",
    "# Ensure X_train, X_val, X_test, and X_2024 are correctly shaped for LSTM\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_val = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "X_2024 = X_2024.reshape(X_2024.shape[0], 1, X_2024.shape[1])\n",
    "\n",
    "# Check to see standardized data.\n",
    "#print(f'Size {y_train.size}')\n",
    "#print(f'Size {X_val.size}')\n",
    "#print(f'Size {y_val.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnclass.simple_nn import SimpleLSTM\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# Create SimpleLTSM.\n",
    "input_size = X_train.shape[2]\n",
    "hidden_size = 32\n",
    "output_size = 1\n",
    "lstm = SimpleLSTM(input_size, hidden_size, output_size)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/350], Loss: 143.6311\n",
      "Count: 9\n",
      "Epoch [2/350], Loss: 181.3407\n",
      "Count: 18\n",
      "Epoch [3/350], Loss: 184.1401\n",
      "Count: 27\n",
      "Epoch [4/350], Loss: 104.8211\n",
      "Count: 36\n",
      "Epoch [5/350], Loss: 256.6461\n",
      "Count: 45\n",
      "Epoch [6/350], Loss: 164.8242\n",
      "Count: 54\n",
      "Epoch [7/350], Loss: 101.0406\n",
      "Count: 63\n",
      "Epoch [8/350], Loss: 176.7945\n",
      "Count: 72\n",
      "Epoch [9/350], Loss: 165.3073\n",
      "Count: 81\n",
      "Epoch [10/350], Loss: 164.1264\n",
      "Count: 90\n",
      "Epoch [11/350], Loss: 159.1503\n",
      "Count: 99\n",
      "Epoch [12/350], Loss: 95.3568\n",
      "Count: 108\n",
      "Epoch [13/350], Loss: 79.3707\n",
      "Count: 117\n",
      "Epoch [14/350], Loss: 180.8107\n",
      "Count: 126\n",
      "Epoch [15/350], Loss: 190.4681\n",
      "Count: 135\n",
      "Epoch [16/350], Loss: 182.4514\n",
      "Count: 144\n",
      "Epoch [17/350], Loss: 72.8522\n",
      "Count: 153\n",
      "Epoch [18/350], Loss: 128.1768\n",
      "Count: 162\n",
      "Epoch [19/350], Loss: 202.7614\n",
      "Count: 171\n",
      "Epoch [20/350], Loss: 81.4523\n",
      "Count: 180\n",
      "Epoch [21/350], Loss: 78.2979\n",
      "Count: 189\n",
      "Epoch [22/350], Loss: 99.4847\n",
      "Count: 198\n",
      "Epoch [23/350], Loss: 116.6010\n",
      "Count: 207\n",
      "Epoch [24/350], Loss: 106.2641\n",
      "Count: 216\n",
      "Epoch [25/350], Loss: 124.8988\n",
      "Count: 225\n",
      "Epoch [26/350], Loss: 87.4909\n",
      "Count: 234\n",
      "Epoch [27/350], Loss: 104.1743\n",
      "Count: 243\n",
      "Epoch [28/350], Loss: 91.4309\n",
      "Count: 252\n",
      "Epoch [29/350], Loss: 71.0865\n",
      "Count: 261\n",
      "Epoch [30/350], Loss: 84.5574\n",
      "Count: 270\n",
      "Epoch [31/350], Loss: 55.7643\n",
      "Count: 279\n",
      "Epoch [32/350], Loss: 107.0889\n",
      "Count: 288\n",
      "Epoch [33/350], Loss: 63.3918\n",
      "Count: 297\n",
      "Epoch [34/350], Loss: 94.9173\n",
      "Count: 306\n",
      "Epoch [35/350], Loss: 59.0118\n",
      "Count: 315\n",
      "Epoch [36/350], Loss: 31.2976\n",
      "Count: 324\n",
      "Epoch [37/350], Loss: 26.4289\n",
      "Count: 333\n",
      "Epoch [38/350], Loss: 47.0428\n",
      "Count: 342\n",
      "Epoch [39/350], Loss: 39.0386\n",
      "Count: 351\n",
      "Epoch [40/350], Loss: 25.7395\n",
      "Count: 360\n",
      "Epoch [41/350], Loss: 31.7535\n",
      "Count: 369\n",
      "Epoch [42/350], Loss: 32.0654\n",
      "Count: 378\n",
      "Epoch [43/350], Loss: 57.9714\n",
      "Count: 387\n",
      "Epoch [44/350], Loss: 44.7761\n",
      "Count: 396\n",
      "Epoch [45/350], Loss: 56.4458\n",
      "Count: 405\n",
      "Epoch [46/350], Loss: 31.3356\n",
      "Count: 414\n",
      "Epoch [47/350], Loss: 25.7533\n",
      "Count: 423\n",
      "Epoch [48/350], Loss: 41.6512\n",
      "Count: 432\n",
      "Epoch [49/350], Loss: 47.5250\n",
      "Count: 441\n",
      "Epoch [50/350], Loss: 34.3511\n",
      "Count: 450\n",
      "Epoch [51/350], Loss: 41.5825\n",
      "Count: 459\n",
      "Epoch [52/350], Loss: 29.5659\n",
      "Count: 468\n",
      "Epoch [53/350], Loss: 15.3284\n",
      "Count: 477\n",
      "Epoch [54/350], Loss: 14.6673\n",
      "Count: 486\n",
      "Epoch [55/350], Loss: 48.0827\n",
      "Count: 495\n",
      "Epoch [56/350], Loss: 38.6995\n",
      "Count: 504\n",
      "Epoch [57/350], Loss: 13.7013\n",
      "Count: 513\n",
      "Epoch [58/350], Loss: 23.7442\n",
      "Count: 522\n",
      "Epoch [59/350], Loss: 23.2328\n",
      "Count: 531\n",
      "Epoch [60/350], Loss: 8.9236\n",
      "Count: 540\n",
      "Epoch [61/350], Loss: 18.2128\n",
      "Count: 549\n",
      "Epoch [62/350], Loss: 36.9258\n",
      "Count: 558\n",
      "Epoch [63/350], Loss: 7.3640\n",
      "Count: 567\n",
      "Epoch [64/350], Loss: 27.9178\n",
      "Count: 576\n",
      "Epoch [65/350], Loss: 19.2098\n",
      "Count: 585\n",
      "Epoch [66/350], Loss: 27.0974\n",
      "Count: 594\n",
      "Epoch [67/350], Loss: 12.2854\n",
      "Count: 603\n",
      "Epoch [68/350], Loss: 25.8170\n",
      "Count: 612\n",
      "Epoch [69/350], Loss: 11.5610\n",
      "Count: 621\n",
      "Epoch [70/350], Loss: 15.3811\n",
      "Count: 630\n",
      "Epoch [71/350], Loss: 14.3615\n",
      "Count: 639\n",
      "Epoch [72/350], Loss: 8.6791\n",
      "Count: 648\n",
      "Epoch [73/350], Loss: 11.5667\n",
      "Count: 657\n",
      "Epoch [74/350], Loss: 14.5864\n",
      "Count: 666\n",
      "Epoch [75/350], Loss: 20.5310\n",
      "Count: 675\n",
      "Epoch [76/350], Loss: 17.8110\n",
      "Count: 684\n",
      "Epoch [77/350], Loss: 5.9852\n",
      "Count: 693\n",
      "Epoch [78/350], Loss: 5.7871\n",
      "Count: 702\n",
      "Epoch [79/350], Loss: 30.1185\n",
      "Count: 711\n",
      "Epoch [80/350], Loss: 32.7693\n",
      "Count: 720\n",
      "Epoch [81/350], Loss: 8.2287\n",
      "Count: 729\n",
      "Epoch [82/350], Loss: 12.2218\n",
      "Count: 738\n",
      "Epoch [83/350], Loss: 10.6855\n",
      "Count: 747\n",
      "Epoch [84/350], Loss: 5.8739\n",
      "Count: 756\n",
      "Epoch [85/350], Loss: 20.6580\n",
      "Count: 765\n",
      "Epoch [86/350], Loss: 7.1068\n",
      "Count: 774\n",
      "Epoch [87/350], Loss: 3.9358\n",
      "Count: 783\n",
      "Epoch [88/350], Loss: 12.2171\n",
      "Count: 792\n",
      "Epoch [89/350], Loss: 22.1186\n",
      "Count: 801\n",
      "Epoch [90/350], Loss: 15.8174\n",
      "Count: 810\n",
      "Epoch [91/350], Loss: 18.8607\n",
      "Count: 819\n",
      "Epoch [92/350], Loss: 13.5437\n",
      "Count: 828\n",
      "Epoch [93/350], Loss: 11.5719\n",
      "Count: 837\n",
      "Epoch [94/350], Loss: 8.0530\n",
      "Count: 846\n",
      "Epoch [95/350], Loss: 12.8860\n",
      "Count: 855\n",
      "Epoch [96/350], Loss: 13.2935\n",
      "Count: 864\n",
      "Epoch [97/350], Loss: 4.0721\n",
      "Count: 873\n",
      "Epoch [98/350], Loss: 3.3816\n",
      "Count: 882\n",
      "Epoch [99/350], Loss: 11.5916\n",
      "Count: 891\n",
      "Epoch [100/350], Loss: 22.8060\n",
      "Count: 900\n",
      "Epoch [101/350], Loss: 7.9985\n",
      "Count: 909\n",
      "Epoch [102/350], Loss: 11.6608\n",
      "Count: 918\n",
      "Epoch [103/350], Loss: 16.6656\n",
      "Count: 927\n",
      "Epoch [104/350], Loss: 4.3178\n",
      "Count: 936\n",
      "Epoch [105/350], Loss: 18.6574\n",
      "Count: 945\n",
      "Epoch [106/350], Loss: 28.2224\n",
      "Count: 954\n",
      "Epoch [107/350], Loss: 11.3808\n",
      "Count: 963\n",
      "Epoch [108/350], Loss: 14.7188\n",
      "Count: 972\n",
      "Epoch [109/350], Loss: 21.1755\n",
      "Count: 981\n",
      "Epoch [110/350], Loss: 7.1759\n",
      "Count: 990\n",
      "Epoch [111/350], Loss: 15.1085\n",
      "Count: 999\n",
      "Epoch [112/350], Loss: 8.4526\n",
      "Count: 1008\n",
      "Epoch [113/350], Loss: 22.3816\n",
      "Count: 1017\n",
      "Epoch [114/350], Loss: 11.2853\n",
      "Count: 1026\n",
      "Epoch [115/350], Loss: 25.4114\n",
      "Count: 1035\n",
      "Epoch [116/350], Loss: 6.6565\n",
      "Count: 1044\n",
      "Epoch [117/350], Loss: 9.8418\n",
      "Count: 1053\n",
      "Epoch [118/350], Loss: 11.6710\n",
      "Count: 1062\n",
      "Epoch [119/350], Loss: 9.3735\n",
      "Count: 1071\n",
      "Epoch [120/350], Loss: 9.8901\n",
      "Count: 1080\n",
      "Epoch [121/350], Loss: 11.5499\n",
      "Count: 1089\n",
      "Epoch [122/350], Loss: 7.0506\n",
      "Count: 1098\n",
      "Epoch [123/350], Loss: 19.6829\n",
      "Count: 1107\n",
      "Epoch [124/350], Loss: 14.0469\n",
      "Count: 1116\n",
      "Epoch [125/350], Loss: 7.3448\n",
      "Count: 1125\n",
      "Epoch [126/350], Loss: 14.6537\n",
      "Count: 1134\n",
      "Epoch [127/350], Loss: 25.6818\n",
      "Count: 1143\n",
      "Epoch [128/350], Loss: 0.6184\n",
      "Count: 1152\n",
      "Epoch [129/350], Loss: 26.5007\n",
      "Count: 1161\n",
      "Epoch [130/350], Loss: 6.7468\n",
      "Count: 1170\n",
      "Epoch [131/350], Loss: 14.5816\n",
      "Count: 1179\n",
      "Epoch [132/350], Loss: 14.2636\n",
      "Count: 1188\n",
      "Epoch [133/350], Loss: 15.3957\n",
      "Count: 1197\n",
      "Epoch [134/350], Loss: 15.4878\n",
      "Count: 1206\n",
      "Epoch [135/350], Loss: 13.5108\n",
      "Count: 1215\n",
      "Epoch [136/350], Loss: 18.3105\n",
      "Count: 1224\n",
      "Epoch [137/350], Loss: 8.7925\n",
      "Count: 1233\n",
      "Epoch [138/350], Loss: 9.1064\n",
      "Count: 1242\n",
      "Epoch [139/350], Loss: 10.6784\n",
      "Count: 1251\n",
      "Epoch [140/350], Loss: 9.8552\n",
      "Count: 1260\n",
      "Epoch [141/350], Loss: 10.4027\n",
      "Count: 1269\n",
      "Epoch [142/350], Loss: 8.5429\n",
      "Count: 1278\n",
      "Epoch [143/350], Loss: 15.1067\n",
      "Count: 1287\n",
      "Epoch [144/350], Loss: 7.1772\n",
      "Count: 1296\n",
      "Epoch [145/350], Loss: 5.8748\n",
      "Count: 1305\n",
      "Epoch [146/350], Loss: 20.3249\n",
      "Count: 1314\n",
      "Epoch [147/350], Loss: 12.0714\n",
      "Count: 1323\n",
      "Epoch [148/350], Loss: 5.7862\n",
      "Count: 1332\n",
      "Epoch [149/350], Loss: 14.3921\n",
      "Count: 1341\n",
      "Epoch [150/350], Loss: 16.3623\n",
      "Count: 1350\n",
      "Epoch [151/350], Loss: 10.0407\n",
      "Count: 1359\n",
      "Epoch [152/350], Loss: 9.4105\n",
      "Count: 1368\n",
      "Epoch [153/350], Loss: 4.4609\n",
      "Count: 1377\n",
      "Epoch [154/350], Loss: 11.2469\n",
      "Count: 1386\n",
      "Epoch [155/350], Loss: 16.4486\n",
      "Count: 1395\n",
      "Epoch [156/350], Loss: 1.8005\n",
      "Count: 1404\n",
      "Epoch [157/350], Loss: 13.8219\n",
      "Count: 1413\n",
      "Epoch [158/350], Loss: 8.0257\n",
      "Count: 1422\n",
      "Epoch [159/350], Loss: 16.1364\n",
      "Count: 1431\n",
      "Epoch [160/350], Loss: 11.9904\n",
      "Count: 1440\n",
      "Epoch [161/350], Loss: 13.8637\n",
      "Count: 1449\n",
      "Epoch [162/350], Loss: 6.1423\n",
      "Count: 1458\n",
      "Epoch [163/350], Loss: 25.0048\n",
      "Count: 1467\n",
      "Epoch [164/350], Loss: 9.4514\n",
      "Count: 1476\n",
      "Epoch [165/350], Loss: 30.4898\n",
      "Count: 1485\n",
      "Epoch [166/350], Loss: 6.1417\n",
      "Count: 1494\n",
      "Epoch [167/350], Loss: 16.1476\n",
      "Count: 1503\n",
      "Epoch [168/350], Loss: 14.9672\n",
      "Count: 1512\n",
      "Epoch [169/350], Loss: 4.2296\n",
      "Count: 1521\n",
      "Epoch [170/350], Loss: 6.9323\n",
      "Count: 1530\n",
      "Epoch [171/350], Loss: 7.1373\n",
      "Count: 1539\n",
      "Epoch [172/350], Loss: 21.8711\n",
      "Count: 1548\n",
      "Epoch [173/350], Loss: 18.0910\n",
      "Count: 1557\n",
      "Epoch [174/350], Loss: 12.5875\n",
      "Count: 1566\n",
      "Epoch [175/350], Loss: 21.0842\n",
      "Count: 1575\n",
      "Epoch [176/350], Loss: 18.6170\n",
      "Count: 1584\n",
      "Epoch [177/350], Loss: 12.8848\n",
      "Count: 1593\n",
      "Epoch [178/350], Loss: 10.8633\n",
      "Count: 1602\n",
      "Epoch [179/350], Loss: 14.8477\n",
      "Count: 1611\n",
      "Epoch [180/350], Loss: 6.1999\n",
      "Count: 1620\n",
      "Epoch [181/350], Loss: 11.0030\n",
      "Count: 1629\n",
      "Epoch [182/350], Loss: 5.9827\n",
      "Count: 1638\n",
      "Epoch [183/350], Loss: 8.2507\n",
      "Count: 1647\n",
      "Epoch [184/350], Loss: 3.0093\n",
      "Count: 1656\n",
      "Epoch [185/350], Loss: 10.7667\n",
      "Count: 1665\n",
      "Epoch [186/350], Loss: 6.5379\n",
      "Count: 1674\n",
      "Epoch [187/350], Loss: 8.9446\n",
      "Count: 1683\n",
      "Epoch [188/350], Loss: 17.0313\n",
      "Count: 1692\n",
      "Epoch [189/350], Loss: 40.3409\n",
      "Count: 1701\n",
      "Epoch [190/350], Loss: 17.3866\n",
      "Count: 1710\n",
      "Epoch [191/350], Loss: 10.1910\n",
      "Count: 1719\n",
      "Epoch [192/350], Loss: 21.5696\n",
      "Count: 1728\n",
      "Epoch [193/350], Loss: 17.8111\n",
      "Count: 1737\n",
      "Epoch [194/350], Loss: 4.5307\n",
      "Count: 1746\n",
      "Epoch [195/350], Loss: 15.1177\n",
      "Count: 1755\n",
      "Epoch [196/350], Loss: 25.9576\n",
      "Count: 1764\n",
      "Epoch [197/350], Loss: 17.3776\n",
      "Count: 1773\n",
      "Epoch [198/350], Loss: 10.9600\n",
      "Count: 1782\n",
      "Epoch [199/350], Loss: 23.1459\n",
      "Count: 1791\n",
      "Epoch [200/350], Loss: 15.5983\n",
      "Count: 1800\n",
      "Epoch [201/350], Loss: 22.4520\n",
      "Count: 1809\n",
      "Epoch [202/350], Loss: 3.2315\n",
      "Count: 1818\n",
      "Epoch [203/350], Loss: 15.8241\n",
      "Count: 1827\n",
      "Epoch [204/350], Loss: 29.3438\n",
      "Count: 1836\n",
      "Epoch [205/350], Loss: 8.0841\n",
      "Count: 1845\n",
      "Epoch [206/350], Loss: 17.3171\n",
      "Count: 1854\n",
      "Epoch [207/350], Loss: 6.0719\n",
      "Count: 1863\n",
      "Epoch [208/350], Loss: 8.4514\n",
      "Count: 1872\n",
      "Epoch [209/350], Loss: 11.8806\n",
      "Count: 1881\n",
      "Epoch [210/350], Loss: 6.7005\n",
      "Count: 1890\n",
      "Epoch [211/350], Loss: 5.7589\n",
      "Count: 1899\n",
      "Epoch [212/350], Loss: 8.9312\n",
      "Count: 1908\n",
      "Epoch [213/350], Loss: 8.3652\n",
      "Count: 1917\n",
      "Epoch [214/350], Loss: 7.1401\n",
      "Count: 1926\n",
      "Epoch [215/350], Loss: 5.5606\n",
      "Count: 1935\n",
      "Epoch [216/350], Loss: 9.8735\n",
      "Count: 1944\n",
      "Epoch [217/350], Loss: 15.7453\n",
      "Count: 1953\n",
      "Epoch [218/350], Loss: 7.6697\n",
      "Count: 1962\n",
      "Epoch [219/350], Loss: 1.8452\n",
      "Count: 1971\n",
      "Epoch [220/350], Loss: 8.4890\n",
      "Count: 1980\n",
      "Epoch [221/350], Loss: 30.3074\n",
      "Count: 1989\n",
      "Epoch [222/350], Loss: 11.6646\n",
      "Count: 1998\n",
      "Epoch [223/350], Loss: 17.4935\n",
      "Count: 2007\n",
      "Epoch [224/350], Loss: 16.4478\n",
      "Count: 2016\n",
      "Epoch [225/350], Loss: 21.6309\n",
      "Count: 2025\n",
      "Epoch [226/350], Loss: 6.0669\n",
      "Count: 2034\n",
      "Epoch [227/350], Loss: 7.0029\n",
      "Count: 2043\n",
      "Epoch [228/350], Loss: 16.5518\n",
      "Count: 2052\n",
      "Epoch [229/350], Loss: 6.3077\n",
      "Count: 2061\n",
      "Epoch [230/350], Loss: 16.1039\n",
      "Count: 2070\n",
      "Epoch [231/350], Loss: 19.8085\n",
      "Count: 2079\n",
      "Epoch [232/350], Loss: 10.2857\n",
      "Count: 2088\n",
      "Epoch [233/350], Loss: 5.9707\n",
      "Count: 2097\n",
      "Epoch [234/350], Loss: 11.4991\n",
      "Count: 2106\n",
      "Epoch [235/350], Loss: 9.1147\n",
      "Count: 2115\n",
      "Epoch [236/350], Loss: 6.5270\n",
      "Count: 2124\n",
      "Epoch [237/350], Loss: 25.9291\n",
      "Count: 2133\n",
      "Epoch [238/350], Loss: 13.6560\n",
      "Count: 2142\n",
      "Epoch [239/350], Loss: 4.8080\n",
      "Count: 2151\n",
      "Epoch [240/350], Loss: 17.7189\n",
      "Count: 2160\n",
      "Epoch [241/350], Loss: 9.2968\n",
      "Count: 2169\n",
      "Epoch [242/350], Loss: 8.9700\n",
      "Count: 2178\n",
      "Epoch [243/350], Loss: 19.2277\n",
      "Count: 2187\n",
      "Epoch [244/350], Loss: 29.4118\n",
      "Count: 2196\n",
      "Epoch [245/350], Loss: 31.0434\n",
      "Count: 2205\n",
      "Epoch [246/350], Loss: 12.3257\n",
      "Count: 2214\n",
      "Epoch [247/350], Loss: 11.9879\n",
      "Count: 2223\n",
      "Epoch [248/350], Loss: 14.0077\n",
      "Count: 2232\n",
      "Epoch [249/350], Loss: 10.7612\n",
      "Count: 2241\n",
      "Epoch [250/350], Loss: 7.6121\n",
      "Count: 2250\n",
      "Epoch [251/350], Loss: 17.3198\n",
      "Count: 2259\n",
      "Epoch [252/350], Loss: 1.8859\n",
      "Count: 2268\n",
      "Epoch [253/350], Loss: 16.9379\n",
      "Count: 2277\n",
      "Epoch [254/350], Loss: 14.8643\n",
      "Count: 2286\n",
      "Epoch [255/350], Loss: 11.9960\n",
      "Count: 2295\n",
      "Epoch [256/350], Loss: 13.5308\n",
      "Count: 2304\n",
      "Epoch [257/350], Loss: 2.4716\n",
      "Count: 2313\n",
      "Epoch [258/350], Loss: 15.4057\n",
      "Count: 2322\n",
      "Epoch [259/350], Loss: 25.8691\n",
      "Count: 2331\n",
      "Epoch [260/350], Loss: 15.1260\n",
      "Count: 2340\n",
      "Epoch [261/350], Loss: 4.7279\n",
      "Count: 2349\n",
      "Epoch [262/350], Loss: 7.9821\n",
      "Count: 2358\n",
      "Epoch [263/350], Loss: 10.3662\n",
      "Count: 2367\n",
      "Epoch [264/350], Loss: 11.4640\n",
      "Count: 2376\n",
      "Epoch [265/350], Loss: 3.7030\n",
      "Count: 2385\n",
      "Epoch [266/350], Loss: 8.1501\n",
      "Count: 2394\n",
      "Epoch [267/350], Loss: 4.7863\n",
      "Count: 2403\n",
      "Epoch [268/350], Loss: 9.3228\n",
      "Count: 2412\n",
      "Epoch [269/350], Loss: 14.7726\n",
      "Count: 2421\n",
      "Epoch [270/350], Loss: 7.2345\n",
      "Count: 2430\n",
      "Epoch [271/350], Loss: 15.0270\n",
      "Count: 2439\n",
      "Epoch [272/350], Loss: 4.8201\n",
      "Count: 2448\n",
      "Epoch [273/350], Loss: 0.7940\n",
      "Count: 2457\n",
      "Epoch [274/350], Loss: 11.4342\n",
      "Count: 2466\n",
      "Epoch [275/350], Loss: 16.0594\n",
      "Count: 2475\n",
      "Epoch [276/350], Loss: 6.9330\n",
      "Count: 2484\n",
      "Epoch [277/350], Loss: 14.4067\n",
      "Count: 2493\n",
      "Epoch [278/350], Loss: 9.0897\n",
      "Count: 2502\n",
      "Epoch [279/350], Loss: 24.8591\n",
      "Count: 2511\n",
      "Epoch [280/350], Loss: 11.1717\n",
      "Count: 2520\n",
      "Epoch [281/350], Loss: 3.2126\n",
      "Count: 2529\n",
      "Epoch [282/350], Loss: 6.0953\n",
      "Count: 2538\n",
      "Epoch [283/350], Loss: 3.2811\n",
      "Count: 2547\n",
      "Epoch [284/350], Loss: 11.7604\n",
      "Count: 2556\n",
      "Epoch [285/350], Loss: 6.1833\n",
      "Count: 2565\n",
      "Epoch [286/350], Loss: 8.2752\n",
      "Count: 2574\n",
      "Epoch [287/350], Loss: 4.1149\n",
      "Count: 2583\n",
      "Epoch [288/350], Loss: 17.3780\n",
      "Count: 2592\n",
      "Epoch [289/350], Loss: 7.6320\n",
      "Count: 2601\n",
      "Epoch [290/350], Loss: 14.7067\n",
      "Count: 2610\n",
      "Epoch [291/350], Loss: 7.0988\n",
      "Count: 2619\n",
      "Epoch [292/350], Loss: 12.6831\n",
      "Count: 2628\n",
      "Epoch [293/350], Loss: 13.7704\n",
      "Count: 2637\n",
      "Epoch [294/350], Loss: 12.2268\n",
      "Count: 2646\n",
      "Epoch [295/350], Loss: 7.6150\n",
      "Count: 2655\n",
      "Epoch [296/350], Loss: 5.9118\n",
      "Count: 2664\n",
      "Epoch [297/350], Loss: 11.1869\n",
      "Count: 2673\n",
      "Epoch [298/350], Loss: 7.3663\n",
      "Count: 2682\n",
      "Epoch [299/350], Loss: 7.5544\n",
      "Count: 2691\n",
      "Epoch [300/350], Loss: 19.7314\n",
      "Count: 2700\n",
      "Epoch [301/350], Loss: 5.3059\n",
      "Count: 2709\n",
      "Epoch [302/350], Loss: 7.2903\n",
      "Count: 2718\n",
      "Epoch [303/350], Loss: 10.8915\n",
      "Count: 2727\n",
      "Epoch [304/350], Loss: 9.7147\n",
      "Count: 2736\n",
      "Epoch [305/350], Loss: 6.6076\n",
      "Count: 2745\n",
      "Epoch [306/350], Loss: 13.9138\n",
      "Count: 2754\n",
      "Epoch [307/350], Loss: 10.1606\n",
      "Count: 2763\n",
      "Epoch [308/350], Loss: 2.0609\n",
      "Count: 2772\n",
      "Epoch [309/350], Loss: 18.0788\n",
      "Count: 2781\n",
      "Epoch [310/350], Loss: 7.2285\n",
      "Count: 2790\n",
      "Epoch [311/350], Loss: 16.6026\n",
      "Count: 2799\n",
      "Epoch [312/350], Loss: 6.6492\n",
      "Count: 2808\n",
      "Epoch [313/350], Loss: 5.5803\n",
      "Count: 2817\n",
      "Epoch [314/350], Loss: 10.4161\n",
      "Count: 2826\n",
      "Epoch [315/350], Loss: 6.2244\n",
      "Count: 2835\n",
      "Epoch [316/350], Loss: 13.4886\n",
      "Count: 2844\n",
      "Epoch [317/350], Loss: 14.2921\n",
      "Count: 2853\n",
      "Epoch [318/350], Loss: 9.8242\n",
      "Count: 2862\n",
      "Epoch [319/350], Loss: 11.5558\n",
      "Count: 2871\n",
      "Epoch [320/350], Loss: 10.6578\n",
      "Count: 2880\n",
      "Epoch [321/350], Loss: 18.9407\n",
      "Count: 2889\n",
      "Epoch [322/350], Loss: 22.6408\n",
      "Count: 2898\n",
      "Epoch [323/350], Loss: 8.1523\n",
      "Count: 2907\n",
      "Epoch [324/350], Loss: 2.4493\n",
      "Count: 2916\n",
      "Epoch [325/350], Loss: 12.0288\n",
      "Count: 2925\n",
      "Epoch [326/350], Loss: 13.4971\n",
      "Count: 2934\n",
      "Epoch [327/350], Loss: 3.9814\n",
      "Count: 2943\n",
      "Epoch [328/350], Loss: 12.1168\n",
      "Count: 2952\n",
      "Epoch [329/350], Loss: 6.2437\n",
      "Count: 2961\n",
      "Epoch [330/350], Loss: 14.5256\n",
      "Count: 2970\n",
      "Epoch [331/350], Loss: 10.7058\n",
      "Count: 2979\n",
      "Epoch [332/350], Loss: 6.7423\n",
      "Count: 2988\n",
      "Epoch [333/350], Loss: 8.9021\n",
      "Count: 2997\n",
      "Epoch [334/350], Loss: 8.8363\n",
      "Count: 3006\n",
      "Epoch [335/350], Loss: 9.1912\n",
      "Count: 3015\n",
      "Epoch [336/350], Loss: 15.9194\n",
      "Count: 3024\n",
      "Epoch [337/350], Loss: 8.1964\n",
      "Count: 3033\n",
      "Epoch [338/350], Loss: 15.4117\n",
      "Count: 3042\n",
      "Epoch [339/350], Loss: 19.4447\n",
      "Count: 3051\n",
      "Epoch [340/350], Loss: 12.4539\n",
      "Count: 3060\n",
      "Epoch [341/350], Loss: 12.6538\n",
      "Count: 3069\n",
      "Epoch [342/350], Loss: 12.3575\n",
      "Count: 3078\n",
      "Epoch [343/350], Loss: 8.2234\n",
      "Count: 3087\n",
      "Epoch [344/350], Loss: 5.0383\n",
      "Count: 3096\n",
      "Epoch [345/350], Loss: 8.9606\n",
      "Count: 3105\n",
      "Epoch [346/350], Loss: 15.7852\n",
      "Count: 3114\n",
      "Epoch [347/350], Loss: 9.7463\n",
      "Count: 3123\n",
      "Epoch [348/350], Loss: 11.1099\n",
      "Count: 3132\n",
      "Epoch [349/350], Loss: 7.9587\n",
      "Count: 3141\n",
      "Epoch [350/350], Loss: 13.6783\n",
      "Count: 3150\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Train the model.\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(lstm.parameters())\n",
    "\n",
    "num_epochs = 350\n",
    "count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    lstm.train() # Set model to training mode\n",
    "    for inputs, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = lstm(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    print(f'Count: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation, Total Loss: 38.1087\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "lstm.eval() # Set model to eval mode\n",
    "total_loss = 0\n",
    "for inputs, labels in val_loader:\n",
    "    # Forward pass\n",
    "    outputs = lstm(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    total_loss += loss\n",
    "print(f'Evaluation, Total Loss: {total_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 3.2666, MAE: 2.5558, R²: 0.5429\n",
      "Testing RMSE: 4.1535, MAE: 3.2161, R²: 0.4473\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "y_train_pred = lstm(X_train_tensor).detach().numpy()\n",
    "y_test_pred = lstm(X_test_tensor).detach().numpy()\n",
    "\n",
    "# Get the diff values for evaluation.\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Training RMSE: {rmse_train:.4f}, MAE: {mae_train:.4f}, R²: {r2_train:.4f}')\n",
    "print(f'Testing RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}, R²: {r2_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Prediction                 Player\n",
      "0    15.967394         Saquon Barkley\n",
      "1    13.889805          Derrick Henry\n",
      "2    14.350593           Jahmyr Gibbs\n",
      "3    15.006719         Bijan Robinson\n",
      "4    14.196068            Josh Jacobs\n",
      "..         ...                    ...\n",
      "77    6.616431            Blake Corum\n",
      "78    8.629021         D'Onta Foreman\n",
      "79    6.600417         Patrick Taylor\n",
      "80    8.197599  Cordarrelle Patterson\n",
      "81   14.830505         Michael Carter\n",
      "\n",
      "[82 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Return results using model.\n",
    "predictions = lstm(torch.tensor(X_2024, dtype=torch.float32)).detach().numpy()\n",
    "predictions_df = pd.DataFrame(predictions, columns=['Prediction'])\n",
    "predictions_df['Player'] = player_names_2024\n",
    "print(f'{predictions_df}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new DataFrame to an Excel file\n",
    "file_path = 'results/simple_lstm_rb.xlsx'\n",
    "predictions_df.to_excel(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
