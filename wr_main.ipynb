{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asadhneni/.local/lib/python3.10/site-packages/numpy/_core/getlimits.py:551: UserWarning: Signature b'\\x00\\xd0\\xcc\\xcc\\xcc\\xcc\\xcc\\xcc\\xfb\\xbf\\x00\\x00\\x00\\x00\\x00\\x00' for <class 'numpy.longdouble'> does not match any known type: falling back to type probe function.\n",
      "This warnings indicates broken support for the dtype!\n",
      "  machar = _get_machar(dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEAR  Rk             Player   Tm FantPos  Age   G  GS  QBCmp  QBAtt  ...  \\\n",
      "4   2024   5      Ja'Marr Chase  CIN      WR   24  17  16      0      0  ...   \n",
      "11  2024  12   Justin Jefferson  MIN      WR   25  17  17      1      1  ...   \n",
      "14  2024  15      George Kittle  SFO      TE   31  15  15      0      0  ...   \n",
      "17  2024  18  Amon-Ra St. Brown  DET      WR   25  17  17      1      1  ...   \n",
      "18  2024  19       Brian Thomas  JAX      WR   22  17  16      0      0  ...   \n",
      "19  2024  20       Brock Bowers  LVR      TE   22  17  16      0      0  ...   \n",
      "22  2024  23     Terry McLaurin  WAS      WR   29  17  17      0      0  ...   \n",
      "23  2024  24       Trey McBride  ARI      TE   25  16  16      0      0  ...   \n",
      "25  2024  26       Drake London  ATL      WR   23  17  17      0      0  ...   \n",
      "27  2024  28        Jonnu Smith  MIA      TE   29  17   6      0      0  ...   \n",
      "\n",
      "    RecYds    Y/R  RecTD  Fmb  FL  TotTD  14:00:00  2PP    PPR      PPR/G  \n",
      "4     1708  13.45     17    0   0     17       0.0  0.0  403.0  23.705882  \n",
      "11    1533  14.88     10    1   0     10       0.0  0.0  317.5  18.676471  \n",
      "14    1106  14.18      8    0   0      8       0.0  0.0  236.6  15.773333  \n",
      "17    1263  10.98     12    1   1     12       0.0  0.0  316.2  18.600000  \n",
      "18    1282  14.74     10    0   0     10       2.0  0.0  284.0  16.705882  \n",
      "19    1194  10.66      5    0   0      5       0.0  0.0  262.7  15.452941  \n",
      "22    1096  13.37     13    1   1     13       0.0  0.0  267.8  15.752941  \n",
      "23    1146  10.32      2    0   0      4       0.0  0.0  249.8  15.612500  \n",
      "25    1271  12.71      9    0   0      9       0.0  0.0  280.8  16.517647  \n",
      "27     884  10.05      8    2   1      8       0.0  0.0  222.3  13.076471  \n",
      "\n",
      "[10 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "pro_football_focus_data = 'data/pro_football_ref.xlsx'\n",
    "model_path = 'model_path/trained_model.pth'\n",
    "\n",
    "# Load and preprocess the pro football focus data.\n",
    "df = pd.read_excel(pro_football_focus_data)\n",
    "# Filter to only include wide receivers (WR)\n",
    "df = df[df['FantPos'].isin(['WR', 'TE'])].copy()\n",
    "df.replace([float('inf'), -float('inf')], 0, inplace=True)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Calculate points per game.\n",
    "df.loc[:, 'PPR/G'] = df['PPR'] / df['G']\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEAR  Rk   Tm FantPos  Age   G  GS  QBCmp  QBAtt  QBYds  ...  RecYds  \\\n",
      "4   2024   5  CIN      WR   24  17  16      0      0      0  ...    1708   \n",
      "11  2024  12  MIN      WR   25  17  17      1      1     22  ...    1533   \n",
      "14  2024  15  SFO      TE   31  15  15      0      0      0  ...    1106   \n",
      "17  2024  18  DET      WR   25  17  17      1      1      7  ...    1263   \n",
      "18  2024  19  JAX      WR   22  17  16      0      0      0  ...    1282   \n",
      "19  2024  20  LVR      TE   22  17  16      0      0      0  ...    1194   \n",
      "22  2024  23  WAS      WR   29  17  17      0      0      0  ...    1096   \n",
      "23  2024  24  ARI      TE   25  16  16      0      0      0  ...    1146   \n",
      "25  2024  26  ATL      WR   23  17  17      0      0      0  ...    1271   \n",
      "27  2024  28  MIA      TE   29  17   6      0      0      0  ...     884   \n",
      "\n",
      "      Y/R  RecTD  Fmb  FL  TotTD  14:00:00  2PP    PPR      PPR/G  \n",
      "4   13.45     17    0   0     17       0.0  0.0  403.0  23.705882  \n",
      "11  14.88     10    1   0     10       0.0  0.0  317.5  18.676471  \n",
      "14  14.18      8    0   0      8       0.0  0.0  236.6  15.773333  \n",
      "17  10.98     12    1   1     12       0.0  0.0  316.2  18.600000  \n",
      "18  14.74     10    0   0     10       2.0  0.0  284.0  16.705882  \n",
      "19  10.66      5    0   0      5       0.0  0.0  262.7  15.452941  \n",
      "22  13.37     13    1   1     13       0.0  0.0  267.8  15.752941  \n",
      "23  10.32      2    0   0      4       0.0  0.0  249.8  15.612500  \n",
      "25  12.71      9    0   0      9       0.0  0.0  280.8  16.517647  \n",
      "27  10.05      8    2   1      8       0.0  0.0  222.3  13.076471  \n",
      "\n",
      "[10 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Copy the 2024 data into separate dataframe.\n",
    "df_2024 = df[df['YEAR'] == 2024].copy()\n",
    "player_names_2024 = df_2024['Player'].reset_index(drop=True)\n",
    "df_2024 = df_2024.drop(columns=['Player'])\n",
    "\n",
    "print(df_2024.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25290\n"
     ]
    }
   ],
   "source": [
    "# Shift to represent the following year's points per game\n",
    "df['NextYearPPR/G'] = df.groupby('Player')['PPR/G'].shift(-1)\n",
    "\n",
    "# Remove rows where the target is NaN (i.e., no following year data)\n",
    "df = df[df['NextYearPPR/G'].notna()]\n",
    "\n",
    "print(df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age  Tgt  Rec  RecYds      PPR/G\n",
      "423    27   87   51     717  11.746154\n",
      "1666   34   82   52     597   8.835714\n",
      "1537   27  149  104    1199  16.343750\n",
      "420    22  110   69     905  10.900000\n",
      "1381   27   60   30     505   8.258333\n",
      "...   ...  ...  ...     ...        ...\n",
      "167    24   71   47     548   7.781250\n",
      "233    25   86   59     494   7.457143\n",
      "626    23  146  106    1161  16.725000\n",
      "1034   29   69   45     556  15.244444\n",
      "222    32   58   40     390   5.352941\n",
      "\n",
      "[505 rows x 5 columns]\n",
      "423     10.629412\n",
      "1666     8.900000\n",
      "1537    16.256250\n",
      "420     10.505882\n",
      "1381     9.864286\n",
      "          ...    \n",
      "167      8.807692\n",
      "233     10.417647\n",
      "626     13.370588\n",
      "1034    15.318750\n",
      "222      7.766667\n",
      "Name: NextYearPPR/G, Length: 505, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define features and target.\n",
    "feature_names = ['Age', 'Tgt', 'Rec', 'RecYds', 'PPR/G']\n",
    "target = 'NextYearPPR/G'\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X = df[feature_names]\n",
    "y = df[target]\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "print(f'{X_train}')\n",
    "print(f'{y_train}')\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "X_2024 = df_2024[feature_names]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_2024 = scaler.transform(X_2024)\n",
    "\n",
    "# Ensure X_train, X_val, X_test, and X_2024 are correctly shaped for LSTM\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_val = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "X_2024 = X_2024.reshape(X_2024.shape[0], 1, X_2024.shape[1])\n",
    "\n",
    "# Check to see standardized data.\n",
    "#print(f'Size {y_train.size}')\n",
    "#print(f'Size {X_val.size}')\n",
    "#print(f'Size {y_val.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnclass.simple_nn import SimpleLSTM\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# Create SimpleLTSM.\n",
    "input_size = X_train.shape[2]\n",
    "hidden_size = 32\n",
    "output_size = 1\n",
    "lstm = SimpleLSTM(input_size, hidden_size, output_size)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/750], Loss: 114.9391\n",
      "Count: 16\n",
      "Epoch [2/750], Loss: 133.8235\n",
      "Count: 32\n",
      "Epoch [3/750], Loss: 137.2437\n",
      "Count: 48\n",
      "Epoch [4/750], Loss: 131.5339\n",
      "Count: 64\n",
      "Epoch [5/750], Loss: 118.4695\n",
      "Count: 80\n",
      "Epoch [6/750], Loss: 158.0957\n",
      "Count: 96\n",
      "Epoch [7/750], Loss: 119.2900\n",
      "Count: 112\n",
      "Epoch [8/750], Loss: 122.2508\n",
      "Count: 128\n",
      "Epoch [9/750], Loss: 109.5540\n",
      "Count: 144\n",
      "Epoch [10/750], Loss: 100.6923\n",
      "Count: 160\n",
      "Epoch [11/750], Loss: 83.9892\n",
      "Count: 176\n",
      "Epoch [12/750], Loss: 111.0381\n",
      "Count: 192\n",
      "Epoch [13/750], Loss: 86.5325\n",
      "Count: 208\n",
      "Epoch [14/750], Loss: 75.0769\n",
      "Count: 224\n",
      "Epoch [15/750], Loss: 77.4620\n",
      "Count: 240\n",
      "Epoch [16/750], Loss: 52.8025\n",
      "Count: 256\n",
      "Epoch [17/750], Loss: 45.0062\n",
      "Count: 272\n",
      "Epoch [18/750], Loss: 69.3775\n",
      "Count: 288\n",
      "Epoch [19/750], Loss: 50.9552\n",
      "Count: 304\n",
      "Epoch [20/750], Loss: 39.3974\n",
      "Count: 320\n",
      "Epoch [21/750], Loss: 44.7584\n",
      "Count: 336\n",
      "Epoch [22/750], Loss: 29.7782\n",
      "Count: 352\n",
      "Epoch [23/750], Loss: 27.5728\n",
      "Count: 368\n",
      "Epoch [24/750], Loss: 33.4538\n",
      "Count: 384\n",
      "Epoch [25/750], Loss: 21.9015\n",
      "Count: 400\n",
      "Epoch [26/750], Loss: 14.3234\n",
      "Count: 416\n",
      "Epoch [27/750], Loss: 17.6165\n",
      "Count: 432\n",
      "Epoch [28/750], Loss: 17.7714\n",
      "Count: 448\n",
      "Epoch [29/750], Loss: 20.2437\n",
      "Count: 464\n",
      "Epoch [30/750], Loss: 20.6121\n",
      "Count: 480\n",
      "Epoch [31/750], Loss: 17.8894\n",
      "Count: 496\n",
      "Epoch [32/750], Loss: 7.5452\n",
      "Count: 512\n",
      "Epoch [33/750], Loss: 13.8295\n",
      "Count: 528\n",
      "Epoch [34/750], Loss: 8.9443\n",
      "Count: 544\n",
      "Epoch [35/750], Loss: 14.4310\n",
      "Count: 560\n",
      "Epoch [36/750], Loss: 14.0550\n",
      "Count: 576\n",
      "Epoch [37/750], Loss: 6.9668\n",
      "Count: 592\n",
      "Epoch [38/750], Loss: 9.6717\n",
      "Count: 608\n",
      "Epoch [39/750], Loss: 19.4885\n",
      "Count: 624\n",
      "Epoch [40/750], Loss: 7.9190\n",
      "Count: 640\n",
      "Epoch [41/750], Loss: 5.2859\n",
      "Count: 656\n",
      "Epoch [42/750], Loss: 11.2956\n",
      "Count: 672\n",
      "Epoch [43/750], Loss: 7.3674\n",
      "Count: 688\n",
      "Epoch [44/750], Loss: 7.1693\n",
      "Count: 704\n",
      "Epoch [45/750], Loss: 16.6074\n",
      "Count: 720\n",
      "Epoch [46/750], Loss: 9.5007\n",
      "Count: 736\n",
      "Epoch [47/750], Loss: 7.3827\n",
      "Count: 752\n",
      "Epoch [48/750], Loss: 8.7405\n",
      "Count: 768\n",
      "Epoch [49/750], Loss: 10.6918\n",
      "Count: 784\n",
      "Epoch [50/750], Loss: 6.9340\n",
      "Count: 800\n",
      "Epoch [51/750], Loss: 10.3346\n",
      "Count: 816\n",
      "Epoch [52/750], Loss: 10.6694\n",
      "Count: 832\n",
      "Epoch [53/750], Loss: 9.2856\n",
      "Count: 848\n",
      "Epoch [54/750], Loss: 7.9454\n",
      "Count: 864\n",
      "Epoch [55/750], Loss: 9.3429\n",
      "Count: 880\n",
      "Epoch [56/750], Loss: 6.8216\n",
      "Count: 896\n",
      "Epoch [57/750], Loss: 5.9745\n",
      "Count: 912\n",
      "Epoch [58/750], Loss: 10.6862\n",
      "Count: 928\n",
      "Epoch [59/750], Loss: 7.3471\n",
      "Count: 944\n",
      "Epoch [60/750], Loss: 10.9991\n",
      "Count: 960\n",
      "Epoch [61/750], Loss: 4.8267\n",
      "Count: 976\n",
      "Epoch [62/750], Loss: 6.6358\n",
      "Count: 992\n",
      "Epoch [63/750], Loss: 6.3003\n",
      "Count: 1008\n",
      "Epoch [64/750], Loss: 9.8906\n",
      "Count: 1024\n",
      "Epoch [65/750], Loss: 6.3234\n",
      "Count: 1040\n",
      "Epoch [66/750], Loss: 11.3434\n",
      "Count: 1056\n",
      "Epoch [67/750], Loss: 9.8792\n",
      "Count: 1072\n",
      "Epoch [68/750], Loss: 6.2755\n",
      "Count: 1088\n",
      "Epoch [69/750], Loss: 7.1036\n",
      "Count: 1104\n",
      "Epoch [70/750], Loss: 7.1972\n",
      "Count: 1120\n",
      "Epoch [71/750], Loss: 10.6503\n",
      "Count: 1136\n",
      "Epoch [72/750], Loss: 7.3348\n",
      "Count: 1152\n",
      "Epoch [73/750], Loss: 8.3288\n",
      "Count: 1168\n",
      "Epoch [74/750], Loss: 8.8844\n",
      "Count: 1184\n",
      "Epoch [75/750], Loss: 6.4954\n",
      "Count: 1200\n",
      "Epoch [76/750], Loss: 13.2083\n",
      "Count: 1216\n",
      "Epoch [77/750], Loss: 6.7562\n",
      "Count: 1232\n",
      "Epoch [78/750], Loss: 5.1393\n",
      "Count: 1248\n",
      "Epoch [79/750], Loss: 8.9508\n",
      "Count: 1264\n",
      "Epoch [80/750], Loss: 4.8851\n",
      "Count: 1280\n",
      "Epoch [81/750], Loss: 8.5142\n",
      "Count: 1296\n",
      "Epoch [82/750], Loss: 5.2843\n",
      "Count: 1312\n",
      "Epoch [83/750], Loss: 9.4579\n",
      "Count: 1328\n",
      "Epoch [84/750], Loss: 3.5595\n",
      "Count: 1344\n",
      "Epoch [85/750], Loss: 4.4837\n",
      "Count: 1360\n",
      "Epoch [86/750], Loss: 6.9849\n",
      "Count: 1376\n",
      "Epoch [87/750], Loss: 6.0235\n",
      "Count: 1392\n",
      "Epoch [88/750], Loss: 5.6279\n",
      "Count: 1408\n",
      "Epoch [89/750], Loss: 11.4112\n",
      "Count: 1424\n",
      "Epoch [90/750], Loss: 7.0164\n",
      "Count: 1440\n",
      "Epoch [91/750], Loss: 10.2720\n",
      "Count: 1456\n",
      "Epoch [92/750], Loss: 8.7058\n",
      "Count: 1472\n",
      "Epoch [93/750], Loss: 6.2382\n",
      "Count: 1488\n",
      "Epoch [94/750], Loss: 5.5373\n",
      "Count: 1504\n",
      "Epoch [95/750], Loss: 11.4420\n",
      "Count: 1520\n",
      "Epoch [96/750], Loss: 9.5033\n",
      "Count: 1536\n",
      "Epoch [97/750], Loss: 8.0147\n",
      "Count: 1552\n",
      "Epoch [98/750], Loss: 6.1487\n",
      "Count: 1568\n",
      "Epoch [99/750], Loss: 8.9919\n",
      "Count: 1584\n",
      "Epoch [100/750], Loss: 5.0118\n",
      "Count: 1600\n",
      "Epoch [101/750], Loss: 8.5604\n",
      "Count: 1616\n",
      "Epoch [102/750], Loss: 9.4415\n",
      "Count: 1632\n",
      "Epoch [103/750], Loss: 4.3781\n",
      "Count: 1648\n",
      "Epoch [104/750], Loss: 4.8399\n",
      "Count: 1664\n",
      "Epoch [105/750], Loss: 7.7794\n",
      "Count: 1680\n",
      "Epoch [106/750], Loss: 9.6819\n",
      "Count: 1696\n",
      "Epoch [107/750], Loss: 8.4866\n",
      "Count: 1712\n",
      "Epoch [108/750], Loss: 6.6921\n",
      "Count: 1728\n",
      "Epoch [109/750], Loss: 10.7377\n",
      "Count: 1744\n",
      "Epoch [110/750], Loss: 8.4692\n",
      "Count: 1760\n",
      "Epoch [111/750], Loss: 9.9697\n",
      "Count: 1776\n",
      "Epoch [112/750], Loss: 11.9338\n",
      "Count: 1792\n",
      "Epoch [113/750], Loss: 7.0190\n",
      "Count: 1808\n",
      "Epoch [114/750], Loss: 12.4268\n",
      "Count: 1824\n",
      "Epoch [115/750], Loss: 10.6828\n",
      "Count: 1840\n",
      "Epoch [116/750], Loss: 7.0184\n",
      "Count: 1856\n",
      "Epoch [117/750], Loss: 9.3050\n",
      "Count: 1872\n",
      "Epoch [118/750], Loss: 7.4668\n",
      "Count: 1888\n",
      "Epoch [119/750], Loss: 4.3882\n",
      "Count: 1904\n",
      "Epoch [120/750], Loss: 8.0692\n",
      "Count: 1920\n",
      "Epoch [121/750], Loss: 6.7038\n",
      "Count: 1936\n",
      "Epoch [122/750], Loss: 8.9315\n",
      "Count: 1952\n",
      "Epoch [123/750], Loss: 9.7510\n",
      "Count: 1968\n",
      "Epoch [124/750], Loss: 7.2579\n",
      "Count: 1984\n",
      "Epoch [125/750], Loss: 8.3014\n",
      "Count: 2000\n",
      "Epoch [126/750], Loss: 7.8431\n",
      "Count: 2016\n",
      "Epoch [127/750], Loss: 8.3513\n",
      "Count: 2032\n",
      "Epoch [128/750], Loss: 6.9206\n",
      "Count: 2048\n",
      "Epoch [129/750], Loss: 13.5149\n",
      "Count: 2064\n",
      "Epoch [130/750], Loss: 7.1277\n",
      "Count: 2080\n",
      "Epoch [131/750], Loss: 9.9865\n",
      "Count: 2096\n",
      "Epoch [132/750], Loss: 7.5243\n",
      "Count: 2112\n",
      "Epoch [133/750], Loss: 7.8077\n",
      "Count: 2128\n",
      "Epoch [134/750], Loss: 8.9230\n",
      "Count: 2144\n",
      "Epoch [135/750], Loss: 6.0372\n",
      "Count: 2160\n",
      "Epoch [136/750], Loss: 5.5850\n",
      "Count: 2176\n",
      "Epoch [137/750], Loss: 10.4707\n",
      "Count: 2192\n",
      "Epoch [138/750], Loss: 8.9548\n",
      "Count: 2208\n",
      "Epoch [139/750], Loss: 7.6669\n",
      "Count: 2224\n",
      "Epoch [140/750], Loss: 9.0163\n",
      "Count: 2240\n",
      "Epoch [141/750], Loss: 6.2148\n",
      "Count: 2256\n",
      "Epoch [142/750], Loss: 6.4696\n",
      "Count: 2272\n",
      "Epoch [143/750], Loss: 6.4331\n",
      "Count: 2288\n",
      "Epoch [144/750], Loss: 5.3713\n",
      "Count: 2304\n",
      "Epoch [145/750], Loss: 8.5859\n",
      "Count: 2320\n",
      "Epoch [146/750], Loss: 13.1507\n",
      "Count: 2336\n",
      "Epoch [147/750], Loss: 9.5036\n",
      "Count: 2352\n",
      "Epoch [148/750], Loss: 12.7768\n",
      "Count: 2368\n",
      "Epoch [149/750], Loss: 5.1071\n",
      "Count: 2384\n",
      "Epoch [150/750], Loss: 6.4732\n",
      "Count: 2400\n",
      "Epoch [151/750], Loss: 5.2630\n",
      "Count: 2416\n",
      "Epoch [152/750], Loss: 7.2942\n",
      "Count: 2432\n",
      "Epoch [153/750], Loss: 6.4617\n",
      "Count: 2448\n",
      "Epoch [154/750], Loss: 11.2875\n",
      "Count: 2464\n",
      "Epoch [155/750], Loss: 6.4107\n",
      "Count: 2480\n",
      "Epoch [156/750], Loss: 5.3024\n",
      "Count: 2496\n",
      "Epoch [157/750], Loss: 5.7178\n",
      "Count: 2512\n",
      "Epoch [158/750], Loss: 5.7095\n",
      "Count: 2528\n",
      "Epoch [159/750], Loss: 6.2723\n",
      "Count: 2544\n",
      "Epoch [160/750], Loss: 9.3367\n",
      "Count: 2560\n",
      "Epoch [161/750], Loss: 3.3852\n",
      "Count: 2576\n",
      "Epoch [162/750], Loss: 7.4903\n",
      "Count: 2592\n",
      "Epoch [163/750], Loss: 5.1955\n",
      "Count: 2608\n",
      "Epoch [164/750], Loss: 6.9553\n",
      "Count: 2624\n",
      "Epoch [165/750], Loss: 5.3997\n",
      "Count: 2640\n",
      "Epoch [166/750], Loss: 7.1173\n",
      "Count: 2656\n",
      "Epoch [167/750], Loss: 7.6336\n",
      "Count: 2672\n",
      "Epoch [168/750], Loss: 4.8056\n",
      "Count: 2688\n",
      "Epoch [169/750], Loss: 4.6746\n",
      "Count: 2704\n",
      "Epoch [170/750], Loss: 9.2829\n",
      "Count: 2720\n",
      "Epoch [171/750], Loss: 10.8676\n",
      "Count: 2736\n",
      "Epoch [172/750], Loss: 8.9340\n",
      "Count: 2752\n",
      "Epoch [173/750], Loss: 2.6283\n",
      "Count: 2768\n",
      "Epoch [174/750], Loss: 6.5629\n",
      "Count: 2784\n",
      "Epoch [175/750], Loss: 11.0972\n",
      "Count: 2800\n",
      "Epoch [176/750], Loss: 8.8796\n",
      "Count: 2816\n",
      "Epoch [177/750], Loss: 3.0571\n",
      "Count: 2832\n",
      "Epoch [178/750], Loss: 7.5915\n",
      "Count: 2848\n",
      "Epoch [179/750], Loss: 9.9576\n",
      "Count: 2864\n",
      "Epoch [180/750], Loss: 6.8959\n",
      "Count: 2880\n",
      "Epoch [181/750], Loss: 4.6864\n",
      "Count: 2896\n",
      "Epoch [182/750], Loss: 6.7886\n",
      "Count: 2912\n",
      "Epoch [183/750], Loss: 9.0393\n",
      "Count: 2928\n",
      "Epoch [184/750], Loss: 8.4020\n",
      "Count: 2944\n",
      "Epoch [185/750], Loss: 10.1084\n",
      "Count: 2960\n",
      "Epoch [186/750], Loss: 6.4084\n",
      "Count: 2976\n",
      "Epoch [187/750], Loss: 5.5346\n",
      "Count: 2992\n",
      "Epoch [188/750], Loss: 8.7209\n",
      "Count: 3008\n",
      "Epoch [189/750], Loss: 11.8207\n",
      "Count: 3024\n",
      "Epoch [190/750], Loss: 8.3668\n",
      "Count: 3040\n",
      "Epoch [191/750], Loss: 6.1576\n",
      "Count: 3056\n",
      "Epoch [192/750], Loss: 9.4084\n",
      "Count: 3072\n",
      "Epoch [193/750], Loss: 11.3506\n",
      "Count: 3088\n",
      "Epoch [194/750], Loss: 7.7543\n",
      "Count: 3104\n",
      "Epoch [195/750], Loss: 8.5541\n",
      "Count: 3120\n",
      "Epoch [196/750], Loss: 5.8325\n",
      "Count: 3136\n",
      "Epoch [197/750], Loss: 6.9424\n",
      "Count: 3152\n",
      "Epoch [198/750], Loss: 6.2727\n",
      "Count: 3168\n",
      "Epoch [199/750], Loss: 9.0372\n",
      "Count: 3184\n",
      "Epoch [200/750], Loss: 5.1676\n",
      "Count: 3200\n",
      "Epoch [201/750], Loss: 10.3552\n",
      "Count: 3216\n",
      "Epoch [202/750], Loss: 10.3664\n",
      "Count: 3232\n",
      "Epoch [203/750], Loss: 10.6984\n",
      "Count: 3248\n",
      "Epoch [204/750], Loss: 6.4872\n",
      "Count: 3264\n",
      "Epoch [205/750], Loss: 9.3349\n",
      "Count: 3280\n",
      "Epoch [206/750], Loss: 6.0982\n",
      "Count: 3296\n",
      "Epoch [207/750], Loss: 9.7819\n",
      "Count: 3312\n",
      "Epoch [208/750], Loss: 5.5643\n",
      "Count: 3328\n",
      "Epoch [209/750], Loss: 5.2291\n",
      "Count: 3344\n",
      "Epoch [210/750], Loss: 10.8756\n",
      "Count: 3360\n",
      "Epoch [211/750], Loss: 7.2423\n",
      "Count: 3376\n",
      "Epoch [212/750], Loss: 11.4793\n",
      "Count: 3392\n",
      "Epoch [213/750], Loss: 11.3078\n",
      "Count: 3408\n",
      "Epoch [214/750], Loss: 9.0581\n",
      "Count: 3424\n",
      "Epoch [215/750], Loss: 7.4100\n",
      "Count: 3440\n",
      "Epoch [216/750], Loss: 8.7132\n",
      "Count: 3456\n",
      "Epoch [217/750], Loss: 6.6186\n",
      "Count: 3472\n",
      "Epoch [218/750], Loss: 7.3270\n",
      "Count: 3488\n",
      "Epoch [219/750], Loss: 4.9650\n",
      "Count: 3504\n",
      "Epoch [220/750], Loss: 8.5462\n",
      "Count: 3520\n",
      "Epoch [221/750], Loss: 6.3105\n",
      "Count: 3536\n",
      "Epoch [222/750], Loss: 7.1881\n",
      "Count: 3552\n",
      "Epoch [223/750], Loss: 6.5417\n",
      "Count: 3568\n",
      "Epoch [224/750], Loss: 5.8831\n",
      "Count: 3584\n",
      "Epoch [225/750], Loss: 6.3740\n",
      "Count: 3600\n",
      "Epoch [226/750], Loss: 15.0106\n",
      "Count: 3616\n",
      "Epoch [227/750], Loss: 8.1189\n",
      "Count: 3632\n",
      "Epoch [228/750], Loss: 4.3043\n",
      "Count: 3648\n",
      "Epoch [229/750], Loss: 7.4885\n",
      "Count: 3664\n",
      "Epoch [230/750], Loss: 9.6930\n",
      "Count: 3680\n",
      "Epoch [231/750], Loss: 9.7743\n",
      "Count: 3696\n",
      "Epoch [232/750], Loss: 6.0709\n",
      "Count: 3712\n",
      "Epoch [233/750], Loss: 13.1009\n",
      "Count: 3728\n",
      "Epoch [234/750], Loss: 10.9601\n",
      "Count: 3744\n",
      "Epoch [235/750], Loss: 8.4607\n",
      "Count: 3760\n",
      "Epoch [236/750], Loss: 6.7827\n",
      "Count: 3776\n",
      "Epoch [237/750], Loss: 10.4029\n",
      "Count: 3792\n",
      "Epoch [238/750], Loss: 6.0262\n",
      "Count: 3808\n",
      "Epoch [239/750], Loss: 6.8771\n",
      "Count: 3824\n",
      "Epoch [240/750], Loss: 7.0168\n",
      "Count: 3840\n",
      "Epoch [241/750], Loss: 6.9281\n",
      "Count: 3856\n",
      "Epoch [242/750], Loss: 4.0180\n",
      "Count: 3872\n",
      "Epoch [243/750], Loss: 7.2185\n",
      "Count: 3888\n",
      "Epoch [244/750], Loss: 6.3602\n",
      "Count: 3904\n",
      "Epoch [245/750], Loss: 6.5782\n",
      "Count: 3920\n",
      "Epoch [246/750], Loss: 7.8573\n",
      "Count: 3936\n",
      "Epoch [247/750], Loss: 5.2921\n",
      "Count: 3952\n",
      "Epoch [248/750], Loss: 7.9133\n",
      "Count: 3968\n",
      "Epoch [249/750], Loss: 8.4029\n",
      "Count: 3984\n",
      "Epoch [250/750], Loss: 8.8686\n",
      "Count: 4000\n",
      "Epoch [251/750], Loss: 3.8709\n",
      "Count: 4016\n",
      "Epoch [252/750], Loss: 9.8291\n",
      "Count: 4032\n",
      "Epoch [253/750], Loss: 7.2493\n",
      "Count: 4048\n",
      "Epoch [254/750], Loss: 7.4537\n",
      "Count: 4064\n",
      "Epoch [255/750], Loss: 9.5834\n",
      "Count: 4080\n",
      "Epoch [256/750], Loss: 5.7723\n",
      "Count: 4096\n",
      "Epoch [257/750], Loss: 6.5680\n",
      "Count: 4112\n",
      "Epoch [258/750], Loss: 11.9934\n",
      "Count: 4128\n",
      "Epoch [259/750], Loss: 11.2562\n",
      "Count: 4144\n",
      "Epoch [260/750], Loss: 4.6450\n",
      "Count: 4160\n",
      "Epoch [261/750], Loss: 4.7852\n",
      "Count: 4176\n",
      "Epoch [262/750], Loss: 4.7585\n",
      "Count: 4192\n",
      "Epoch [263/750], Loss: 8.6246\n",
      "Count: 4208\n",
      "Epoch [264/750], Loss: 7.9386\n",
      "Count: 4224\n",
      "Epoch [265/750], Loss: 8.8825\n",
      "Count: 4240\n",
      "Epoch [266/750], Loss: 5.7461\n",
      "Count: 4256\n",
      "Epoch [267/750], Loss: 6.8183\n",
      "Count: 4272\n",
      "Epoch [268/750], Loss: 5.3075\n",
      "Count: 4288\n",
      "Epoch [269/750], Loss: 9.9973\n",
      "Count: 4304\n",
      "Epoch [270/750], Loss: 9.6768\n",
      "Count: 4320\n",
      "Epoch [271/750], Loss: 5.9943\n",
      "Count: 4336\n",
      "Epoch [272/750], Loss: 7.0211\n",
      "Count: 4352\n",
      "Epoch [273/750], Loss: 6.8955\n",
      "Count: 4368\n",
      "Epoch [274/750], Loss: 8.2476\n",
      "Count: 4384\n",
      "Epoch [275/750], Loss: 10.1362\n",
      "Count: 4400\n",
      "Epoch [276/750], Loss: 6.9592\n",
      "Count: 4416\n",
      "Epoch [277/750], Loss: 9.8969\n",
      "Count: 4432\n",
      "Epoch [278/750], Loss: 9.6851\n",
      "Count: 4448\n",
      "Epoch [279/750], Loss: 7.8998\n",
      "Count: 4464\n",
      "Epoch [280/750], Loss: 9.7983\n",
      "Count: 4480\n",
      "Epoch [281/750], Loss: 9.3019\n",
      "Count: 4496\n",
      "Epoch [282/750], Loss: 6.5556\n",
      "Count: 4512\n",
      "Epoch [283/750], Loss: 5.5175\n",
      "Count: 4528\n",
      "Epoch [284/750], Loss: 10.0695\n",
      "Count: 4544\n",
      "Epoch [285/750], Loss: 13.7135\n",
      "Count: 4560\n",
      "Epoch [286/750], Loss: 7.1918\n",
      "Count: 4576\n",
      "Epoch [287/750], Loss: 6.4917\n",
      "Count: 4592\n",
      "Epoch [288/750], Loss: 6.9119\n",
      "Count: 4608\n",
      "Epoch [289/750], Loss: 7.1909\n",
      "Count: 4624\n",
      "Epoch [290/750], Loss: 7.1330\n",
      "Count: 4640\n",
      "Epoch [291/750], Loss: 5.8058\n",
      "Count: 4656\n",
      "Epoch [292/750], Loss: 9.8757\n",
      "Count: 4672\n",
      "Epoch [293/750], Loss: 7.0639\n",
      "Count: 4688\n",
      "Epoch [294/750], Loss: 11.6379\n",
      "Count: 4704\n",
      "Epoch [295/750], Loss: 5.8378\n",
      "Count: 4720\n",
      "Epoch [296/750], Loss: 8.0475\n",
      "Count: 4736\n",
      "Epoch [297/750], Loss: 6.0880\n",
      "Count: 4752\n",
      "Epoch [298/750], Loss: 11.3415\n",
      "Count: 4768\n",
      "Epoch [299/750], Loss: 10.1552\n",
      "Count: 4784\n",
      "Epoch [300/750], Loss: 6.0672\n",
      "Count: 4800\n",
      "Epoch [301/750], Loss: 9.6976\n",
      "Count: 4816\n",
      "Epoch [302/750], Loss: 4.4467\n",
      "Count: 4832\n",
      "Epoch [303/750], Loss: 9.5147\n",
      "Count: 4848\n",
      "Epoch [304/750], Loss: 11.1795\n",
      "Count: 4864\n",
      "Epoch [305/750], Loss: 5.5256\n",
      "Count: 4880\n",
      "Epoch [306/750], Loss: 7.7370\n",
      "Count: 4896\n",
      "Epoch [307/750], Loss: 5.8959\n",
      "Count: 4912\n",
      "Epoch [308/750], Loss: 6.8612\n",
      "Count: 4928\n",
      "Epoch [309/750], Loss: 5.2854\n",
      "Count: 4944\n",
      "Epoch [310/750], Loss: 7.9009\n",
      "Count: 4960\n",
      "Epoch [311/750], Loss: 6.8624\n",
      "Count: 4976\n",
      "Epoch [312/750], Loss: 6.6447\n",
      "Count: 4992\n",
      "Epoch [313/750], Loss: 8.2919\n",
      "Count: 5008\n",
      "Epoch [314/750], Loss: 6.2788\n",
      "Count: 5024\n",
      "Epoch [315/750], Loss: 9.1888\n",
      "Count: 5040\n",
      "Epoch [316/750], Loss: 7.6014\n",
      "Count: 5056\n",
      "Epoch [317/750], Loss: 10.5026\n",
      "Count: 5072\n",
      "Epoch [318/750], Loss: 13.5039\n",
      "Count: 5088\n",
      "Epoch [319/750], Loss: 7.1247\n",
      "Count: 5104\n",
      "Epoch [320/750], Loss: 8.4949\n",
      "Count: 5120\n",
      "Epoch [321/750], Loss: 9.5708\n",
      "Count: 5136\n",
      "Epoch [322/750], Loss: 9.4149\n",
      "Count: 5152\n",
      "Epoch [323/750], Loss: 10.1021\n",
      "Count: 5168\n",
      "Epoch [324/750], Loss: 8.2723\n",
      "Count: 5184\n",
      "Epoch [325/750], Loss: 9.6366\n",
      "Count: 5200\n",
      "Epoch [326/750], Loss: 8.1843\n",
      "Count: 5216\n",
      "Epoch [327/750], Loss: 10.1690\n",
      "Count: 5232\n",
      "Epoch [328/750], Loss: 6.9665\n",
      "Count: 5248\n",
      "Epoch [329/750], Loss: 5.5887\n",
      "Count: 5264\n",
      "Epoch [330/750], Loss: 5.5109\n",
      "Count: 5280\n",
      "Epoch [331/750], Loss: 5.7898\n",
      "Count: 5296\n",
      "Epoch [332/750], Loss: 7.4752\n",
      "Count: 5312\n",
      "Epoch [333/750], Loss: 6.8264\n",
      "Count: 5328\n",
      "Epoch [334/750], Loss: 10.7123\n",
      "Count: 5344\n",
      "Epoch [335/750], Loss: 5.5629\n",
      "Count: 5360\n",
      "Epoch [336/750], Loss: 5.8457\n",
      "Count: 5376\n",
      "Epoch [337/750], Loss: 8.8261\n",
      "Count: 5392\n",
      "Epoch [338/750], Loss: 6.5372\n",
      "Count: 5408\n",
      "Epoch [339/750], Loss: 12.1444\n",
      "Count: 5424\n",
      "Epoch [340/750], Loss: 5.2052\n",
      "Count: 5440\n",
      "Epoch [341/750], Loss: 9.7273\n",
      "Count: 5456\n",
      "Epoch [342/750], Loss: 6.0542\n",
      "Count: 5472\n",
      "Epoch [343/750], Loss: 8.0362\n",
      "Count: 5488\n",
      "Epoch [344/750], Loss: 7.2228\n",
      "Count: 5504\n",
      "Epoch [345/750], Loss: 5.3975\n",
      "Count: 5520\n",
      "Epoch [346/750], Loss: 8.0789\n",
      "Count: 5536\n",
      "Epoch [347/750], Loss: 12.8661\n",
      "Count: 5552\n",
      "Epoch [348/750], Loss: 9.4411\n",
      "Count: 5568\n",
      "Epoch [349/750], Loss: 5.2505\n",
      "Count: 5584\n",
      "Epoch [350/750], Loss: 7.8641\n",
      "Count: 5600\n",
      "Epoch [351/750], Loss: 10.0060\n",
      "Count: 5616\n",
      "Epoch [352/750], Loss: 7.0457\n",
      "Count: 5632\n",
      "Epoch [353/750], Loss: 9.4490\n",
      "Count: 5648\n",
      "Epoch [354/750], Loss: 5.4094\n",
      "Count: 5664\n",
      "Epoch [355/750], Loss: 8.2207\n",
      "Count: 5680\n",
      "Epoch [356/750], Loss: 4.9231\n",
      "Count: 5696\n",
      "Epoch [357/750], Loss: 7.6308\n",
      "Count: 5712\n",
      "Epoch [358/750], Loss: 4.0506\n",
      "Count: 5728\n",
      "Epoch [359/750], Loss: 9.5908\n",
      "Count: 5744\n",
      "Epoch [360/750], Loss: 6.0269\n",
      "Count: 5760\n",
      "Epoch [361/750], Loss: 6.5799\n",
      "Count: 5776\n",
      "Epoch [362/750], Loss: 7.0931\n",
      "Count: 5792\n",
      "Epoch [363/750], Loss: 9.2830\n",
      "Count: 5808\n",
      "Epoch [364/750], Loss: 10.9040\n",
      "Count: 5824\n",
      "Epoch [365/750], Loss: 6.2906\n",
      "Count: 5840\n",
      "Epoch [366/750], Loss: 10.1008\n",
      "Count: 5856\n",
      "Epoch [367/750], Loss: 6.4117\n",
      "Count: 5872\n",
      "Epoch [368/750], Loss: 5.8216\n",
      "Count: 5888\n",
      "Epoch [369/750], Loss: 7.0526\n",
      "Count: 5904\n",
      "Epoch [370/750], Loss: 9.5887\n",
      "Count: 5920\n",
      "Epoch [371/750], Loss: 12.7505\n",
      "Count: 5936\n",
      "Epoch [372/750], Loss: 9.5049\n",
      "Count: 5952\n",
      "Epoch [373/750], Loss: 6.3375\n",
      "Count: 5968\n",
      "Epoch [374/750], Loss: 9.0749\n",
      "Count: 5984\n",
      "Epoch [375/750], Loss: 7.1756\n",
      "Count: 6000\n",
      "Epoch [376/750], Loss: 6.4505\n",
      "Count: 6016\n",
      "Epoch [377/750], Loss: 9.8142\n",
      "Count: 6032\n",
      "Epoch [378/750], Loss: 15.6094\n",
      "Count: 6048\n",
      "Epoch [379/750], Loss: 6.2627\n",
      "Count: 6064\n",
      "Epoch [380/750], Loss: 6.3142\n",
      "Count: 6080\n",
      "Epoch [381/750], Loss: 8.2019\n",
      "Count: 6096\n",
      "Epoch [382/750], Loss: 8.2007\n",
      "Count: 6112\n",
      "Epoch [383/750], Loss: 7.2207\n",
      "Count: 6128\n",
      "Epoch [384/750], Loss: 5.2630\n",
      "Count: 6144\n",
      "Epoch [385/750], Loss: 5.8773\n",
      "Count: 6160\n",
      "Epoch [386/750], Loss: 8.7768\n",
      "Count: 6176\n",
      "Epoch [387/750], Loss: 3.3152\n",
      "Count: 6192\n",
      "Epoch [388/750], Loss: 7.2600\n",
      "Count: 6208\n",
      "Epoch [389/750], Loss: 4.9696\n",
      "Count: 6224\n",
      "Epoch [390/750], Loss: 4.0096\n",
      "Count: 6240\n",
      "Epoch [391/750], Loss: 5.4351\n",
      "Count: 6256\n",
      "Epoch [392/750], Loss: 4.4216\n",
      "Count: 6272\n",
      "Epoch [393/750], Loss: 6.6128\n",
      "Count: 6288\n",
      "Epoch [394/750], Loss: 7.8896\n",
      "Count: 6304\n",
      "Epoch [395/750], Loss: 4.5404\n",
      "Count: 6320\n",
      "Epoch [396/750], Loss: 5.2996\n",
      "Count: 6336\n",
      "Epoch [397/750], Loss: 7.4168\n",
      "Count: 6352\n",
      "Epoch [398/750], Loss: 6.7715\n",
      "Count: 6368\n",
      "Epoch [399/750], Loss: 5.4393\n",
      "Count: 6384\n",
      "Epoch [400/750], Loss: 6.5243\n",
      "Count: 6400\n",
      "Epoch [401/750], Loss: 4.2891\n",
      "Count: 6416\n",
      "Epoch [402/750], Loss: 5.8701\n",
      "Count: 6432\n",
      "Epoch [403/750], Loss: 6.7176\n",
      "Count: 6448\n",
      "Epoch [404/750], Loss: 7.0298\n",
      "Count: 6464\n",
      "Epoch [405/750], Loss: 5.3026\n",
      "Count: 6480\n",
      "Epoch [406/750], Loss: 11.1438\n",
      "Count: 6496\n",
      "Epoch [407/750], Loss: 7.6347\n",
      "Count: 6512\n",
      "Epoch [408/750], Loss: 6.1437\n",
      "Count: 6528\n",
      "Epoch [409/750], Loss: 11.2295\n",
      "Count: 6544\n",
      "Epoch [410/750], Loss: 6.3287\n",
      "Count: 6560\n",
      "Epoch [411/750], Loss: 4.4664\n",
      "Count: 6576\n",
      "Epoch [412/750], Loss: 8.4685\n",
      "Count: 6592\n",
      "Epoch [413/750], Loss: 10.4860\n",
      "Count: 6608\n",
      "Epoch [414/750], Loss: 5.2412\n",
      "Count: 6624\n",
      "Epoch [415/750], Loss: 5.4426\n",
      "Count: 6640\n",
      "Epoch [416/750], Loss: 5.7906\n",
      "Count: 6656\n",
      "Epoch [417/750], Loss: 5.7878\n",
      "Count: 6672\n",
      "Epoch [418/750], Loss: 7.7843\n",
      "Count: 6688\n",
      "Epoch [419/750], Loss: 8.2931\n",
      "Count: 6704\n",
      "Epoch [420/750], Loss: 8.3085\n",
      "Count: 6720\n",
      "Epoch [421/750], Loss: 9.1713\n",
      "Count: 6736\n",
      "Epoch [422/750], Loss: 7.3756\n",
      "Count: 6752\n",
      "Epoch [423/750], Loss: 9.9085\n",
      "Count: 6768\n",
      "Epoch [424/750], Loss: 7.1897\n",
      "Count: 6784\n",
      "Epoch [425/750], Loss: 9.1484\n",
      "Count: 6800\n",
      "Epoch [426/750], Loss: 8.6937\n",
      "Count: 6816\n",
      "Epoch [427/750], Loss: 8.5789\n",
      "Count: 6832\n",
      "Epoch [428/750], Loss: 5.9379\n",
      "Count: 6848\n",
      "Epoch [429/750], Loss: 6.3499\n",
      "Count: 6864\n",
      "Epoch [430/750], Loss: 7.8883\n",
      "Count: 6880\n",
      "Epoch [431/750], Loss: 6.6879\n",
      "Count: 6896\n",
      "Epoch [432/750], Loss: 6.2823\n",
      "Count: 6912\n",
      "Epoch [433/750], Loss: 4.7365\n",
      "Count: 6928\n",
      "Epoch [434/750], Loss: 5.2608\n",
      "Count: 6944\n",
      "Epoch [435/750], Loss: 9.2199\n",
      "Count: 6960\n",
      "Epoch [436/750], Loss: 6.9735\n",
      "Count: 6976\n",
      "Epoch [437/750], Loss: 5.2268\n",
      "Count: 6992\n",
      "Epoch [438/750], Loss: 4.8592\n",
      "Count: 7008\n",
      "Epoch [439/750], Loss: 9.1055\n",
      "Count: 7024\n",
      "Epoch [440/750], Loss: 8.2411\n",
      "Count: 7040\n",
      "Epoch [441/750], Loss: 6.8036\n",
      "Count: 7056\n",
      "Epoch [442/750], Loss: 6.8661\n",
      "Count: 7072\n",
      "Epoch [443/750], Loss: 7.0992\n",
      "Count: 7088\n",
      "Epoch [444/750], Loss: 6.8931\n",
      "Count: 7104\n",
      "Epoch [445/750], Loss: 9.0919\n",
      "Count: 7120\n",
      "Epoch [446/750], Loss: 4.8851\n",
      "Count: 7136\n",
      "Epoch [447/750], Loss: 6.6288\n",
      "Count: 7152\n",
      "Epoch [448/750], Loss: 9.9527\n",
      "Count: 7168\n",
      "Epoch [449/750], Loss: 6.1510\n",
      "Count: 7184\n",
      "Epoch [450/750], Loss: 7.8852\n",
      "Count: 7200\n",
      "Epoch [451/750], Loss: 11.7866\n",
      "Count: 7216\n",
      "Epoch [452/750], Loss: 3.8778\n",
      "Count: 7232\n",
      "Epoch [453/750], Loss: 10.6918\n",
      "Count: 7248\n",
      "Epoch [454/750], Loss: 6.7204\n",
      "Count: 7264\n",
      "Epoch [455/750], Loss: 8.2497\n",
      "Count: 7280\n",
      "Epoch [456/750], Loss: 8.1491\n",
      "Count: 7296\n",
      "Epoch [457/750], Loss: 5.5924\n",
      "Count: 7312\n",
      "Epoch [458/750], Loss: 8.8444\n",
      "Count: 7328\n",
      "Epoch [459/750], Loss: 6.1941\n",
      "Count: 7344\n",
      "Epoch [460/750], Loss: 7.8561\n",
      "Count: 7360\n",
      "Epoch [461/750], Loss: 4.8384\n",
      "Count: 7376\n",
      "Epoch [462/750], Loss: 3.8930\n",
      "Count: 7392\n",
      "Epoch [463/750], Loss: 3.5747\n",
      "Count: 7408\n",
      "Epoch [464/750], Loss: 5.0692\n",
      "Count: 7424\n",
      "Epoch [465/750], Loss: 5.5116\n",
      "Count: 7440\n",
      "Epoch [466/750], Loss: 7.5835\n",
      "Count: 7456\n",
      "Epoch [467/750], Loss: 5.2397\n",
      "Count: 7472\n",
      "Epoch [468/750], Loss: 12.4678\n",
      "Count: 7488\n",
      "Epoch [469/750], Loss: 6.0478\n",
      "Count: 7504\n",
      "Epoch [470/750], Loss: 7.1166\n",
      "Count: 7520\n",
      "Epoch [471/750], Loss: 5.0522\n",
      "Count: 7536\n",
      "Epoch [472/750], Loss: 9.4783\n",
      "Count: 7552\n",
      "Epoch [473/750], Loss: 5.7596\n",
      "Count: 7568\n",
      "Epoch [474/750], Loss: 5.7031\n",
      "Count: 7584\n",
      "Epoch [475/750], Loss: 8.0093\n",
      "Count: 7600\n",
      "Epoch [476/750], Loss: 5.1043\n",
      "Count: 7616\n",
      "Epoch [477/750], Loss: 7.2525\n",
      "Count: 7632\n",
      "Epoch [478/750], Loss: 7.6678\n",
      "Count: 7648\n",
      "Epoch [479/750], Loss: 3.7943\n",
      "Count: 7664\n",
      "Epoch [480/750], Loss: 8.3293\n",
      "Count: 7680\n",
      "Epoch [481/750], Loss: 10.5928\n",
      "Count: 7696\n",
      "Epoch [482/750], Loss: 6.6567\n",
      "Count: 7712\n",
      "Epoch [483/750], Loss: 8.8668\n",
      "Count: 7728\n",
      "Epoch [484/750], Loss: 8.5027\n",
      "Count: 7744\n",
      "Epoch [485/750], Loss: 5.2221\n",
      "Count: 7760\n",
      "Epoch [486/750], Loss: 8.4732\n",
      "Count: 7776\n",
      "Epoch [487/750], Loss: 6.2165\n",
      "Count: 7792\n",
      "Epoch [488/750], Loss: 5.8159\n",
      "Count: 7808\n",
      "Epoch [489/750], Loss: 8.4506\n",
      "Count: 7824\n",
      "Epoch [490/750], Loss: 10.7563\n",
      "Count: 7840\n",
      "Epoch [491/750], Loss: 6.7457\n",
      "Count: 7856\n",
      "Epoch [492/750], Loss: 6.3906\n",
      "Count: 7872\n",
      "Epoch [493/750], Loss: 7.7327\n",
      "Count: 7888\n",
      "Epoch [494/750], Loss: 4.9739\n",
      "Count: 7904\n",
      "Epoch [495/750], Loss: 6.9720\n",
      "Count: 7920\n",
      "Epoch [496/750], Loss: 5.0146\n",
      "Count: 7936\n",
      "Epoch [497/750], Loss: 8.0507\n",
      "Count: 7952\n",
      "Epoch [498/750], Loss: 6.7517\n",
      "Count: 7968\n",
      "Epoch [499/750], Loss: 5.3419\n",
      "Count: 7984\n",
      "Epoch [500/750], Loss: 11.1327\n",
      "Count: 8000\n",
      "Epoch [501/750], Loss: 4.3070\n",
      "Count: 8016\n",
      "Epoch [502/750], Loss: 10.1025\n",
      "Count: 8032\n",
      "Epoch [503/750], Loss: 10.8378\n",
      "Count: 8048\n",
      "Epoch [504/750], Loss: 6.7140\n",
      "Count: 8064\n",
      "Epoch [505/750], Loss: 9.1848\n",
      "Count: 8080\n",
      "Epoch [506/750], Loss: 4.9344\n",
      "Count: 8096\n",
      "Epoch [507/750], Loss: 9.1801\n",
      "Count: 8112\n",
      "Epoch [508/750], Loss: 4.7712\n",
      "Count: 8128\n",
      "Epoch [509/750], Loss: 6.2268\n",
      "Count: 8144\n",
      "Epoch [510/750], Loss: 7.3738\n",
      "Count: 8160\n",
      "Epoch [511/750], Loss: 6.8530\n",
      "Count: 8176\n",
      "Epoch [512/750], Loss: 9.0745\n",
      "Count: 8192\n",
      "Epoch [513/750], Loss: 4.9655\n",
      "Count: 8208\n",
      "Epoch [514/750], Loss: 5.8439\n",
      "Count: 8224\n",
      "Epoch [515/750], Loss: 6.8398\n",
      "Count: 8240\n",
      "Epoch [516/750], Loss: 8.0428\n",
      "Count: 8256\n",
      "Epoch [517/750], Loss: 3.9490\n",
      "Count: 8272\n",
      "Epoch [518/750], Loss: 7.3506\n",
      "Count: 8288\n",
      "Epoch [519/750], Loss: 10.2193\n",
      "Count: 8304\n",
      "Epoch [520/750], Loss: 7.2449\n",
      "Count: 8320\n",
      "Epoch [521/750], Loss: 8.1176\n",
      "Count: 8336\n",
      "Epoch [522/750], Loss: 5.7322\n",
      "Count: 8352\n",
      "Epoch [523/750], Loss: 6.3309\n",
      "Count: 8368\n",
      "Epoch [524/750], Loss: 9.8646\n",
      "Count: 8384\n",
      "Epoch [525/750], Loss: 9.2016\n",
      "Count: 8400\n",
      "Epoch [526/750], Loss: 8.3805\n",
      "Count: 8416\n",
      "Epoch [527/750], Loss: 6.2321\n",
      "Count: 8432\n",
      "Epoch [528/750], Loss: 11.0569\n",
      "Count: 8448\n",
      "Epoch [529/750], Loss: 10.5767\n",
      "Count: 8464\n",
      "Epoch [530/750], Loss: 9.5672\n",
      "Count: 8480\n",
      "Epoch [531/750], Loss: 7.3584\n",
      "Count: 8496\n",
      "Epoch [532/750], Loss: 6.5833\n",
      "Count: 8512\n",
      "Epoch [533/750], Loss: 7.1343\n",
      "Count: 8528\n",
      "Epoch [534/750], Loss: 8.3258\n",
      "Count: 8544\n",
      "Epoch [535/750], Loss: 10.3629\n",
      "Count: 8560\n",
      "Epoch [536/750], Loss: 14.4678\n",
      "Count: 8576\n",
      "Epoch [537/750], Loss: 10.6792\n",
      "Count: 8592\n",
      "Epoch [538/750], Loss: 8.9419\n",
      "Count: 8608\n",
      "Epoch [539/750], Loss: 7.0619\n",
      "Count: 8624\n",
      "Epoch [540/750], Loss: 8.2418\n",
      "Count: 8640\n",
      "Epoch [541/750], Loss: 5.1711\n",
      "Count: 8656\n",
      "Epoch [542/750], Loss: 6.2976\n",
      "Count: 8672\n",
      "Epoch [543/750], Loss: 8.1041\n",
      "Count: 8688\n",
      "Epoch [544/750], Loss: 5.2607\n",
      "Count: 8704\n",
      "Epoch [545/750], Loss: 8.2413\n",
      "Count: 8720\n",
      "Epoch [546/750], Loss: 9.4844\n",
      "Count: 8736\n",
      "Epoch [547/750], Loss: 10.0344\n",
      "Count: 8752\n",
      "Epoch [548/750], Loss: 7.3395\n",
      "Count: 8768\n",
      "Epoch [549/750], Loss: 8.8325\n",
      "Count: 8784\n",
      "Epoch [550/750], Loss: 8.1294\n",
      "Count: 8800\n",
      "Epoch [551/750], Loss: 8.5673\n",
      "Count: 8816\n",
      "Epoch [552/750], Loss: 6.4827\n",
      "Count: 8832\n",
      "Epoch [553/750], Loss: 10.5639\n",
      "Count: 8848\n",
      "Epoch [554/750], Loss: 9.0987\n",
      "Count: 8864\n",
      "Epoch [555/750], Loss: 7.1946\n",
      "Count: 8880\n",
      "Epoch [556/750], Loss: 5.7868\n",
      "Count: 8896\n",
      "Epoch [557/750], Loss: 4.9209\n",
      "Count: 8912\n",
      "Epoch [558/750], Loss: 8.2107\n",
      "Count: 8928\n",
      "Epoch [559/750], Loss: 8.7291\n",
      "Count: 8944\n",
      "Epoch [560/750], Loss: 6.7359\n",
      "Count: 8960\n",
      "Epoch [561/750], Loss: 4.8912\n",
      "Count: 8976\n",
      "Epoch [562/750], Loss: 9.7986\n",
      "Count: 8992\n",
      "Epoch [563/750], Loss: 5.4171\n",
      "Count: 9008\n",
      "Epoch [564/750], Loss: 6.4979\n",
      "Count: 9024\n",
      "Epoch [565/750], Loss: 6.4444\n",
      "Count: 9040\n",
      "Epoch [566/750], Loss: 6.3831\n",
      "Count: 9056\n",
      "Epoch [567/750], Loss: 10.7204\n",
      "Count: 9072\n",
      "Epoch [568/750], Loss: 6.4604\n",
      "Count: 9088\n",
      "Epoch [569/750], Loss: 6.6801\n",
      "Count: 9104\n",
      "Epoch [570/750], Loss: 8.8795\n",
      "Count: 9120\n",
      "Epoch [571/750], Loss: 8.0585\n",
      "Count: 9136\n",
      "Epoch [572/750], Loss: 8.2772\n",
      "Count: 9152\n",
      "Epoch [573/750], Loss: 7.4625\n",
      "Count: 9168\n",
      "Epoch [574/750], Loss: 5.9112\n",
      "Count: 9184\n",
      "Epoch [575/750], Loss: 7.1178\n",
      "Count: 9200\n",
      "Epoch [576/750], Loss: 5.2117\n",
      "Count: 9216\n",
      "Epoch [577/750], Loss: 4.7952\n",
      "Count: 9232\n",
      "Epoch [578/750], Loss: 4.8137\n",
      "Count: 9248\n",
      "Epoch [579/750], Loss: 7.5508\n",
      "Count: 9264\n",
      "Epoch [580/750], Loss: 6.1122\n",
      "Count: 9280\n",
      "Epoch [581/750], Loss: 8.2612\n",
      "Count: 9296\n",
      "Epoch [582/750], Loss: 7.2593\n",
      "Count: 9312\n",
      "Epoch [583/750], Loss: 8.8317\n",
      "Count: 9328\n",
      "Epoch [584/750], Loss: 12.0340\n",
      "Count: 9344\n",
      "Epoch [585/750], Loss: 8.7271\n",
      "Count: 9360\n",
      "Epoch [586/750], Loss: 5.8603\n",
      "Count: 9376\n",
      "Epoch [587/750], Loss: 8.8732\n",
      "Count: 9392\n",
      "Epoch [588/750], Loss: 9.7398\n",
      "Count: 9408\n",
      "Epoch [589/750], Loss: 8.2112\n",
      "Count: 9424\n",
      "Epoch [590/750], Loss: 6.5625\n",
      "Count: 9440\n",
      "Epoch [591/750], Loss: 5.6563\n",
      "Count: 9456\n",
      "Epoch [592/750], Loss: 7.8933\n",
      "Count: 9472\n",
      "Epoch [593/750], Loss: 5.1161\n",
      "Count: 9488\n",
      "Epoch [594/750], Loss: 7.6193\n",
      "Count: 9504\n",
      "Epoch [595/750], Loss: 9.8302\n",
      "Count: 9520\n",
      "Epoch [596/750], Loss: 7.9264\n",
      "Count: 9536\n",
      "Epoch [597/750], Loss: 6.1002\n",
      "Count: 9552\n",
      "Epoch [598/750], Loss: 6.6646\n",
      "Count: 9568\n",
      "Epoch [599/750], Loss: 10.4106\n",
      "Count: 9584\n",
      "Epoch [600/750], Loss: 6.5438\n",
      "Count: 9600\n",
      "Epoch [601/750], Loss: 5.1774\n",
      "Count: 9616\n",
      "Epoch [602/750], Loss: 9.3434\n",
      "Count: 9632\n",
      "Epoch [603/750], Loss: 14.8621\n",
      "Count: 9648\n",
      "Epoch [604/750], Loss: 6.3825\n",
      "Count: 9664\n",
      "Epoch [605/750], Loss: 8.1902\n",
      "Count: 9680\n",
      "Epoch [606/750], Loss: 9.0806\n",
      "Count: 9696\n",
      "Epoch [607/750], Loss: 4.3552\n",
      "Count: 9712\n",
      "Epoch [608/750], Loss: 6.0402\n",
      "Count: 9728\n",
      "Epoch [609/750], Loss: 6.4089\n",
      "Count: 9744\n",
      "Epoch [610/750], Loss: 6.4325\n",
      "Count: 9760\n",
      "Epoch [611/750], Loss: 10.1897\n",
      "Count: 9776\n",
      "Epoch [612/750], Loss: 5.9536\n",
      "Count: 9792\n",
      "Epoch [613/750], Loss: 8.4615\n",
      "Count: 9808\n",
      "Epoch [614/750], Loss: 5.2427\n",
      "Count: 9824\n",
      "Epoch [615/750], Loss: 6.0495\n",
      "Count: 9840\n",
      "Epoch [616/750], Loss: 8.5637\n",
      "Count: 9856\n",
      "Epoch [617/750], Loss: 12.6601\n",
      "Count: 9872\n",
      "Epoch [618/750], Loss: 6.8551\n",
      "Count: 9888\n",
      "Epoch [619/750], Loss: 3.4770\n",
      "Count: 9904\n",
      "Epoch [620/750], Loss: 4.2462\n",
      "Count: 9920\n",
      "Epoch [621/750], Loss: 8.0162\n",
      "Count: 9936\n",
      "Epoch [622/750], Loss: 8.9127\n",
      "Count: 9952\n",
      "Epoch [623/750], Loss: 5.9301\n",
      "Count: 9968\n",
      "Epoch [624/750], Loss: 11.3734\n",
      "Count: 9984\n",
      "Epoch [625/750], Loss: 9.9407\n",
      "Count: 10000\n",
      "Epoch [626/750], Loss: 6.5536\n",
      "Count: 10016\n",
      "Epoch [627/750], Loss: 3.1528\n",
      "Count: 10032\n",
      "Epoch [628/750], Loss: 6.6729\n",
      "Count: 10048\n",
      "Epoch [629/750], Loss: 6.8577\n",
      "Count: 10064\n",
      "Epoch [630/750], Loss: 6.8829\n",
      "Count: 10080\n",
      "Epoch [631/750], Loss: 7.4079\n",
      "Count: 10096\n",
      "Epoch [632/750], Loss: 9.2372\n",
      "Count: 10112\n",
      "Epoch [633/750], Loss: 9.0493\n",
      "Count: 10128\n",
      "Epoch [634/750], Loss: 6.0568\n",
      "Count: 10144\n",
      "Epoch [635/750], Loss: 9.0024\n",
      "Count: 10160\n",
      "Epoch [636/750], Loss: 7.9418\n",
      "Count: 10176\n",
      "Epoch [637/750], Loss: 8.5132\n",
      "Count: 10192\n",
      "Epoch [638/750], Loss: 7.5083\n",
      "Count: 10208\n",
      "Epoch [639/750], Loss: 8.6052\n",
      "Count: 10224\n",
      "Epoch [640/750], Loss: 7.4304\n",
      "Count: 10240\n",
      "Epoch [641/750], Loss: 5.4820\n",
      "Count: 10256\n",
      "Epoch [642/750], Loss: 7.4885\n",
      "Count: 10272\n",
      "Epoch [643/750], Loss: 10.1435\n",
      "Count: 10288\n",
      "Epoch [644/750], Loss: 4.0673\n",
      "Count: 10304\n",
      "Epoch [645/750], Loss: 4.9083\n",
      "Count: 10320\n",
      "Epoch [646/750], Loss: 5.9548\n",
      "Count: 10336\n",
      "Epoch [647/750], Loss: 8.0909\n",
      "Count: 10352\n",
      "Epoch [648/750], Loss: 5.6677\n",
      "Count: 10368\n",
      "Epoch [649/750], Loss: 8.2954\n",
      "Count: 10384\n",
      "Epoch [650/750], Loss: 5.1436\n",
      "Count: 10400\n",
      "Epoch [651/750], Loss: 7.3500\n",
      "Count: 10416\n",
      "Epoch [652/750], Loss: 7.0163\n",
      "Count: 10432\n",
      "Epoch [653/750], Loss: 6.8427\n",
      "Count: 10448\n",
      "Epoch [654/750], Loss: 7.8247\n",
      "Count: 10464\n",
      "Epoch [655/750], Loss: 7.6469\n",
      "Count: 10480\n",
      "Epoch [656/750], Loss: 5.6804\n",
      "Count: 10496\n",
      "Epoch [657/750], Loss: 6.3100\n",
      "Count: 10512\n",
      "Epoch [658/750], Loss: 7.4965\n",
      "Count: 10528\n",
      "Epoch [659/750], Loss: 6.4351\n",
      "Count: 10544\n",
      "Epoch [660/750], Loss: 5.4129\n",
      "Count: 10560\n",
      "Epoch [661/750], Loss: 4.2539\n",
      "Count: 10576\n",
      "Epoch [662/750], Loss: 7.7680\n",
      "Count: 10592\n",
      "Epoch [663/750], Loss: 6.8625\n",
      "Count: 10608\n",
      "Epoch [664/750], Loss: 6.3132\n",
      "Count: 10624\n",
      "Epoch [665/750], Loss: 9.2935\n",
      "Count: 10640\n",
      "Epoch [666/750], Loss: 4.6280\n",
      "Count: 10656\n",
      "Epoch [667/750], Loss: 6.7203\n",
      "Count: 10672\n",
      "Epoch [668/750], Loss: 7.3227\n",
      "Count: 10688\n",
      "Epoch [669/750], Loss: 5.5188\n",
      "Count: 10704\n",
      "Epoch [670/750], Loss: 4.7306\n",
      "Count: 10720\n",
      "Epoch [671/750], Loss: 8.0067\n",
      "Count: 10736\n",
      "Epoch [672/750], Loss: 10.9123\n",
      "Count: 10752\n",
      "Epoch [673/750], Loss: 3.6359\n",
      "Count: 10768\n",
      "Epoch [674/750], Loss: 6.0725\n",
      "Count: 10784\n",
      "Epoch [675/750], Loss: 5.9976\n",
      "Count: 10800\n",
      "Epoch [676/750], Loss: 8.7920\n",
      "Count: 10816\n",
      "Epoch [677/750], Loss: 7.9946\n",
      "Count: 10832\n",
      "Epoch [678/750], Loss: 5.3526\n",
      "Count: 10848\n",
      "Epoch [679/750], Loss: 7.6883\n",
      "Count: 10864\n",
      "Epoch [680/750], Loss: 9.4511\n",
      "Count: 10880\n",
      "Epoch [681/750], Loss: 7.3479\n",
      "Count: 10896\n",
      "Epoch [682/750], Loss: 10.0970\n",
      "Count: 10912\n",
      "Epoch [683/750], Loss: 7.2477\n",
      "Count: 10928\n",
      "Epoch [684/750], Loss: 3.2119\n",
      "Count: 10944\n",
      "Epoch [685/750], Loss: 4.0753\n",
      "Count: 10960\n",
      "Epoch [686/750], Loss: 6.7971\n",
      "Count: 10976\n",
      "Epoch [687/750], Loss: 7.0391\n",
      "Count: 10992\n",
      "Epoch [688/750], Loss: 4.7110\n",
      "Count: 11008\n",
      "Epoch [689/750], Loss: 14.8160\n",
      "Count: 11024\n",
      "Epoch [690/750], Loss: 3.6598\n",
      "Count: 11040\n",
      "Epoch [691/750], Loss: 4.6628\n",
      "Count: 11056\n",
      "Epoch [692/750], Loss: 8.2979\n",
      "Count: 11072\n",
      "Epoch [693/750], Loss: 5.3081\n",
      "Count: 11088\n",
      "Epoch [694/750], Loss: 9.7676\n",
      "Count: 11104\n",
      "Epoch [695/750], Loss: 4.8730\n",
      "Count: 11120\n",
      "Epoch [696/750], Loss: 4.7121\n",
      "Count: 11136\n",
      "Epoch [697/750], Loss: 6.8162\n",
      "Count: 11152\n",
      "Epoch [698/750], Loss: 4.8729\n",
      "Count: 11168\n",
      "Epoch [699/750], Loss: 7.9565\n",
      "Count: 11184\n",
      "Epoch [700/750], Loss: 6.0844\n",
      "Count: 11200\n",
      "Epoch [701/750], Loss: 5.4910\n",
      "Count: 11216\n",
      "Epoch [702/750], Loss: 8.0520\n",
      "Count: 11232\n",
      "Epoch [703/750], Loss: 8.7841\n",
      "Count: 11248\n",
      "Epoch [704/750], Loss: 2.7265\n",
      "Count: 11264\n",
      "Epoch [705/750], Loss: 8.2953\n",
      "Count: 11280\n",
      "Epoch [706/750], Loss: 7.1208\n",
      "Count: 11296\n",
      "Epoch [707/750], Loss: 9.2262\n",
      "Count: 11312\n",
      "Epoch [708/750], Loss: 5.2802\n",
      "Count: 11328\n",
      "Epoch [709/750], Loss: 5.5056\n",
      "Count: 11344\n",
      "Epoch [710/750], Loss: 14.2415\n",
      "Count: 11360\n",
      "Epoch [711/750], Loss: 5.9492\n",
      "Count: 11376\n",
      "Epoch [712/750], Loss: 6.5900\n",
      "Count: 11392\n",
      "Epoch [713/750], Loss: 6.4857\n",
      "Count: 11408\n",
      "Epoch [714/750], Loss: 4.9234\n",
      "Count: 11424\n",
      "Epoch [715/750], Loss: 5.6811\n",
      "Count: 11440\n",
      "Epoch [716/750], Loss: 5.1810\n",
      "Count: 11456\n",
      "Epoch [717/750], Loss: 5.5830\n",
      "Count: 11472\n",
      "Epoch [718/750], Loss: 9.4869\n",
      "Count: 11488\n",
      "Epoch [719/750], Loss: 10.2446\n",
      "Count: 11504\n",
      "Epoch [720/750], Loss: 9.0025\n",
      "Count: 11520\n",
      "Epoch [721/750], Loss: 10.5380\n",
      "Count: 11536\n",
      "Epoch [722/750], Loss: 4.6607\n",
      "Count: 11552\n",
      "Epoch [723/750], Loss: 9.2368\n",
      "Count: 11568\n",
      "Epoch [724/750], Loss: 8.6798\n",
      "Count: 11584\n",
      "Epoch [725/750], Loss: 8.5558\n",
      "Count: 11600\n",
      "Epoch [726/750], Loss: 5.2112\n",
      "Count: 11616\n",
      "Epoch [727/750], Loss: 6.3884\n",
      "Count: 11632\n",
      "Epoch [728/750], Loss: 9.2398\n",
      "Count: 11648\n",
      "Epoch [729/750], Loss: 6.3877\n",
      "Count: 11664\n",
      "Epoch [730/750], Loss: 8.2237\n",
      "Count: 11680\n",
      "Epoch [731/750], Loss: 7.0547\n",
      "Count: 11696\n",
      "Epoch [732/750], Loss: 6.8988\n",
      "Count: 11712\n",
      "Epoch [733/750], Loss: 5.2126\n",
      "Count: 11728\n",
      "Epoch [734/750], Loss: 8.9237\n",
      "Count: 11744\n",
      "Epoch [735/750], Loss: 4.4258\n",
      "Count: 11760\n",
      "Epoch [736/750], Loss: 11.1702\n",
      "Count: 11776\n",
      "Epoch [737/750], Loss: 5.8887\n",
      "Count: 11792\n",
      "Epoch [738/750], Loss: 6.8243\n",
      "Count: 11808\n",
      "Epoch [739/750], Loss: 4.7658\n",
      "Count: 11824\n",
      "Epoch [740/750], Loss: 9.9933\n",
      "Count: 11840\n",
      "Epoch [741/750], Loss: 9.8278\n",
      "Count: 11856\n",
      "Epoch [742/750], Loss: 9.7436\n",
      "Count: 11872\n",
      "Epoch [743/750], Loss: 8.2599\n",
      "Count: 11888\n",
      "Epoch [744/750], Loss: 6.3677\n",
      "Count: 11904\n",
      "Epoch [745/750], Loss: 6.1992\n",
      "Count: 11920\n",
      "Epoch [746/750], Loss: 6.5309\n",
      "Count: 11936\n",
      "Epoch [747/750], Loss: 7.0227\n",
      "Count: 11952\n",
      "Epoch [748/750], Loss: 5.8256\n",
      "Count: 11968\n",
      "Epoch [749/750], Loss: 6.4863\n",
      "Count: 11984\n",
      "Epoch [750/750], Loss: 5.4687\n",
      "Count: 12000\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Train the model.\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(lstm.parameters())\n",
    "\n",
    "num_epochs = 750\n",
    "count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    lstm.train() # Set model to training mode\n",
    "    for inputs, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = lstm(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    print(f'Count: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation, Total Loss: 56.1223\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "lstm.eval() # Set model to eval mode\n",
    "total_loss = 0\n",
    "for inputs, labels in val_loader:\n",
    "    # Forward pass\n",
    "    outputs = lstm(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    total_loss += loss\n",
    "print(f'Evaluation, Total Loss: {total_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 2.6535, MAE: 2.0850, R²: 0.6190\n",
      "Testing RMSE: 3.1983, MAE: 2.5173, R²: 0.3950\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "y_train_pred = lstm(X_train_tensor).detach().numpy()\n",
    "y_test_pred = lstm(X_test_tensor).detach().numpy()\n",
    "\n",
    "# Get the diff values for evaluation.\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Training RMSE: {rmse_train:.4f}, MAE: {mae_train:.4f}, R²: {r2_train:.4f}')\n",
    "print(f'Testing RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}, R²: {r2_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Prediction              Player\n",
      "0     17.062727       Ja'Marr Chase\n",
      "1     15.240273    Justin Jefferson\n",
      "2     11.612712       George Kittle\n",
      "3     15.051228   Amon-Ra St. Brown\n",
      "4     12.320720        Brian Thomas\n",
      "..          ...                 ...\n",
      "163    4.739200      Elijah Higgins\n",
      "164    5.135512    Malik Washington\n",
      "165    5.101123        Derius Davis\n",
      "166    5.679075        Johnny Mundt\n",
      "167    4.327011  Darnell Washington\n",
      "\n",
      "[168 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Return results using model.\n",
    "predictions = lstm(torch.tensor(X_2024, dtype=torch.float32)).detach().numpy()\n",
    "predictions_df = pd.DataFrame(predictions, columns=['Prediction'])\n",
    "predictions_df['Player'] = player_names_2024\n",
    "print(f'{predictions_df}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new DataFrame to an Excel file\n",
    "file_path = 'results/simple_lstm_wr.xlsx'\n",
    "predictions_df.to_excel(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
