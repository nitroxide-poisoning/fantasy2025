{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEAR  Rk             Player   Tm FantPos  Age   G  GS  QBCmp  QBAtt  ...  \\\n",
      "4   2024   5      Ja'Marr Chase  CIN      WR   24  17  16      0      0  ...   \n",
      "11  2024  12   Justin Jefferson  MIN      WR   25  17  17      1      1  ...   \n",
      "14  2024  15      George Kittle  SFO      TE   31  15  15      0      0  ...   \n",
      "17  2024  18  Amon-Ra St. Brown  DET      WR   25  17  17      1      1  ...   \n",
      "18  2024  19       Brian Thomas  JAX      WR   22  17  16      0      0  ...   \n",
      "19  2024  20       Brock Bowers  LVR      TE   22  17  16      0      0  ...   \n",
      "22  2024  23     Terry McLaurin  WAS      WR   29  17  17      0      0  ...   \n",
      "23  2024  24       Trey McBride  ARI      TE   25  16  16      0      0  ...   \n",
      "25  2024  26       Drake London  ATL      WR   23  17  17      0      0  ...   \n",
      "27  2024  28        Jonnu Smith  MIA      TE   29  17   6      0      0  ...   \n",
      "\n",
      "      Y/R  RecTD  Fmb  FL  TotTD  14:00:00  2PP    PPR      PPR/G  Age^2  \n",
      "4   13.45     17    0   0     17       0.0  0.0  403.0  23.705882     26  \n",
      "11  14.88     10    1   0     10       0.0  0.0  317.5  18.676471     27  \n",
      "14  14.18      8    0   0      8       0.0  0.0  236.6  15.773333     29  \n",
      "17  10.98     12    1   1     12       0.0  0.0  316.2  18.600000     27  \n",
      "18  14.74     10    0   0     10       2.0  0.0  284.0  16.705882     20  \n",
      "19  10.66      5    0   0      5       0.0  0.0  262.7  15.452941     20  \n",
      "22  13.37     13    1   1     13       0.0  0.0  267.8  15.752941     31  \n",
      "23  10.32      2    0   0      4       0.0  0.0  249.8  15.612500     27  \n",
      "25  12.71      9    0   0      9       0.0  0.0  280.8  16.517647     21  \n",
      "27  10.05      8    2   1      8       0.0  0.0  222.3  13.076471     31  \n",
      "\n",
      "[10 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "pro_football_focus_data = 'data/pro_football_ref.xlsx'\n",
    "model_path = 'model_path/trained_model.pth'\n",
    "\n",
    "# Load and preprocess the pro football focus data.\n",
    "df = pd.read_excel(pro_football_focus_data)\n",
    "# Filter to only include wide receivers (WR)\n",
    "df = df[df['FantPos'].isin(['WR', 'TE'])].copy()\n",
    "df.replace([float('inf'), -float('inf')], 0, inplace=True)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Feature engineering.\n",
    "df.loc[:, 'PPR/G'] = df['PPR'] / df['G']\n",
    "df.loc[:, 'Age^2'] = df['Age']^2\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEAR  Rk   Tm FantPos  Age   G  GS  QBCmp  QBAtt  QBYds  ...    Y/R  \\\n",
      "4   2024   5  CIN      WR   24  17  16      0      0      0  ...  13.45   \n",
      "11  2024  12  MIN      WR   25  17  17      1      1     22  ...  14.88   \n",
      "14  2024  15  SFO      TE   31  15  15      0      0      0  ...  14.18   \n",
      "17  2024  18  DET      WR   25  17  17      1      1      7  ...  10.98   \n",
      "18  2024  19  JAX      WR   22  17  16      0      0      0  ...  14.74   \n",
      "19  2024  20  LVR      TE   22  17  16      0      0      0  ...  10.66   \n",
      "22  2024  23  WAS      WR   29  17  17      0      0      0  ...  13.37   \n",
      "23  2024  24  ARI      TE   25  16  16      0      0      0  ...  10.32   \n",
      "25  2024  26  ATL      WR   23  17  17      0      0      0  ...  12.71   \n",
      "27  2024  28  MIA      TE   29  17   6      0      0      0  ...  10.05   \n",
      "\n",
      "    RecTD  Fmb  FL  TotTD  14:00:00  2PP    PPR      PPR/G  Age^2  \n",
      "4      17    0   0     17       0.0  0.0  403.0  23.705882     26  \n",
      "11     10    1   0     10       0.0  0.0  317.5  18.676471     27  \n",
      "14      8    0   0      8       0.0  0.0  236.6  15.773333     29  \n",
      "17     12    1   1     12       0.0  0.0  316.2  18.600000     27  \n",
      "18     10    0   0     10       2.0  0.0  284.0  16.705882     20  \n",
      "19      5    0   0      5       0.0  0.0  262.7  15.452941     20  \n",
      "22     13    1   1     13       0.0  0.0  267.8  15.752941     31  \n",
      "23      2    0   0      4       0.0  0.0  249.8  15.612500     27  \n",
      "25      9    0   0      9       0.0  0.0  280.8  16.517647     21  \n",
      "27      8    2   1      8       0.0  0.0  222.3  13.076471     31  \n",
      "\n",
      "[10 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Copy the 2024 data into separate dataframe.\n",
    "df_2024 = df[df['YEAR'] == 2024].copy()\n",
    "player_names_2024 = df_2024['Player'].reset_index(drop=True)\n",
    "df_2024 = df_2024.drop(columns=['Player'])\n",
    "\n",
    "print(df_2024.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26133\n"
     ]
    }
   ],
   "source": [
    "# Shift to represent the following year's points per game\n",
    "df['NextYearPPR/G'] = df.groupby('Player')['PPR/G'].shift(-1)\n",
    "\n",
    "# Remove rows where the target is NaN (i.e., no following year data)\n",
    "df = df[df['NextYearPPR/G'].notna()]\n",
    "\n",
    "print(df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age  Age^2  Tgt  Rec  RecYds    Y/R      PPR/G\n",
      "423    27     25   87   51     717  14.06  11.746154\n",
      "1666   34     32   82   52     597  11.48   8.835714\n",
      "1537   27     25  149  104    1199  11.53  16.343750\n",
      "420    22     20  110   69     905  13.12  10.900000\n",
      "1381   27     25   60   30     505  16.83   8.258333\n",
      "...   ...    ...  ...  ...     ...    ...        ...\n",
      "167    24     26   71   47     548  11.66   7.781250\n",
      "233    25     27   86   59     494   8.37   7.457143\n",
      "626    23     21  146  106    1161  10.95  16.725000\n",
      "1034   29     31   69   45     556  12.36  15.244444\n",
      "222    32     34   58   40     390   9.75   5.352941\n",
      "\n",
      "[505 rows x 7 columns]\n",
      "423     10.629412\n",
      "1666     8.900000\n",
      "1537    16.256250\n",
      "420     10.505882\n",
      "1381     9.864286\n",
      "          ...    \n",
      "167      8.807692\n",
      "233     10.417647\n",
      "626     13.370588\n",
      "1034    15.318750\n",
      "222      7.766667\n",
      "Name: NextYearPPR/G, Length: 505, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define features and target.\n",
    "feature_names = ['Age', 'Age^2', 'Tgt', 'Rec', 'RecYds', 'Y/R', 'PPR/G']\n",
    "target = 'NextYearPPR/G'\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X = df[feature_names]\n",
    "y = df[target]\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "print(f'{X_train}')\n",
    "print(f'{y_train}')\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "X_2024 = df_2024[feature_names]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_2024 = scaler.transform(X_2024)\n",
    "\n",
    "# Ensure X_train, X_val, X_test, and X_2024 are correctly shaped for LSTM\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_val = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "X_2024 = X_2024.reshape(X_2024.shape[0], 1, X_2024.shape[1])\n",
    "\n",
    "# Check to see standardized data.\n",
    "#print(f'Size {y_train.size}')\n",
    "#print(f'Size {X_val.size}')\n",
    "#print(f'Size {y_val.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnclass.simple_nn import SimpleLSTM\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# Create SimpleLTSM.\n",
    "input_size = X_train.shape[2]\n",
    "hidden_size = 32\n",
    "output_size = 1\n",
    "lstm = SimpleLSTM(input_size, hidden_size, output_size)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 120.2884\n",
      "Count: 16\n",
      "Epoch [2/500], Loss: 120.0605\n",
      "Count: 32\n",
      "Epoch [3/500], Loss: 160.1648\n",
      "Count: 48\n",
      "Epoch [4/500], Loss: 147.5186\n",
      "Count: 64\n",
      "Epoch [5/500], Loss: 106.9168\n",
      "Count: 80\n",
      "Epoch [6/500], Loss: 126.3040\n",
      "Count: 96\n",
      "Epoch [7/500], Loss: 125.3114\n",
      "Count: 112\n",
      "Epoch [8/500], Loss: 131.1670\n",
      "Count: 128\n",
      "Epoch [9/500], Loss: 88.5249\n",
      "Count: 144\n",
      "Epoch [10/500], Loss: 112.5459\n",
      "Count: 160\n",
      "Epoch [11/500], Loss: 91.2063\n",
      "Count: 176\n",
      "Epoch [12/500], Loss: 93.6631\n",
      "Count: 192\n",
      "Epoch [13/500], Loss: 113.5240\n",
      "Count: 208\n",
      "Epoch [14/500], Loss: 92.7368\n",
      "Count: 224\n",
      "Epoch [15/500], Loss: 49.9315\n",
      "Count: 240\n",
      "Epoch [16/500], Loss: 79.9255\n",
      "Count: 256\n",
      "Epoch [17/500], Loss: 94.3937\n",
      "Count: 272\n",
      "Epoch [18/500], Loss: 49.3390\n",
      "Count: 288\n",
      "Epoch [19/500], Loss: 55.8594\n",
      "Count: 304\n",
      "Epoch [20/500], Loss: 36.7769\n",
      "Count: 320\n",
      "Epoch [21/500], Loss: 56.7124\n",
      "Count: 336\n",
      "Epoch [22/500], Loss: 40.2793\n",
      "Count: 352\n",
      "Epoch [23/500], Loss: 30.2496\n",
      "Count: 368\n",
      "Epoch [24/500], Loss: 33.3105\n",
      "Count: 384\n",
      "Epoch [25/500], Loss: 33.4724\n",
      "Count: 400\n",
      "Epoch [26/500], Loss: 26.3449\n",
      "Count: 416\n",
      "Epoch [27/500], Loss: 11.9859\n",
      "Count: 432\n",
      "Epoch [28/500], Loss: 18.0294\n",
      "Count: 448\n",
      "Epoch [29/500], Loss: 14.8789\n",
      "Count: 464\n",
      "Epoch [30/500], Loss: 18.9411\n",
      "Count: 480\n",
      "Epoch [31/500], Loss: 11.8732\n",
      "Count: 496\n",
      "Epoch [32/500], Loss: 10.7401\n",
      "Count: 512\n",
      "Epoch [33/500], Loss: 8.6116\n",
      "Count: 528\n",
      "Epoch [34/500], Loss: 21.6860\n",
      "Count: 544\n",
      "Epoch [35/500], Loss: 10.5976\n",
      "Count: 560\n",
      "Epoch [36/500], Loss: 8.0065\n",
      "Count: 576\n",
      "Epoch [37/500], Loss: 14.3928\n",
      "Count: 592\n",
      "Epoch [38/500], Loss: 7.9952\n",
      "Count: 608\n",
      "Epoch [39/500], Loss: 12.2236\n",
      "Count: 624\n",
      "Epoch [40/500], Loss: 10.5693\n",
      "Count: 640\n",
      "Epoch [41/500], Loss: 4.9078\n",
      "Count: 656\n",
      "Epoch [42/500], Loss: 10.4363\n",
      "Count: 672\n",
      "Epoch [43/500], Loss: 9.1097\n",
      "Count: 688\n",
      "Epoch [44/500], Loss: 9.0492\n",
      "Count: 704\n",
      "Epoch [45/500], Loss: 11.2134\n",
      "Count: 720\n",
      "Epoch [46/500], Loss: 6.3882\n",
      "Count: 736\n",
      "Epoch [47/500], Loss: 6.4625\n",
      "Count: 752\n",
      "Epoch [48/500], Loss: 8.2881\n",
      "Count: 768\n",
      "Epoch [49/500], Loss: 8.4989\n",
      "Count: 784\n",
      "Epoch [50/500], Loss: 9.1024\n",
      "Count: 800\n",
      "Epoch [51/500], Loss: 9.3554\n",
      "Count: 816\n",
      "Epoch [52/500], Loss: 9.8195\n",
      "Count: 832\n",
      "Epoch [53/500], Loss: 13.9098\n",
      "Count: 848\n",
      "Epoch [54/500], Loss: 5.4289\n",
      "Count: 864\n",
      "Epoch [55/500], Loss: 8.7349\n",
      "Count: 880\n",
      "Epoch [56/500], Loss: 10.3486\n",
      "Count: 896\n",
      "Epoch [57/500], Loss: 5.0418\n",
      "Count: 912\n",
      "Epoch [58/500], Loss: 7.5462\n",
      "Count: 928\n",
      "Epoch [59/500], Loss: 8.3770\n",
      "Count: 944\n",
      "Epoch [60/500], Loss: 9.2699\n",
      "Count: 960\n",
      "Epoch [61/500], Loss: 10.9967\n",
      "Count: 976\n",
      "Epoch [62/500], Loss: 9.3356\n",
      "Count: 992\n",
      "Epoch [63/500], Loss: 15.1230\n",
      "Count: 1008\n",
      "Epoch [64/500], Loss: 8.1662\n",
      "Count: 1024\n",
      "Epoch [65/500], Loss: 6.7259\n",
      "Count: 1040\n",
      "Epoch [66/500], Loss: 10.1203\n",
      "Count: 1056\n",
      "Epoch [67/500], Loss: 7.7064\n",
      "Count: 1072\n",
      "Epoch [68/500], Loss: 7.3786\n",
      "Count: 1088\n",
      "Epoch [69/500], Loss: 9.2436\n",
      "Count: 1104\n",
      "Epoch [70/500], Loss: 6.6866\n",
      "Count: 1120\n",
      "Epoch [71/500], Loss: 7.5803\n",
      "Count: 1136\n",
      "Epoch [72/500], Loss: 7.0260\n",
      "Count: 1152\n",
      "Epoch [73/500], Loss: 7.2044\n",
      "Count: 1168\n",
      "Epoch [74/500], Loss: 10.0112\n",
      "Count: 1184\n",
      "Epoch [75/500], Loss: 9.2661\n",
      "Count: 1200\n",
      "Epoch [76/500], Loss: 9.6825\n",
      "Count: 1216\n",
      "Epoch [77/500], Loss: 7.7380\n",
      "Count: 1232\n",
      "Epoch [78/500], Loss: 10.2121\n",
      "Count: 1248\n",
      "Epoch [79/500], Loss: 7.9020\n",
      "Count: 1264\n",
      "Epoch [80/500], Loss: 7.2795\n",
      "Count: 1280\n",
      "Epoch [81/500], Loss: 9.3388\n",
      "Count: 1296\n",
      "Epoch [82/500], Loss: 5.7509\n",
      "Count: 1312\n",
      "Epoch [83/500], Loss: 10.4098\n",
      "Count: 1328\n",
      "Epoch [84/500], Loss: 11.3903\n",
      "Count: 1344\n",
      "Epoch [85/500], Loss: 7.0863\n",
      "Count: 1360\n",
      "Epoch [86/500], Loss: 6.7731\n",
      "Count: 1376\n",
      "Epoch [87/500], Loss: 10.3318\n",
      "Count: 1392\n",
      "Epoch [88/500], Loss: 8.7128\n",
      "Count: 1408\n",
      "Epoch [89/500], Loss: 9.5235\n",
      "Count: 1424\n",
      "Epoch [90/500], Loss: 4.3075\n",
      "Count: 1440\n",
      "Epoch [91/500], Loss: 6.4321\n",
      "Count: 1456\n",
      "Epoch [92/500], Loss: 10.1058\n",
      "Count: 1472\n",
      "Epoch [93/500], Loss: 9.6475\n",
      "Count: 1488\n",
      "Epoch [94/500], Loss: 10.1300\n",
      "Count: 1504\n",
      "Epoch [95/500], Loss: 6.6066\n",
      "Count: 1520\n",
      "Epoch [96/500], Loss: 4.9808\n",
      "Count: 1536\n",
      "Epoch [97/500], Loss: 9.1842\n",
      "Count: 1552\n",
      "Epoch [98/500], Loss: 5.1791\n",
      "Count: 1568\n",
      "Epoch [99/500], Loss: 6.4144\n",
      "Count: 1584\n",
      "Epoch [100/500], Loss: 7.2674\n",
      "Count: 1600\n",
      "Epoch [101/500], Loss: 11.3047\n",
      "Count: 1616\n",
      "Epoch [102/500], Loss: 5.6635\n",
      "Count: 1632\n",
      "Epoch [103/500], Loss: 6.2898\n",
      "Count: 1648\n",
      "Epoch [104/500], Loss: 10.5993\n",
      "Count: 1664\n",
      "Epoch [105/500], Loss: 6.8945\n",
      "Count: 1680\n",
      "Epoch [106/500], Loss: 6.0113\n",
      "Count: 1696\n",
      "Epoch [107/500], Loss: 9.1545\n",
      "Count: 1712\n",
      "Epoch [108/500], Loss: 7.0737\n",
      "Count: 1728\n",
      "Epoch [109/500], Loss: 12.3769\n",
      "Count: 1744\n",
      "Epoch [110/500], Loss: 5.0555\n",
      "Count: 1760\n",
      "Epoch [111/500], Loss: 7.4313\n",
      "Count: 1776\n",
      "Epoch [112/500], Loss: 7.7792\n",
      "Count: 1792\n",
      "Epoch [113/500], Loss: 7.2593\n",
      "Count: 1808\n",
      "Epoch [114/500], Loss: 4.2686\n",
      "Count: 1824\n",
      "Epoch [115/500], Loss: 7.3076\n",
      "Count: 1840\n",
      "Epoch [116/500], Loss: 5.8532\n",
      "Count: 1856\n",
      "Epoch [117/500], Loss: 14.0098\n",
      "Count: 1872\n",
      "Epoch [118/500], Loss: 8.8299\n",
      "Count: 1888\n",
      "Epoch [119/500], Loss: 10.3154\n",
      "Count: 1904\n",
      "Epoch [120/500], Loss: 6.0095\n",
      "Count: 1920\n",
      "Epoch [121/500], Loss: 11.9017\n",
      "Count: 1936\n",
      "Epoch [122/500], Loss: 3.7095\n",
      "Count: 1952\n",
      "Epoch [123/500], Loss: 7.0534\n",
      "Count: 1968\n",
      "Epoch [124/500], Loss: 7.9180\n",
      "Count: 1984\n",
      "Epoch [125/500], Loss: 5.3326\n",
      "Count: 2000\n",
      "Epoch [126/500], Loss: 7.5833\n",
      "Count: 2016\n",
      "Epoch [127/500], Loss: 10.7672\n",
      "Count: 2032\n",
      "Epoch [128/500], Loss: 5.3736\n",
      "Count: 2048\n",
      "Epoch [129/500], Loss: 10.6159\n",
      "Count: 2064\n",
      "Epoch [130/500], Loss: 11.1367\n",
      "Count: 2080\n",
      "Epoch [131/500], Loss: 9.7428\n",
      "Count: 2096\n",
      "Epoch [132/500], Loss: 7.4126\n",
      "Count: 2112\n",
      "Epoch [133/500], Loss: 12.3171\n",
      "Count: 2128\n",
      "Epoch [134/500], Loss: 11.2730\n",
      "Count: 2144\n",
      "Epoch [135/500], Loss: 7.5323\n",
      "Count: 2160\n",
      "Epoch [136/500], Loss: 7.8073\n",
      "Count: 2176\n",
      "Epoch [137/500], Loss: 5.0121\n",
      "Count: 2192\n",
      "Epoch [138/500], Loss: 8.3270\n",
      "Count: 2208\n",
      "Epoch [139/500], Loss: 7.2988\n",
      "Count: 2224\n",
      "Epoch [140/500], Loss: 8.3020\n",
      "Count: 2240\n",
      "Epoch [141/500], Loss: 11.5678\n",
      "Count: 2256\n",
      "Epoch [142/500], Loss: 6.8787\n",
      "Count: 2272\n",
      "Epoch [143/500], Loss: 7.0231\n",
      "Count: 2288\n",
      "Epoch [144/500], Loss: 12.4925\n",
      "Count: 2304\n",
      "Epoch [145/500], Loss: 9.7379\n",
      "Count: 2320\n",
      "Epoch [146/500], Loss: 3.9454\n",
      "Count: 2336\n",
      "Epoch [147/500], Loss: 12.8092\n",
      "Count: 2352\n",
      "Epoch [148/500], Loss: 7.2591\n",
      "Count: 2368\n",
      "Epoch [149/500], Loss: 11.5928\n",
      "Count: 2384\n",
      "Epoch [150/500], Loss: 9.9776\n",
      "Count: 2400\n",
      "Epoch [151/500], Loss: 8.9925\n",
      "Count: 2416\n",
      "Epoch [152/500], Loss: 9.0501\n",
      "Count: 2432\n",
      "Epoch [153/500], Loss: 8.8973\n",
      "Count: 2448\n",
      "Epoch [154/500], Loss: 9.0030\n",
      "Count: 2464\n",
      "Epoch [155/500], Loss: 5.8524\n",
      "Count: 2480\n",
      "Epoch [156/500], Loss: 5.2993\n",
      "Count: 2496\n",
      "Epoch [157/500], Loss: 7.1237\n",
      "Count: 2512\n",
      "Epoch [158/500], Loss: 4.3630\n",
      "Count: 2528\n",
      "Epoch [159/500], Loss: 5.6628\n",
      "Count: 2544\n",
      "Epoch [160/500], Loss: 11.5598\n",
      "Count: 2560\n",
      "Epoch [161/500], Loss: 7.8650\n",
      "Count: 2576\n",
      "Epoch [162/500], Loss: 5.9821\n",
      "Count: 2592\n",
      "Epoch [163/500], Loss: 8.0386\n",
      "Count: 2608\n",
      "Epoch [164/500], Loss: 5.0962\n",
      "Count: 2624\n",
      "Epoch [165/500], Loss: 6.6701\n",
      "Count: 2640\n",
      "Epoch [166/500], Loss: 7.4777\n",
      "Count: 2656\n",
      "Epoch [167/500], Loss: 4.1716\n",
      "Count: 2672\n",
      "Epoch [168/500], Loss: 10.0839\n",
      "Count: 2688\n",
      "Epoch [169/500], Loss: 9.1282\n",
      "Count: 2704\n",
      "Epoch [170/500], Loss: 9.5618\n",
      "Count: 2720\n",
      "Epoch [171/500], Loss: 8.1106\n",
      "Count: 2736\n",
      "Epoch [172/500], Loss: 6.0637\n",
      "Count: 2752\n",
      "Epoch [173/500], Loss: 9.3868\n",
      "Count: 2768\n",
      "Epoch [174/500], Loss: 7.7655\n",
      "Count: 2784\n",
      "Epoch [175/500], Loss: 7.8968\n",
      "Count: 2800\n",
      "Epoch [176/500], Loss: 7.0150\n",
      "Count: 2816\n",
      "Epoch [177/500], Loss: 6.0945\n",
      "Count: 2832\n",
      "Epoch [178/500], Loss: 8.0090\n",
      "Count: 2848\n",
      "Epoch [179/500], Loss: 5.6773\n",
      "Count: 2864\n",
      "Epoch [180/500], Loss: 4.4172\n",
      "Count: 2880\n",
      "Epoch [181/500], Loss: 4.8128\n",
      "Count: 2896\n",
      "Epoch [182/500], Loss: 8.1909\n",
      "Count: 2912\n",
      "Epoch [183/500], Loss: 3.6764\n",
      "Count: 2928\n",
      "Epoch [184/500], Loss: 8.7535\n",
      "Count: 2944\n",
      "Epoch [185/500], Loss: 4.8288\n",
      "Count: 2960\n",
      "Epoch [186/500], Loss: 4.6172\n",
      "Count: 2976\n",
      "Epoch [187/500], Loss: 4.0942\n",
      "Count: 2992\n",
      "Epoch [188/500], Loss: 6.7529\n",
      "Count: 3008\n",
      "Epoch [189/500], Loss: 6.7226\n",
      "Count: 3024\n",
      "Epoch [190/500], Loss: 13.5251\n",
      "Count: 3040\n",
      "Epoch [191/500], Loss: 4.9416\n",
      "Count: 3056\n",
      "Epoch [192/500], Loss: 6.5819\n",
      "Count: 3072\n",
      "Epoch [193/500], Loss: 5.3620\n",
      "Count: 3088\n",
      "Epoch [194/500], Loss: 6.3516\n",
      "Count: 3104\n",
      "Epoch [195/500], Loss: 8.5403\n",
      "Count: 3120\n",
      "Epoch [196/500], Loss: 6.6507\n",
      "Count: 3136\n",
      "Epoch [197/500], Loss: 9.1211\n",
      "Count: 3152\n",
      "Epoch [198/500], Loss: 9.8748\n",
      "Count: 3168\n",
      "Epoch [199/500], Loss: 4.1233\n",
      "Count: 3184\n",
      "Epoch [200/500], Loss: 9.1287\n",
      "Count: 3200\n",
      "Epoch [201/500], Loss: 8.4755\n",
      "Count: 3216\n",
      "Epoch [202/500], Loss: 12.9119\n",
      "Count: 3232\n",
      "Epoch [203/500], Loss: 5.5619\n",
      "Count: 3248\n",
      "Epoch [204/500], Loss: 4.2232\n",
      "Count: 3264\n",
      "Epoch [205/500], Loss: 8.4205\n",
      "Count: 3280\n",
      "Epoch [206/500], Loss: 5.8951\n",
      "Count: 3296\n",
      "Epoch [207/500], Loss: 9.8667\n",
      "Count: 3312\n",
      "Epoch [208/500], Loss: 9.6921\n",
      "Count: 3328\n",
      "Epoch [209/500], Loss: 7.1704\n",
      "Count: 3344\n",
      "Epoch [210/500], Loss: 6.6732\n",
      "Count: 3360\n",
      "Epoch [211/500], Loss: 11.5053\n",
      "Count: 3376\n",
      "Epoch [212/500], Loss: 6.3648\n",
      "Count: 3392\n",
      "Epoch [213/500], Loss: 3.6241\n",
      "Count: 3408\n",
      "Epoch [214/500], Loss: 5.7838\n",
      "Count: 3424\n",
      "Epoch [215/500], Loss: 9.2131\n",
      "Count: 3440\n",
      "Epoch [216/500], Loss: 5.4247\n",
      "Count: 3456\n",
      "Epoch [217/500], Loss: 5.8570\n",
      "Count: 3472\n",
      "Epoch [218/500], Loss: 5.9271\n",
      "Count: 3488\n",
      "Epoch [219/500], Loss: 3.7223\n",
      "Count: 3504\n",
      "Epoch [220/500], Loss: 4.7449\n",
      "Count: 3520\n",
      "Epoch [221/500], Loss: 5.9796\n",
      "Count: 3536\n",
      "Epoch [222/500], Loss: 7.4336\n",
      "Count: 3552\n",
      "Epoch [223/500], Loss: 6.2112\n",
      "Count: 3568\n",
      "Epoch [224/500], Loss: 7.0121\n",
      "Count: 3584\n",
      "Epoch [225/500], Loss: 6.6806\n",
      "Count: 3600\n",
      "Epoch [226/500], Loss: 7.1529\n",
      "Count: 3616\n",
      "Epoch [227/500], Loss: 11.1256\n",
      "Count: 3632\n",
      "Epoch [228/500], Loss: 8.4963\n",
      "Count: 3648\n",
      "Epoch [229/500], Loss: 6.8525\n",
      "Count: 3664\n",
      "Epoch [230/500], Loss: 3.6260\n",
      "Count: 3680\n",
      "Epoch [231/500], Loss: 4.9852\n",
      "Count: 3696\n",
      "Epoch [232/500], Loss: 9.0153\n",
      "Count: 3712\n",
      "Epoch [233/500], Loss: 6.7020\n",
      "Count: 3728\n",
      "Epoch [234/500], Loss: 9.7267\n",
      "Count: 3744\n",
      "Epoch [235/500], Loss: 8.1423\n",
      "Count: 3760\n",
      "Epoch [236/500], Loss: 10.8932\n",
      "Count: 3776\n",
      "Epoch [237/500], Loss: 5.5306\n",
      "Count: 3792\n",
      "Epoch [238/500], Loss: 10.1187\n",
      "Count: 3808\n",
      "Epoch [239/500], Loss: 6.8452\n",
      "Count: 3824\n",
      "Epoch [240/500], Loss: 7.5374\n",
      "Count: 3840\n",
      "Epoch [241/500], Loss: 7.4918\n",
      "Count: 3856\n",
      "Epoch [242/500], Loss: 10.7197\n",
      "Count: 3872\n",
      "Epoch [243/500], Loss: 5.9967\n",
      "Count: 3888\n",
      "Epoch [244/500], Loss: 8.7348\n",
      "Count: 3904\n",
      "Epoch [245/500], Loss: 8.2612\n",
      "Count: 3920\n",
      "Epoch [246/500], Loss: 7.3438\n",
      "Count: 3936\n",
      "Epoch [247/500], Loss: 10.7985\n",
      "Count: 3952\n",
      "Epoch [248/500], Loss: 5.7906\n",
      "Count: 3968\n",
      "Epoch [249/500], Loss: 6.0064\n",
      "Count: 3984\n",
      "Epoch [250/500], Loss: 9.1469\n",
      "Count: 4000\n",
      "Epoch [251/500], Loss: 4.7594\n",
      "Count: 4016\n",
      "Epoch [252/500], Loss: 8.2122\n",
      "Count: 4032\n",
      "Epoch [253/500], Loss: 6.3195\n",
      "Count: 4048\n",
      "Epoch [254/500], Loss: 7.6692\n",
      "Count: 4064\n",
      "Epoch [255/500], Loss: 6.3799\n",
      "Count: 4080\n",
      "Epoch [256/500], Loss: 3.6062\n",
      "Count: 4096\n",
      "Epoch [257/500], Loss: 4.5460\n",
      "Count: 4112\n",
      "Epoch [258/500], Loss: 6.7628\n",
      "Count: 4128\n",
      "Epoch [259/500], Loss: 5.3862\n",
      "Count: 4144\n",
      "Epoch [260/500], Loss: 7.2588\n",
      "Count: 4160\n",
      "Epoch [261/500], Loss: 6.2813\n",
      "Count: 4176\n",
      "Epoch [262/500], Loss: 8.6869\n",
      "Count: 4192\n",
      "Epoch [263/500], Loss: 4.3834\n",
      "Count: 4208\n",
      "Epoch [264/500], Loss: 6.7691\n",
      "Count: 4224\n",
      "Epoch [265/500], Loss: 5.6063\n",
      "Count: 4240\n",
      "Epoch [266/500], Loss: 5.2587\n",
      "Count: 4256\n",
      "Epoch [267/500], Loss: 9.0448\n",
      "Count: 4272\n",
      "Epoch [268/500], Loss: 4.6450\n",
      "Count: 4288\n",
      "Epoch [269/500], Loss: 10.7873\n",
      "Count: 4304\n",
      "Epoch [270/500], Loss: 6.5310\n",
      "Count: 4320\n",
      "Epoch [271/500], Loss: 14.6559\n",
      "Count: 4336\n",
      "Epoch [272/500], Loss: 6.6444\n",
      "Count: 4352\n",
      "Epoch [273/500], Loss: 4.0796\n",
      "Count: 4368\n",
      "Epoch [274/500], Loss: 13.1160\n",
      "Count: 4384\n",
      "Epoch [275/500], Loss: 8.0406\n",
      "Count: 4400\n",
      "Epoch [276/500], Loss: 5.4293\n",
      "Count: 4416\n",
      "Epoch [277/500], Loss: 3.6851\n",
      "Count: 4432\n",
      "Epoch [278/500], Loss: 6.2074\n",
      "Count: 4448\n",
      "Epoch [279/500], Loss: 5.8039\n",
      "Count: 4464\n",
      "Epoch [280/500], Loss: 7.5834\n",
      "Count: 4480\n",
      "Epoch [281/500], Loss: 11.3455\n",
      "Count: 4496\n",
      "Epoch [282/500], Loss: 4.9930\n",
      "Count: 4512\n",
      "Epoch [283/500], Loss: 7.4965\n",
      "Count: 4528\n",
      "Epoch [284/500], Loss: 4.4457\n",
      "Count: 4544\n",
      "Epoch [285/500], Loss: 6.9325\n",
      "Count: 4560\n",
      "Epoch [286/500], Loss: 5.6181\n",
      "Count: 4576\n",
      "Epoch [287/500], Loss: 9.8590\n",
      "Count: 4592\n",
      "Epoch [288/500], Loss: 9.6389\n",
      "Count: 4608\n",
      "Epoch [289/500], Loss: 5.8121\n",
      "Count: 4624\n",
      "Epoch [290/500], Loss: 4.3550\n",
      "Count: 4640\n",
      "Epoch [291/500], Loss: 7.9023\n",
      "Count: 4656\n",
      "Epoch [292/500], Loss: 4.7759\n",
      "Count: 4672\n",
      "Epoch [293/500], Loss: 10.3526\n",
      "Count: 4688\n",
      "Epoch [294/500], Loss: 5.6677\n",
      "Count: 4704\n",
      "Epoch [295/500], Loss: 6.6062\n",
      "Count: 4720\n",
      "Epoch [296/500], Loss: 8.6592\n",
      "Count: 4736\n",
      "Epoch [297/500], Loss: 8.5619\n",
      "Count: 4752\n",
      "Epoch [298/500], Loss: 11.3062\n",
      "Count: 4768\n",
      "Epoch [299/500], Loss: 7.2768\n",
      "Count: 4784\n",
      "Epoch [300/500], Loss: 4.1631\n",
      "Count: 4800\n",
      "Epoch [301/500], Loss: 8.8531\n",
      "Count: 4816\n",
      "Epoch [302/500], Loss: 4.3076\n",
      "Count: 4832\n",
      "Epoch [303/500], Loss: 4.1595\n",
      "Count: 4848\n",
      "Epoch [304/500], Loss: 5.9753\n",
      "Count: 4864\n",
      "Epoch [305/500], Loss: 8.1491\n",
      "Count: 4880\n",
      "Epoch [306/500], Loss: 9.6160\n",
      "Count: 4896\n",
      "Epoch [307/500], Loss: 6.1803\n",
      "Count: 4912\n",
      "Epoch [308/500], Loss: 5.4577\n",
      "Count: 4928\n",
      "Epoch [309/500], Loss: 11.0632\n",
      "Count: 4944\n",
      "Epoch [310/500], Loss: 9.5228\n",
      "Count: 4960\n",
      "Epoch [311/500], Loss: 5.7946\n",
      "Count: 4976\n",
      "Epoch [312/500], Loss: 4.9380\n",
      "Count: 4992\n",
      "Epoch [313/500], Loss: 9.5234\n",
      "Count: 5008\n",
      "Epoch [314/500], Loss: 5.9665\n",
      "Count: 5024\n",
      "Epoch [315/500], Loss: 9.5604\n",
      "Count: 5040\n",
      "Epoch [316/500], Loss: 11.1823\n",
      "Count: 5056\n",
      "Epoch [317/500], Loss: 3.6772\n",
      "Count: 5072\n",
      "Epoch [318/500], Loss: 7.9363\n",
      "Count: 5088\n",
      "Epoch [319/500], Loss: 7.4058\n",
      "Count: 5104\n",
      "Epoch [320/500], Loss: 7.8171\n",
      "Count: 5120\n",
      "Epoch [321/500], Loss: 5.7402\n",
      "Count: 5136\n",
      "Epoch [322/500], Loss: 7.0131\n",
      "Count: 5152\n",
      "Epoch [323/500], Loss: 8.9273\n",
      "Count: 5168\n",
      "Epoch [324/500], Loss: 12.3427\n",
      "Count: 5184\n",
      "Epoch [325/500], Loss: 5.6556\n",
      "Count: 5200\n",
      "Epoch [326/500], Loss: 4.0153\n",
      "Count: 5216\n",
      "Epoch [327/500], Loss: 5.3947\n",
      "Count: 5232\n",
      "Epoch [328/500], Loss: 7.9325\n",
      "Count: 5248\n",
      "Epoch [329/500], Loss: 3.9282\n",
      "Count: 5264\n",
      "Epoch [330/500], Loss: 6.0625\n",
      "Count: 5280\n",
      "Epoch [331/500], Loss: 4.9005\n",
      "Count: 5296\n",
      "Epoch [332/500], Loss: 12.7079\n",
      "Count: 5312\n",
      "Epoch [333/500], Loss: 6.1097\n",
      "Count: 5328\n",
      "Epoch [334/500], Loss: 11.0124\n",
      "Count: 5344\n",
      "Epoch [335/500], Loss: 4.0964\n",
      "Count: 5360\n",
      "Epoch [336/500], Loss: 6.6224\n",
      "Count: 5376\n",
      "Epoch [337/500], Loss: 6.9355\n",
      "Count: 5392\n",
      "Epoch [338/500], Loss: 7.3733\n",
      "Count: 5408\n",
      "Epoch [339/500], Loss: 4.8542\n",
      "Count: 5424\n",
      "Epoch [340/500], Loss: 9.8185\n",
      "Count: 5440\n",
      "Epoch [341/500], Loss: 5.1128\n",
      "Count: 5456\n",
      "Epoch [342/500], Loss: 8.1584\n",
      "Count: 5472\n",
      "Epoch [343/500], Loss: 6.1307\n",
      "Count: 5488\n",
      "Epoch [344/500], Loss: 6.0138\n",
      "Count: 5504\n",
      "Epoch [345/500], Loss: 9.4681\n",
      "Count: 5520\n",
      "Epoch [346/500], Loss: 7.5744\n",
      "Count: 5536\n",
      "Epoch [347/500], Loss: 5.3637\n",
      "Count: 5552\n",
      "Epoch [348/500], Loss: 7.0957\n",
      "Count: 5568\n",
      "Epoch [349/500], Loss: 9.3840\n",
      "Count: 5584\n",
      "Epoch [350/500], Loss: 2.1480\n",
      "Count: 5600\n",
      "Epoch [351/500], Loss: 6.8387\n",
      "Count: 5616\n",
      "Epoch [352/500], Loss: 7.8039\n",
      "Count: 5632\n",
      "Epoch [353/500], Loss: 9.4173\n",
      "Count: 5648\n",
      "Epoch [354/500], Loss: 6.3637\n",
      "Count: 5664\n",
      "Epoch [355/500], Loss: 6.2554\n",
      "Count: 5680\n",
      "Epoch [356/500], Loss: 8.5152\n",
      "Count: 5696\n",
      "Epoch [357/500], Loss: 5.4751\n",
      "Count: 5712\n",
      "Epoch [358/500], Loss: 12.3749\n",
      "Count: 5728\n",
      "Epoch [359/500], Loss: 9.1400\n",
      "Count: 5744\n",
      "Epoch [360/500], Loss: 2.5848\n",
      "Count: 5760\n",
      "Epoch [361/500], Loss: 6.0499\n",
      "Count: 5776\n",
      "Epoch [362/500], Loss: 4.2824\n",
      "Count: 5792\n",
      "Epoch [363/500], Loss: 4.7592\n",
      "Count: 5808\n",
      "Epoch [364/500], Loss: 5.2297\n",
      "Count: 5824\n",
      "Epoch [365/500], Loss: 5.0275\n",
      "Count: 5840\n",
      "Epoch [366/500], Loss: 5.6198\n",
      "Count: 5856\n",
      "Epoch [367/500], Loss: 5.5860\n",
      "Count: 5872\n",
      "Epoch [368/500], Loss: 10.9827\n",
      "Count: 5888\n",
      "Epoch [369/500], Loss: 5.9988\n",
      "Count: 5904\n",
      "Epoch [370/500], Loss: 5.5083\n",
      "Count: 5920\n",
      "Epoch [371/500], Loss: 8.9389\n",
      "Count: 5936\n",
      "Epoch [372/500], Loss: 10.0524\n",
      "Count: 5952\n",
      "Epoch [373/500], Loss: 9.3296\n",
      "Count: 5968\n",
      "Epoch [374/500], Loss: 5.3013\n",
      "Count: 5984\n",
      "Epoch [375/500], Loss: 5.3337\n",
      "Count: 6000\n",
      "Epoch [376/500], Loss: 6.9800\n",
      "Count: 6016\n",
      "Epoch [377/500], Loss: 10.8418\n",
      "Count: 6032\n",
      "Epoch [378/500], Loss: 6.8503\n",
      "Count: 6048\n",
      "Epoch [379/500], Loss: 7.6539\n",
      "Count: 6064\n",
      "Epoch [380/500], Loss: 4.3610\n",
      "Count: 6080\n",
      "Epoch [381/500], Loss: 7.0359\n",
      "Count: 6096\n",
      "Epoch [382/500], Loss: 4.6327\n",
      "Count: 6112\n",
      "Epoch [383/500], Loss: 7.7881\n",
      "Count: 6128\n",
      "Epoch [384/500], Loss: 8.7484\n",
      "Count: 6144\n",
      "Epoch [385/500], Loss: 5.9139\n",
      "Count: 6160\n",
      "Epoch [386/500], Loss: 10.7956\n",
      "Count: 6176\n",
      "Epoch [387/500], Loss: 5.9534\n",
      "Count: 6192\n",
      "Epoch [388/500], Loss: 6.3650\n",
      "Count: 6208\n",
      "Epoch [389/500], Loss: 7.7454\n",
      "Count: 6224\n",
      "Epoch [390/500], Loss: 10.0605\n",
      "Count: 6240\n",
      "Epoch [391/500], Loss: 7.1963\n",
      "Count: 6256\n",
      "Epoch [392/500], Loss: 8.0262\n",
      "Count: 6272\n",
      "Epoch [393/500], Loss: 7.7422\n",
      "Count: 6288\n",
      "Epoch [394/500], Loss: 10.8987\n",
      "Count: 6304\n",
      "Epoch [395/500], Loss: 9.4081\n",
      "Count: 6320\n",
      "Epoch [396/500], Loss: 7.9719\n",
      "Count: 6336\n",
      "Epoch [397/500], Loss: 6.7236\n",
      "Count: 6352\n",
      "Epoch [398/500], Loss: 8.0904\n",
      "Count: 6368\n",
      "Epoch [399/500], Loss: 5.8846\n",
      "Count: 6384\n",
      "Epoch [400/500], Loss: 6.0705\n",
      "Count: 6400\n",
      "Epoch [401/500], Loss: 4.0545\n",
      "Count: 6416\n",
      "Epoch [402/500], Loss: 5.4278\n",
      "Count: 6432\n",
      "Epoch [403/500], Loss: 6.3192\n",
      "Count: 6448\n",
      "Epoch [404/500], Loss: 6.5095\n",
      "Count: 6464\n",
      "Epoch [405/500], Loss: 6.3323\n",
      "Count: 6480\n",
      "Epoch [406/500], Loss: 5.0661\n",
      "Count: 6496\n",
      "Epoch [407/500], Loss: 6.8320\n",
      "Count: 6512\n",
      "Epoch [408/500], Loss: 5.6825\n",
      "Count: 6528\n",
      "Epoch [409/500], Loss: 4.1398\n",
      "Count: 6544\n",
      "Epoch [410/500], Loss: 6.7345\n",
      "Count: 6560\n",
      "Epoch [411/500], Loss: 6.7996\n",
      "Count: 6576\n",
      "Epoch [412/500], Loss: 6.9653\n",
      "Count: 6592\n",
      "Epoch [413/500], Loss: 6.5005\n",
      "Count: 6608\n",
      "Epoch [414/500], Loss: 6.2182\n",
      "Count: 6624\n",
      "Epoch [415/500], Loss: 6.4385\n",
      "Count: 6640\n",
      "Epoch [416/500], Loss: 8.9699\n",
      "Count: 6656\n",
      "Epoch [417/500], Loss: 5.3467\n",
      "Count: 6672\n",
      "Epoch [418/500], Loss: 6.1305\n",
      "Count: 6688\n",
      "Epoch [419/500], Loss: 9.1935\n",
      "Count: 6704\n",
      "Epoch [420/500], Loss: 7.4800\n",
      "Count: 6720\n",
      "Epoch [421/500], Loss: 6.4615\n",
      "Count: 6736\n",
      "Epoch [422/500], Loss: 6.4324\n",
      "Count: 6752\n",
      "Epoch [423/500], Loss: 4.4582\n",
      "Count: 6768\n",
      "Epoch [424/500], Loss: 6.4051\n",
      "Count: 6784\n",
      "Epoch [425/500], Loss: 4.0319\n",
      "Count: 6800\n",
      "Epoch [426/500], Loss: 7.8990\n",
      "Count: 6816\n",
      "Epoch [427/500], Loss: 3.8289\n",
      "Count: 6832\n",
      "Epoch [428/500], Loss: 6.0607\n",
      "Count: 6848\n",
      "Epoch [429/500], Loss: 10.8543\n",
      "Count: 6864\n",
      "Epoch [430/500], Loss: 8.0205\n",
      "Count: 6880\n",
      "Epoch [431/500], Loss: 4.1593\n",
      "Count: 6896\n",
      "Epoch [432/500], Loss: 5.5406\n",
      "Count: 6912\n",
      "Epoch [433/500], Loss: 7.0481\n",
      "Count: 6928\n",
      "Epoch [434/500], Loss: 8.7133\n",
      "Count: 6944\n",
      "Epoch [435/500], Loss: 6.4401\n",
      "Count: 6960\n",
      "Epoch [436/500], Loss: 7.2301\n",
      "Count: 6976\n",
      "Epoch [437/500], Loss: 6.8027\n",
      "Count: 6992\n",
      "Epoch [438/500], Loss: 5.9929\n",
      "Count: 7008\n",
      "Epoch [439/500], Loss: 7.0813\n",
      "Count: 7024\n",
      "Epoch [440/500], Loss: 6.7258\n",
      "Count: 7040\n",
      "Epoch [441/500], Loss: 5.5223\n",
      "Count: 7056\n",
      "Epoch [442/500], Loss: 5.8412\n",
      "Count: 7072\n",
      "Epoch [443/500], Loss: 4.4317\n",
      "Count: 7088\n",
      "Epoch [444/500], Loss: 8.3593\n",
      "Count: 7104\n",
      "Epoch [445/500], Loss: 6.5024\n",
      "Count: 7120\n",
      "Epoch [446/500], Loss: 6.6395\n",
      "Count: 7136\n",
      "Epoch [447/500], Loss: 6.3491\n",
      "Count: 7152\n",
      "Epoch [448/500], Loss: 5.0900\n",
      "Count: 7168\n",
      "Epoch [449/500], Loss: 6.4824\n",
      "Count: 7184\n",
      "Epoch [450/500], Loss: 10.0354\n",
      "Count: 7200\n",
      "Epoch [451/500], Loss: 8.6647\n",
      "Count: 7216\n",
      "Epoch [452/500], Loss: 5.8894\n",
      "Count: 7232\n",
      "Epoch [453/500], Loss: 4.6728\n",
      "Count: 7248\n",
      "Epoch [454/500], Loss: 5.8512\n",
      "Count: 7264\n",
      "Epoch [455/500], Loss: 5.9712\n",
      "Count: 7280\n",
      "Epoch [456/500], Loss: 5.4780\n",
      "Count: 7296\n",
      "Epoch [457/500], Loss: 5.0453\n",
      "Count: 7312\n",
      "Epoch [458/500], Loss: 9.1712\n",
      "Count: 7328\n",
      "Epoch [459/500], Loss: 5.6447\n",
      "Count: 7344\n",
      "Epoch [460/500], Loss: 6.6602\n",
      "Count: 7360\n",
      "Epoch [461/500], Loss: 4.1300\n",
      "Count: 7376\n",
      "Epoch [462/500], Loss: 11.6446\n",
      "Count: 7392\n",
      "Epoch [463/500], Loss: 8.9027\n",
      "Count: 7408\n",
      "Epoch [464/500], Loss: 5.9346\n",
      "Count: 7424\n",
      "Epoch [465/500], Loss: 5.7196\n",
      "Count: 7440\n",
      "Epoch [466/500], Loss: 9.7046\n",
      "Count: 7456\n",
      "Epoch [467/500], Loss: 6.2795\n",
      "Count: 7472\n",
      "Epoch [468/500], Loss: 11.0622\n",
      "Count: 7488\n",
      "Epoch [469/500], Loss: 7.1241\n",
      "Count: 7504\n",
      "Epoch [470/500], Loss: 4.7221\n",
      "Count: 7520\n",
      "Epoch [471/500], Loss: 9.7117\n",
      "Count: 7536\n",
      "Epoch [472/500], Loss: 2.0048\n",
      "Count: 7552\n",
      "Epoch [473/500], Loss: 8.5875\n",
      "Count: 7568\n",
      "Epoch [474/500], Loss: 7.0918\n",
      "Count: 7584\n",
      "Epoch [475/500], Loss: 7.6318\n",
      "Count: 7600\n",
      "Epoch [476/500], Loss: 8.8214\n",
      "Count: 7616\n",
      "Epoch [477/500], Loss: 8.6980\n",
      "Count: 7632\n",
      "Epoch [478/500], Loss: 9.9720\n",
      "Count: 7648\n",
      "Epoch [479/500], Loss: 6.9612\n",
      "Count: 7664\n",
      "Epoch [480/500], Loss: 10.8154\n",
      "Count: 7680\n",
      "Epoch [481/500], Loss: 8.0301\n",
      "Count: 7696\n",
      "Epoch [482/500], Loss: 7.4424\n",
      "Count: 7712\n",
      "Epoch [483/500], Loss: 4.0819\n",
      "Count: 7728\n",
      "Epoch [484/500], Loss: 5.3821\n",
      "Count: 7744\n",
      "Epoch [485/500], Loss: 8.3215\n",
      "Count: 7760\n",
      "Epoch [486/500], Loss: 6.4454\n",
      "Count: 7776\n",
      "Epoch [487/500], Loss: 6.5606\n",
      "Count: 7792\n",
      "Epoch [488/500], Loss: 8.2740\n",
      "Count: 7808\n",
      "Epoch [489/500], Loss: 9.5292\n",
      "Count: 7824\n",
      "Epoch [490/500], Loss: 9.3590\n",
      "Count: 7840\n",
      "Epoch [491/500], Loss: 7.8371\n",
      "Count: 7856\n",
      "Epoch [492/500], Loss: 4.2483\n",
      "Count: 7872\n",
      "Epoch [493/500], Loss: 6.0342\n",
      "Count: 7888\n",
      "Epoch [494/500], Loss: 5.0726\n",
      "Count: 7904\n",
      "Epoch [495/500], Loss: 5.4608\n",
      "Count: 7920\n",
      "Epoch [496/500], Loss: 5.4915\n",
      "Count: 7936\n",
      "Epoch [497/500], Loss: 7.8307\n",
      "Count: 7952\n",
      "Epoch [498/500], Loss: 7.6647\n",
      "Count: 7968\n",
      "Epoch [499/500], Loss: 3.7982\n",
      "Count: 7984\n",
      "Epoch [500/500], Loss: 4.1569\n",
      "Count: 8000\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Train the model.\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(lstm.parameters())\n",
    "\n",
    "num_epochs = 500\n",
    "count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    lstm.train() # Set model to training mode\n",
    "    for inputs, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = lstm(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    print(f'Count: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation, Total Loss: 59.8671\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "lstm.eval() # Set model to eval mode\n",
    "total_loss = 0\n",
    "for inputs, labels in val_loader:\n",
    "    # Forward pass\n",
    "    outputs = lstm(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    total_loss += loss\n",
    "print(f'Evaluation, Total Loss: {total_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 2.5151, MAE: 1.9666, R²: 0.6577\n",
      "Testing RMSE: 3.1852, MAE: 2.4923, R²: 0.4000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "y_train_pred = lstm(X_train_tensor).detach().numpy()\n",
    "y_test_pred = lstm(X_test_tensor).detach().numpy()\n",
    "\n",
    "# Get the diff values for evaluation.\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Training RMSE: {rmse_train:.4f}, MAE: {mae_train:.4f}, R²: {r2_train:.4f}')\n",
    "print(f'Testing RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}, R²: {r2_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Prediction              Player\n",
      "0     16.889122       Ja'Marr Chase\n",
      "1     15.235064    Justin Jefferson\n",
      "2     12.762156       George Kittle\n",
      "3     14.490393   Amon-Ra St. Brown\n",
      "4     12.461808        Brian Thomas\n",
      "..          ...                 ...\n",
      "163    5.223334      Elijah Higgins\n",
      "164    6.054760    Malik Washington\n",
      "165    5.493084        Derius Davis\n",
      "166    5.729812        Johnny Mundt\n",
      "167    4.245804  Darnell Washington\n",
      "\n",
      "[168 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Return results using model.\n",
    "predictions = lstm(torch.tensor(X_2024, dtype=torch.float32)).detach().numpy()\n",
    "predictions_df = pd.DataFrame(predictions, columns=['Prediction'])\n",
    "predictions_df['Player'] = player_names_2024\n",
    "print(f'{predictions_df}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new DataFrame to an Excel file\n",
    "file_path = 'results/simple_lstm_wr.xlsx'\n",
    "predictions_df.to_excel(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
