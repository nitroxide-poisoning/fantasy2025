{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asadhneni/.local/lib/python3.10/site-packages/numpy/_core/getlimits.py:551: UserWarning: Signature b'\\x00\\xd0\\xcc\\xcc\\xcc\\xcc\\xcc\\xcc\\xfb\\xbf\\x00\\x00\\x00\\x00\\x00\\x00' for <class 'numpy.longdouble'> does not match any known type: falling back to type probe function.\n",
      "This warnings indicates broken support for the dtype!\n",
      "  machar = _get_machar(dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEAR  Rk             Player   Tm FantPos  Age   G  GS  Cmp  Att  ...  \\\n",
      "4   2024   5      Ja'Marr Chase  CIN      WR   24  17  16    0    0  ...   \n",
      "11  2024  12   Justin Jefferson  MIN      WR   25  17  17    1    1  ...   \n",
      "17  2024  18  Amon-Ra St. Brown  DET      WR   25  17  17    1    1  ...   \n",
      "18  2024  19       Brian Thomas  JAX      WR   22  17  16    0    0  ...   \n",
      "22  2024  23     Terry McLaurin  WAS      WR   29  17  17    0    0  ...   \n",
      "25  2024  26       Drake London  ATL      WR   23  17  17    0    0  ...   \n",
      "34  2024  35         Mike Evans  TAM      WR   31  14  14    0    0  ...   \n",
      "36  2024  37       Malik Nabers  NYG      WR   21  15  13    0    1  ...   \n",
      "39  2024  40        CeeDee Lamb  DAL      WR   25  15  15    0    0  ...   \n",
      "41  2024  42   Courtland Sutton  DEN      WR   29  17  13    2    2  ...   \n",
      "\n",
      "    Yds.2    Y/R  TD.2  Fmb  FL  TD.3  14:00:00  2PP    PPR      PPR/G  \n",
      "4    1708  13.45    17    0   0    17       0.0  0.0  403.0  23.705882  \n",
      "11   1533  14.88    10    1   0    10       0.0  0.0  317.5  18.676471  \n",
      "17   1263  10.98    12    1   1    12       0.0  0.0  316.2  18.600000  \n",
      "18   1282  14.74    10    0   0    10       2.0  0.0  284.0  16.705882  \n",
      "22   1096  13.37    13    1   1    13       0.0  0.0  267.8  15.752941  \n",
      "25   1271  12.71     9    0   0     9       0.0  0.0  280.8  16.517647  \n",
      "34   1004  13.57    11    0   0    11       0.0  0.0  240.4  17.171429  \n",
      "36   1204  11.05     7    1   0     7       1.0  0.0  273.6  18.240000  \n",
      "39   1194  11.82     6    1   1     6       1.0  0.0  263.4  17.560000  \n",
      "41   1081  13.35     8    1   1     8       0.0  0.0  240.3  14.135294  \n",
      "\n",
      "[10 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "pro_football_focus_data = 'data/pro_football_ref.xlsx'\n",
    "model_path = 'model_path/trained_model.pth'\n",
    "\n",
    "# Load and preprocess the pro football focus data.\n",
    "df = pd.read_excel(pro_football_focus_data)\n",
    "# Filter to only include wide receivers (WR)\n",
    "df = df[df['FantPos'] == 'WR'].copy()\n",
    "df.replace([float('inf'), -float('inf')], 0, inplace=True)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Calculate points per game.\n",
    "df.loc[:, 'PPR/G'] = df['PPR'] / df['G']\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEAR  Rk   Tm FantPos  Age   G  GS  Cmp  Att  Yds  ...  Yds.2    Y/R  \\\n",
      "4   2024   5  CIN      WR   24  17  16    0    0    0  ...   1708  13.45   \n",
      "11  2024  12  MIN      WR   25  17  17    1    1   22  ...   1533  14.88   \n",
      "17  2024  18  DET      WR   25  17  17    1    1    7  ...   1263  10.98   \n",
      "18  2024  19  JAX      WR   22  17  16    0    0    0  ...   1282  14.74   \n",
      "22  2024  23  WAS      WR   29  17  17    0    0    0  ...   1096  13.37   \n",
      "25  2024  26  ATL      WR   23  17  17    0    0    0  ...   1271  12.71   \n",
      "34  2024  35  TAM      WR   31  14  14    0    0    0  ...   1004  13.57   \n",
      "36  2024  37  NYG      WR   21  15  13    0    1    0  ...   1204  11.05   \n",
      "39  2024  40  DAL      WR   25  15  15    0    0    0  ...   1194  11.82   \n",
      "41  2024  42  DEN      WR   29  17  13    2    2   30  ...   1081  13.35   \n",
      "\n",
      "    TD.2  Fmb  FL  TD.3  14:00:00  2PP    PPR      PPR/G  \n",
      "4     17    0   0    17       0.0  0.0  403.0  23.705882  \n",
      "11    10    1   0    10       0.0  0.0  317.5  18.676471  \n",
      "17    12    1   1    12       0.0  0.0  316.2  18.600000  \n",
      "18    10    0   0    10       2.0  0.0  284.0  16.705882  \n",
      "22    13    1   1    13       0.0  0.0  267.8  15.752941  \n",
      "25     9    0   0     9       0.0  0.0  280.8  16.517647  \n",
      "34    11    0   0    11       0.0  0.0  240.4  17.171429  \n",
      "36     7    1   0     7       1.0  0.0  273.6  18.240000  \n",
      "39     6    1   1     6       1.0  0.0  263.4  17.560000  \n",
      "41     8    1   1     8       0.0  0.0  240.3  14.135294  \n",
      "\n",
      "[10 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Copy the 2024 data into separate dataframe.\n",
    "df_2024 = df[df['YEAR'] == 2024].copy()\n",
    "player_names_2024 = df_2024['Player'].reset_index(drop=True)\n",
    "df_2024 = df_2024.drop(columns=['Player'])\n",
    "\n",
    "print(df_2024.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18540\n"
     ]
    }
   ],
   "source": [
    "# Shift to represent the following year's points per game\n",
    "df['NextYearPPR/G'] = df.groupby('Player')['PPR/G'].shift(-1)\n",
    "\n",
    "# Remove rows where the target is NaN (i.e., no following year data)\n",
    "df = df[df['NextYearPPR/G'].notna()]\n",
    "\n",
    "print(df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age  Tgt  Rec  Yds.2      PPR/G\n",
      "1034   29   69   45    556  15.244444\n",
      "1625   27   64   42    651  10.221429\n",
      "1025   25   94   66    770  11.642857\n",
      "2076   24   83   61    631   8.043750\n",
      "109    32  121   70    744  12.293333\n",
      "...   ...  ...  ...    ...        ...\n",
      "214    28   67   33    375   7.425000\n",
      "333    31  175  103   1144  15.611765\n",
      "881    29   44   20    282   3.262500\n",
      "1445   27   32   20    338  13.160000\n",
      "324    25  105   75   1342  15.575000\n",
      "\n",
      "[370 rows x 5 columns]\n",
      "1034    15.318750\n",
      "1625     8.612500\n",
      "1025    11.318750\n",
      "2076     8.866667\n",
      "109     21.453846\n",
      "          ...    \n",
      "214     11.746154\n",
      "333     19.735294\n",
      "881      8.147059\n",
      "1445    15.500000\n",
      "324     13.400000\n",
      "Name: NextYearPPR/G, Length: 370, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define features and target.\n",
    "feature_names = ['Age', 'Tgt', 'Rec', 'Yds.2', 'PPR/G']\n",
    "target = 'NextYearPPR/G'\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X = df[feature_names]\n",
    "y = df[target]\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "print(f'{X_train}')\n",
    "print(f'{y_train}')\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "X_2024 = df_2024[feature_names]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_2024 = scaler.transform(X_2024)\n",
    "\n",
    "# Ensure X_train, X_val, X_test, and X_2024 are correctly shaped for LSTM\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_val = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "X_2024 = X_2024.reshape(X_2024.shape[0], 1, X_2024.shape[1])\n",
    "\n",
    "# Check to see standardized data.\n",
    "#print(f'Size {y_train.size}')\n",
    "#print(f'Size {X_val.size}')\n",
    "#print(f'Size {y_val.size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnclass.simple_nn import SimpleLSTM\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# Create SimpleLTSM.\n",
    "input_size = X_train.shape[2]\n",
    "hidden_size = 32\n",
    "output_size = 1\n",
    "lstm = SimpleLSTM(input_size, hidden_size, output_size)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/750], Loss: 127.4833\n",
      "Count: 12\n",
      "Epoch [2/750], Loss: 121.2383\n",
      "Count: 24\n",
      "Epoch [3/750], Loss: 116.1457\n",
      "Count: 36\n",
      "Epoch [4/750], Loss: 157.8345\n",
      "Count: 48\n",
      "Epoch [5/750], Loss: 115.1941\n",
      "Count: 60\n",
      "Epoch [6/750], Loss: 151.1011\n",
      "Count: 72\n",
      "Epoch [7/750], Loss: 170.7756\n",
      "Count: 84\n",
      "Epoch [8/750], Loss: 101.7715\n",
      "Count: 96\n",
      "Epoch [9/750], Loss: 156.7645\n",
      "Count: 108\n",
      "Epoch [10/750], Loss: 91.4719\n",
      "Count: 120\n",
      "Epoch [11/750], Loss: 132.3840\n",
      "Count: 132\n",
      "Epoch [12/750], Loss: 104.3698\n",
      "Count: 144\n",
      "Epoch [13/750], Loss: 125.1248\n",
      "Count: 156\n",
      "Epoch [14/750], Loss: 124.1508\n",
      "Count: 168\n",
      "Epoch [15/750], Loss: 92.7383\n",
      "Count: 180\n",
      "Epoch [16/750], Loss: 113.3530\n",
      "Count: 192\n",
      "Epoch [17/750], Loss: 107.9936\n",
      "Count: 204\n",
      "Epoch [18/750], Loss: 72.3917\n",
      "Count: 216\n",
      "Epoch [19/750], Loss: 83.3252\n",
      "Count: 228\n",
      "Epoch [20/750], Loss: 77.5191\n",
      "Count: 240\n",
      "Epoch [21/750], Loss: 83.0116\n",
      "Count: 252\n",
      "Epoch [22/750], Loss: 68.1567\n",
      "Count: 264\n",
      "Epoch [23/750], Loss: 57.2378\n",
      "Count: 276\n",
      "Epoch [24/750], Loss: 48.3545\n",
      "Count: 288\n",
      "Epoch [25/750], Loss: 69.9481\n",
      "Count: 300\n",
      "Epoch [26/750], Loss: 61.0779\n",
      "Count: 312\n",
      "Epoch [27/750], Loss: 68.3315\n",
      "Count: 324\n",
      "Epoch [28/750], Loss: 55.0512\n",
      "Count: 336\n",
      "Epoch [29/750], Loss: 45.3914\n",
      "Count: 348\n",
      "Epoch [30/750], Loss: 33.8048\n",
      "Count: 360\n",
      "Epoch [31/750], Loss: 31.3628\n",
      "Count: 372\n",
      "Epoch [32/750], Loss: 48.4454\n",
      "Count: 384\n",
      "Epoch [33/750], Loss: 25.9480\n",
      "Count: 396\n",
      "Epoch [34/750], Loss: 22.8461\n",
      "Count: 408\n",
      "Epoch [35/750], Loss: 26.0674\n",
      "Count: 420\n",
      "Epoch [36/750], Loss: 21.7512\n",
      "Count: 432\n",
      "Epoch [37/750], Loss: 19.1235\n",
      "Count: 444\n",
      "Epoch [38/750], Loss: 29.6498\n",
      "Count: 456\n",
      "Epoch [39/750], Loss: 17.4474\n",
      "Count: 468\n",
      "Epoch [40/750], Loss: 29.2645\n",
      "Count: 480\n",
      "Epoch [41/750], Loss: 16.6214\n",
      "Count: 492\n",
      "Epoch [42/750], Loss: 24.1861\n",
      "Count: 504\n",
      "Epoch [43/750], Loss: 16.8536\n",
      "Count: 516\n",
      "Epoch [44/750], Loss: 15.3661\n",
      "Count: 528\n",
      "Epoch [45/750], Loss: 10.8758\n",
      "Count: 540\n",
      "Epoch [46/750], Loss: 12.9305\n",
      "Count: 552\n",
      "Epoch [47/750], Loss: 15.9085\n",
      "Count: 564\n",
      "Epoch [48/750], Loss: 11.2620\n",
      "Count: 576\n",
      "Epoch [49/750], Loss: 22.1852\n",
      "Count: 588\n",
      "Epoch [50/750], Loss: 10.6263\n",
      "Count: 600\n",
      "Epoch [51/750], Loss: 12.4861\n",
      "Count: 612\n",
      "Epoch [52/750], Loss: 23.0309\n",
      "Count: 624\n",
      "Epoch [53/750], Loss: 14.7884\n",
      "Count: 636\n",
      "Epoch [54/750], Loss: 10.7262\n",
      "Count: 648\n",
      "Epoch [55/750], Loss: 16.4099\n",
      "Count: 660\n",
      "Epoch [56/750], Loss: 14.3677\n",
      "Count: 672\n",
      "Epoch [57/750], Loss: 8.9810\n",
      "Count: 684\n",
      "Epoch [58/750], Loss: 5.0577\n",
      "Count: 696\n",
      "Epoch [59/750], Loss: 9.3689\n",
      "Count: 708\n",
      "Epoch [60/750], Loss: 12.4755\n",
      "Count: 720\n",
      "Epoch [61/750], Loss: 14.7206\n",
      "Count: 732\n",
      "Epoch [62/750], Loss: 11.7982\n",
      "Count: 744\n",
      "Epoch [63/750], Loss: 5.9702\n",
      "Count: 756\n",
      "Epoch [64/750], Loss: 17.0496\n",
      "Count: 768\n",
      "Epoch [65/750], Loss: 9.2735\n",
      "Count: 780\n",
      "Epoch [66/750], Loss: 9.2599\n",
      "Count: 792\n",
      "Epoch [67/750], Loss: 7.1526\n",
      "Count: 804\n",
      "Epoch [68/750], Loss: 13.8508\n",
      "Count: 816\n",
      "Epoch [69/750], Loss: 7.5599\n",
      "Count: 828\n",
      "Epoch [70/750], Loss: 19.0851\n",
      "Count: 840\n",
      "Epoch [71/750], Loss: 5.6557\n",
      "Count: 852\n",
      "Epoch [72/750], Loss: 11.0125\n",
      "Count: 864\n",
      "Epoch [73/750], Loss: 8.5366\n",
      "Count: 876\n",
      "Epoch [74/750], Loss: 9.3772\n",
      "Count: 888\n",
      "Epoch [75/750], Loss: 15.6708\n",
      "Count: 900\n",
      "Epoch [76/750], Loss: 8.3678\n",
      "Count: 912\n",
      "Epoch [77/750], Loss: 7.9830\n",
      "Count: 924\n",
      "Epoch [78/750], Loss: 9.6664\n",
      "Count: 936\n",
      "Epoch [79/750], Loss: 5.2703\n",
      "Count: 948\n",
      "Epoch [80/750], Loss: 17.2353\n",
      "Count: 960\n",
      "Epoch [81/750], Loss: 16.5552\n",
      "Count: 972\n",
      "Epoch [82/750], Loss: 12.3159\n",
      "Count: 984\n",
      "Epoch [83/750], Loss: 9.3752\n",
      "Count: 996\n",
      "Epoch [84/750], Loss: 16.3679\n",
      "Count: 1008\n",
      "Epoch [85/750], Loss: 16.4235\n",
      "Count: 1020\n",
      "Epoch [86/750], Loss: 14.2834\n",
      "Count: 1032\n",
      "Epoch [87/750], Loss: 12.2751\n",
      "Count: 1044\n",
      "Epoch [88/750], Loss: 10.8698\n",
      "Count: 1056\n",
      "Epoch [89/750], Loss: 12.1857\n",
      "Count: 1068\n",
      "Epoch [90/750], Loss: 6.3307\n",
      "Count: 1080\n",
      "Epoch [91/750], Loss: 7.6112\n",
      "Count: 1092\n",
      "Epoch [92/750], Loss: 8.1808\n",
      "Count: 1104\n",
      "Epoch [93/750], Loss: 12.0947\n",
      "Count: 1116\n",
      "Epoch [94/750], Loss: 17.9312\n",
      "Count: 1128\n",
      "Epoch [95/750], Loss: 13.5560\n",
      "Count: 1140\n",
      "Epoch [96/750], Loss: 6.5372\n",
      "Count: 1152\n",
      "Epoch [97/750], Loss: 9.3314\n",
      "Count: 1164\n",
      "Epoch [98/750], Loss: 12.2526\n",
      "Count: 1176\n",
      "Epoch [99/750], Loss: 8.2824\n",
      "Count: 1188\n",
      "Epoch [100/750], Loss: 21.9610\n",
      "Count: 1200\n",
      "Epoch [101/750], Loss: 10.9505\n",
      "Count: 1212\n",
      "Epoch [102/750], Loss: 12.1271\n",
      "Count: 1224\n",
      "Epoch [103/750], Loss: 9.2874\n",
      "Count: 1236\n",
      "Epoch [104/750], Loss: 12.3767\n",
      "Count: 1248\n",
      "Epoch [105/750], Loss: 6.0357\n",
      "Count: 1260\n",
      "Epoch [106/750], Loss: 6.3667\n",
      "Count: 1272\n",
      "Epoch [107/750], Loss: 11.1645\n",
      "Count: 1284\n",
      "Epoch [108/750], Loss: 7.2255\n",
      "Count: 1296\n",
      "Epoch [109/750], Loss: 7.6306\n",
      "Count: 1308\n",
      "Epoch [110/750], Loss: 12.7758\n",
      "Count: 1320\n",
      "Epoch [111/750], Loss: 7.7247\n",
      "Count: 1332\n",
      "Epoch [112/750], Loss: 7.9526\n",
      "Count: 1344\n",
      "Epoch [113/750], Loss: 11.8810\n",
      "Count: 1356\n",
      "Epoch [114/750], Loss: 11.8540\n",
      "Count: 1368\n",
      "Epoch [115/750], Loss: 8.9026\n",
      "Count: 1380\n",
      "Epoch [116/750], Loss: 9.9582\n",
      "Count: 1392\n",
      "Epoch [117/750], Loss: 16.4876\n",
      "Count: 1404\n",
      "Epoch [118/750], Loss: 13.3425\n",
      "Count: 1416\n",
      "Epoch [119/750], Loss: 11.4357\n",
      "Count: 1428\n",
      "Epoch [120/750], Loss: 9.9098\n",
      "Count: 1440\n",
      "Epoch [121/750], Loss: 12.0615\n",
      "Count: 1452\n",
      "Epoch [122/750], Loss: 6.6993\n",
      "Count: 1464\n",
      "Epoch [123/750], Loss: 4.0221\n",
      "Count: 1476\n",
      "Epoch [124/750], Loss: 9.2283\n",
      "Count: 1488\n",
      "Epoch [125/750], Loss: 8.9222\n",
      "Count: 1500\n",
      "Epoch [126/750], Loss: 5.6139\n",
      "Count: 1512\n",
      "Epoch [127/750], Loss: 10.6478\n",
      "Count: 1524\n",
      "Epoch [128/750], Loss: 7.2195\n",
      "Count: 1536\n",
      "Epoch [129/750], Loss: 11.2027\n",
      "Count: 1548\n",
      "Epoch [130/750], Loss: 6.5046\n",
      "Count: 1560\n",
      "Epoch [131/750], Loss: 11.4115\n",
      "Count: 1572\n",
      "Epoch [132/750], Loss: 9.9756\n",
      "Count: 1584\n",
      "Epoch [133/750], Loss: 4.2947\n",
      "Count: 1596\n",
      "Epoch [134/750], Loss: 7.3339\n",
      "Count: 1608\n",
      "Epoch [135/750], Loss: 6.2113\n",
      "Count: 1620\n",
      "Epoch [136/750], Loss: 11.5310\n",
      "Count: 1632\n",
      "Epoch [137/750], Loss: 14.7405\n",
      "Count: 1644\n",
      "Epoch [138/750], Loss: 7.7756\n",
      "Count: 1656\n",
      "Epoch [139/750], Loss: 14.5502\n",
      "Count: 1668\n",
      "Epoch [140/750], Loss: 14.9796\n",
      "Count: 1680\n",
      "Epoch [141/750], Loss: 6.2965\n",
      "Count: 1692\n",
      "Epoch [142/750], Loss: 7.1381\n",
      "Count: 1704\n",
      "Epoch [143/750], Loss: 9.9004\n",
      "Count: 1716\n",
      "Epoch [144/750], Loss: 5.9350\n",
      "Count: 1728\n",
      "Epoch [145/750], Loss: 10.5651\n",
      "Count: 1740\n",
      "Epoch [146/750], Loss: 13.8476\n",
      "Count: 1752\n",
      "Epoch [147/750], Loss: 17.6311\n",
      "Count: 1764\n",
      "Epoch [148/750], Loss: 11.9740\n",
      "Count: 1776\n",
      "Epoch [149/750], Loss: 5.2893\n",
      "Count: 1788\n",
      "Epoch [150/750], Loss: 4.8837\n",
      "Count: 1800\n",
      "Epoch [151/750], Loss: 15.1919\n",
      "Count: 1812\n",
      "Epoch [152/750], Loss: 8.6891\n",
      "Count: 1824\n",
      "Epoch [153/750], Loss: 10.3933\n",
      "Count: 1836\n",
      "Epoch [154/750], Loss: 6.7982\n",
      "Count: 1848\n",
      "Epoch [155/750], Loss: 11.6357\n",
      "Count: 1860\n",
      "Epoch [156/750], Loss: 5.1670\n",
      "Count: 1872\n",
      "Epoch [157/750], Loss: 7.6212\n",
      "Count: 1884\n",
      "Epoch [158/750], Loss: 9.6426\n",
      "Count: 1896\n",
      "Epoch [159/750], Loss: 9.4023\n",
      "Count: 1908\n",
      "Epoch [160/750], Loss: 8.7585\n",
      "Count: 1920\n",
      "Epoch [161/750], Loss: 11.6524\n",
      "Count: 1932\n",
      "Epoch [162/750], Loss: 9.0284\n",
      "Count: 1944\n",
      "Epoch [163/750], Loss: 5.4286\n",
      "Count: 1956\n",
      "Epoch [164/750], Loss: 11.2946\n",
      "Count: 1968\n",
      "Epoch [165/750], Loss: 9.4949\n",
      "Count: 1980\n",
      "Epoch [166/750], Loss: 12.6012\n",
      "Count: 1992\n",
      "Epoch [167/750], Loss: 9.1671\n",
      "Count: 2004\n",
      "Epoch [168/750], Loss: 8.6996\n",
      "Count: 2016\n",
      "Epoch [169/750], Loss: 9.0262\n",
      "Count: 2028\n",
      "Epoch [170/750], Loss: 5.1291\n",
      "Count: 2040\n",
      "Epoch [171/750], Loss: 3.9880\n",
      "Count: 2052\n",
      "Epoch [172/750], Loss: 8.3777\n",
      "Count: 2064\n",
      "Epoch [173/750], Loss: 10.8839\n",
      "Count: 2076\n",
      "Epoch [174/750], Loss: 9.0618\n",
      "Count: 2088\n",
      "Epoch [175/750], Loss: 9.6349\n",
      "Count: 2100\n",
      "Epoch [176/750], Loss: 10.2024\n",
      "Count: 2112\n",
      "Epoch [177/750], Loss: 5.5206\n",
      "Count: 2124\n",
      "Epoch [178/750], Loss: 12.1097\n",
      "Count: 2136\n",
      "Epoch [179/750], Loss: 3.1538\n",
      "Count: 2148\n",
      "Epoch [180/750], Loss: 3.4439\n",
      "Count: 2160\n",
      "Epoch [181/750], Loss: 11.1339\n",
      "Count: 2172\n",
      "Epoch [182/750], Loss: 9.1197\n",
      "Count: 2184\n",
      "Epoch [183/750], Loss: 12.7704\n",
      "Count: 2196\n",
      "Epoch [184/750], Loss: 10.3459\n",
      "Count: 2208\n",
      "Epoch [185/750], Loss: 14.4391\n",
      "Count: 2220\n",
      "Epoch [186/750], Loss: 6.3341\n",
      "Count: 2232\n",
      "Epoch [187/750], Loss: 16.4497\n",
      "Count: 2244\n",
      "Epoch [188/750], Loss: 9.6498\n",
      "Count: 2256\n",
      "Epoch [189/750], Loss: 17.7770\n",
      "Count: 2268\n",
      "Epoch [190/750], Loss: 9.2630\n",
      "Count: 2280\n",
      "Epoch [191/750], Loss: 5.8118\n",
      "Count: 2292\n",
      "Epoch [192/750], Loss: 15.6217\n",
      "Count: 2304\n",
      "Epoch [193/750], Loss: 6.2768\n",
      "Count: 2316\n",
      "Epoch [194/750], Loss: 8.5921\n",
      "Count: 2328\n",
      "Epoch [195/750], Loss: 8.8372\n",
      "Count: 2340\n",
      "Epoch [196/750], Loss: 15.3271\n",
      "Count: 2352\n",
      "Epoch [197/750], Loss: 9.3032\n",
      "Count: 2364\n",
      "Epoch [198/750], Loss: 9.3174\n",
      "Count: 2376\n",
      "Epoch [199/750], Loss: 4.6141\n",
      "Count: 2388\n",
      "Epoch [200/750], Loss: 8.1469\n",
      "Count: 2400\n",
      "Epoch [201/750], Loss: 9.4161\n",
      "Count: 2412\n",
      "Epoch [202/750], Loss: 12.5637\n",
      "Count: 2424\n",
      "Epoch [203/750], Loss: 2.1221\n",
      "Count: 2436\n",
      "Epoch [204/750], Loss: 9.1087\n",
      "Count: 2448\n",
      "Epoch [205/750], Loss: 23.2686\n",
      "Count: 2460\n",
      "Epoch [206/750], Loss: 14.1574\n",
      "Count: 2472\n",
      "Epoch [207/750], Loss: 12.5604\n",
      "Count: 2484\n",
      "Epoch [208/750], Loss: 14.2956\n",
      "Count: 2496\n",
      "Epoch [209/750], Loss: 10.9286\n",
      "Count: 2508\n",
      "Epoch [210/750], Loss: 6.0429\n",
      "Count: 2520\n",
      "Epoch [211/750], Loss: 7.7297\n",
      "Count: 2532\n",
      "Epoch [212/750], Loss: 10.0061\n",
      "Count: 2544\n",
      "Epoch [213/750], Loss: 7.1216\n",
      "Count: 2556\n",
      "Epoch [214/750], Loss: 5.8805\n",
      "Count: 2568\n",
      "Epoch [215/750], Loss: 11.0045\n",
      "Count: 2580\n",
      "Epoch [216/750], Loss: 4.3733\n",
      "Count: 2592\n",
      "Epoch [217/750], Loss: 5.7567\n",
      "Count: 2604\n",
      "Epoch [218/750], Loss: 5.3764\n",
      "Count: 2616\n",
      "Epoch [219/750], Loss: 6.9197\n",
      "Count: 2628\n",
      "Epoch [220/750], Loss: 4.3289\n",
      "Count: 2640\n",
      "Epoch [221/750], Loss: 12.6779\n",
      "Count: 2652\n",
      "Epoch [222/750], Loss: 9.5083\n",
      "Count: 2664\n",
      "Epoch [223/750], Loss: 7.0518\n",
      "Count: 2676\n",
      "Epoch [224/750], Loss: 5.2436\n",
      "Count: 2688\n",
      "Epoch [225/750], Loss: 9.9893\n",
      "Count: 2700\n",
      "Epoch [226/750], Loss: 16.5337\n",
      "Count: 2712\n",
      "Epoch [227/750], Loss: 8.9896\n",
      "Count: 2724\n",
      "Epoch [228/750], Loss: 7.6264\n",
      "Count: 2736\n",
      "Epoch [229/750], Loss: 14.7006\n",
      "Count: 2748\n",
      "Epoch [230/750], Loss: 7.9247\n",
      "Count: 2760\n",
      "Epoch [231/750], Loss: 5.6344\n",
      "Count: 2772\n",
      "Epoch [232/750], Loss: 6.5648\n",
      "Count: 2784\n",
      "Epoch [233/750], Loss: 5.6512\n",
      "Count: 2796\n",
      "Epoch [234/750], Loss: 10.9146\n",
      "Count: 2808\n",
      "Epoch [235/750], Loss: 9.4845\n",
      "Count: 2820\n",
      "Epoch [236/750], Loss: 12.4580\n",
      "Count: 2832\n",
      "Epoch [237/750], Loss: 9.1023\n",
      "Count: 2844\n",
      "Epoch [238/750], Loss: 8.1372\n",
      "Count: 2856\n",
      "Epoch [239/750], Loss: 13.0449\n",
      "Count: 2868\n",
      "Epoch [240/750], Loss: 12.6026\n",
      "Count: 2880\n",
      "Epoch [241/750], Loss: 8.6490\n",
      "Count: 2892\n",
      "Epoch [242/750], Loss: 8.3249\n",
      "Count: 2904\n",
      "Epoch [243/750], Loss: 11.2611\n",
      "Count: 2916\n",
      "Epoch [244/750], Loss: 6.6158\n",
      "Count: 2928\n",
      "Epoch [245/750], Loss: 8.9434\n",
      "Count: 2940\n",
      "Epoch [246/750], Loss: 8.3522\n",
      "Count: 2952\n",
      "Epoch [247/750], Loss: 5.6060\n",
      "Count: 2964\n",
      "Epoch [248/750], Loss: 12.8511\n",
      "Count: 2976\n",
      "Epoch [249/750], Loss: 8.5908\n",
      "Count: 2988\n",
      "Epoch [250/750], Loss: 16.5259\n",
      "Count: 3000\n",
      "Epoch [251/750], Loss: 8.5670\n",
      "Count: 3012\n",
      "Epoch [252/750], Loss: 6.3640\n",
      "Count: 3024\n",
      "Epoch [253/750], Loss: 15.1950\n",
      "Count: 3036\n",
      "Epoch [254/750], Loss: 11.6508\n",
      "Count: 3048\n",
      "Epoch [255/750], Loss: 7.0482\n",
      "Count: 3060\n",
      "Epoch [256/750], Loss: 11.6491\n",
      "Count: 3072\n",
      "Epoch [257/750], Loss: 11.2026\n",
      "Count: 3084\n",
      "Epoch [258/750], Loss: 17.5548\n",
      "Count: 3096\n",
      "Epoch [259/750], Loss: 4.5489\n",
      "Count: 3108\n",
      "Epoch [260/750], Loss: 8.8171\n",
      "Count: 3120\n",
      "Epoch [261/750], Loss: 10.4696\n",
      "Count: 3132\n",
      "Epoch [262/750], Loss: 14.5322\n",
      "Count: 3144\n",
      "Epoch [263/750], Loss: 10.0229\n",
      "Count: 3156\n",
      "Epoch [264/750], Loss: 8.9248\n",
      "Count: 3168\n",
      "Epoch [265/750], Loss: 6.6551\n",
      "Count: 3180\n",
      "Epoch [266/750], Loss: 23.7001\n",
      "Count: 3192\n",
      "Epoch [267/750], Loss: 5.0108\n",
      "Count: 3204\n",
      "Epoch [268/750], Loss: 10.8759\n",
      "Count: 3216\n",
      "Epoch [269/750], Loss: 13.5024\n",
      "Count: 3228\n",
      "Epoch [270/750], Loss: 5.8256\n",
      "Count: 3240\n",
      "Epoch [271/750], Loss: 6.8159\n",
      "Count: 3252\n",
      "Epoch [272/750], Loss: 5.5477\n",
      "Count: 3264\n",
      "Epoch [273/750], Loss: 8.1900\n",
      "Count: 3276\n",
      "Epoch [274/750], Loss: 11.4305\n",
      "Count: 3288\n",
      "Epoch [275/750], Loss: 3.6749\n",
      "Count: 3300\n",
      "Epoch [276/750], Loss: 9.8367\n",
      "Count: 3312\n",
      "Epoch [277/750], Loss: 4.9129\n",
      "Count: 3324\n",
      "Epoch [278/750], Loss: 6.3609\n",
      "Count: 3336\n",
      "Epoch [279/750], Loss: 12.6923\n",
      "Count: 3348\n",
      "Epoch [280/750], Loss: 8.7491\n",
      "Count: 3360\n",
      "Epoch [281/750], Loss: 9.0927\n",
      "Count: 3372\n",
      "Epoch [282/750], Loss: 14.1385\n",
      "Count: 3384\n",
      "Epoch [283/750], Loss: 19.8347\n",
      "Count: 3396\n",
      "Epoch [284/750], Loss: 12.1999\n",
      "Count: 3408\n",
      "Epoch [285/750], Loss: 8.1503\n",
      "Count: 3420\n",
      "Epoch [286/750], Loss: 11.1929\n",
      "Count: 3432\n",
      "Epoch [287/750], Loss: 15.1770\n",
      "Count: 3444\n",
      "Epoch [288/750], Loss: 7.3794\n",
      "Count: 3456\n",
      "Epoch [289/750], Loss: 12.6827\n",
      "Count: 3468\n",
      "Epoch [290/750], Loss: 4.1260\n",
      "Count: 3480\n",
      "Epoch [291/750], Loss: 13.9346\n",
      "Count: 3492\n",
      "Epoch [292/750], Loss: 7.5425\n",
      "Count: 3504\n",
      "Epoch [293/750], Loss: 12.1864\n",
      "Count: 3516\n",
      "Epoch [294/750], Loss: 10.8099\n",
      "Count: 3528\n",
      "Epoch [295/750], Loss: 7.0453\n",
      "Count: 3540\n",
      "Epoch [296/750], Loss: 14.1429\n",
      "Count: 3552\n",
      "Epoch [297/750], Loss: 14.8390\n",
      "Count: 3564\n",
      "Epoch [298/750], Loss: 9.0512\n",
      "Count: 3576\n",
      "Epoch [299/750], Loss: 4.7726\n",
      "Count: 3588\n",
      "Epoch [300/750], Loss: 9.2101\n",
      "Count: 3600\n",
      "Epoch [301/750], Loss: 5.9609\n",
      "Count: 3612\n",
      "Epoch [302/750], Loss: 11.8528\n",
      "Count: 3624\n",
      "Epoch [303/750], Loss: 6.3876\n",
      "Count: 3636\n",
      "Epoch [304/750], Loss: 9.2440\n",
      "Count: 3648\n",
      "Epoch [305/750], Loss: 5.6103\n",
      "Count: 3660\n",
      "Epoch [306/750], Loss: 15.8115\n",
      "Count: 3672\n",
      "Epoch [307/750], Loss: 10.3599\n",
      "Count: 3684\n",
      "Epoch [308/750], Loss: 6.3112\n",
      "Count: 3696\n",
      "Epoch [309/750], Loss: 6.2056\n",
      "Count: 3708\n",
      "Epoch [310/750], Loss: 11.1657\n",
      "Count: 3720\n",
      "Epoch [311/750], Loss: 7.6879\n",
      "Count: 3732\n",
      "Epoch [312/750], Loss: 9.3678\n",
      "Count: 3744\n",
      "Epoch [313/750], Loss: 7.5592\n",
      "Count: 3756\n",
      "Epoch [314/750], Loss: 7.1373\n",
      "Count: 3768\n",
      "Epoch [315/750], Loss: 16.4024\n",
      "Count: 3780\n",
      "Epoch [316/750], Loss: 5.3435\n",
      "Count: 3792\n",
      "Epoch [317/750], Loss: 12.7794\n",
      "Count: 3804\n",
      "Epoch [318/750], Loss: 8.1387\n",
      "Count: 3816\n",
      "Epoch [319/750], Loss: 12.0150\n",
      "Count: 3828\n",
      "Epoch [320/750], Loss: 8.3322\n",
      "Count: 3840\n",
      "Epoch [321/750], Loss: 8.1440\n",
      "Count: 3852\n",
      "Epoch [322/750], Loss: 6.8908\n",
      "Count: 3864\n",
      "Epoch [323/750], Loss: 12.3499\n",
      "Count: 3876\n",
      "Epoch [324/750], Loss: 12.1756\n",
      "Count: 3888\n",
      "Epoch [325/750], Loss: 13.8073\n",
      "Count: 3900\n",
      "Epoch [326/750], Loss: 8.0495\n",
      "Count: 3912\n",
      "Epoch [327/750], Loss: 5.9415\n",
      "Count: 3924\n",
      "Epoch [328/750], Loss: 7.6536\n",
      "Count: 3936\n",
      "Epoch [329/750], Loss: 14.8563\n",
      "Count: 3948\n",
      "Epoch [330/750], Loss: 3.5071\n",
      "Count: 3960\n",
      "Epoch [331/750], Loss: 12.7226\n",
      "Count: 3972\n",
      "Epoch [332/750], Loss: 9.5785\n",
      "Count: 3984\n",
      "Epoch [333/750], Loss: 4.4196\n",
      "Count: 3996\n",
      "Epoch [334/750], Loss: 12.9189\n",
      "Count: 4008\n",
      "Epoch [335/750], Loss: 8.3372\n",
      "Count: 4020\n",
      "Epoch [336/750], Loss: 13.0722\n",
      "Count: 4032\n",
      "Epoch [337/750], Loss: 9.1649\n",
      "Count: 4044\n",
      "Epoch [338/750], Loss: 12.3015\n",
      "Count: 4056\n",
      "Epoch [339/750], Loss: 10.6242\n",
      "Count: 4068\n",
      "Epoch [340/750], Loss: 9.6658\n",
      "Count: 4080\n",
      "Epoch [341/750], Loss: 8.2657\n",
      "Count: 4092\n",
      "Epoch [342/750], Loss: 10.7656\n",
      "Count: 4104\n",
      "Epoch [343/750], Loss: 8.6186\n",
      "Count: 4116\n",
      "Epoch [344/750], Loss: 2.6690\n",
      "Count: 4128\n",
      "Epoch [345/750], Loss: 9.9636\n",
      "Count: 4140\n",
      "Epoch [346/750], Loss: 7.2611\n",
      "Count: 4152\n",
      "Epoch [347/750], Loss: 9.6488\n",
      "Count: 4164\n",
      "Epoch [348/750], Loss: 9.7836\n",
      "Count: 4176\n",
      "Epoch [349/750], Loss: 13.3090\n",
      "Count: 4188\n",
      "Epoch [350/750], Loss: 8.2207\n",
      "Count: 4200\n",
      "Epoch [351/750], Loss: 7.1486\n",
      "Count: 4212\n",
      "Epoch [352/750], Loss: 9.5403\n",
      "Count: 4224\n",
      "Epoch [353/750], Loss: 10.6887\n",
      "Count: 4236\n",
      "Epoch [354/750], Loss: 6.8331\n",
      "Count: 4248\n",
      "Epoch [355/750], Loss: 11.1341\n",
      "Count: 4260\n",
      "Epoch [356/750], Loss: 13.8012\n",
      "Count: 4272\n",
      "Epoch [357/750], Loss: 8.0539\n",
      "Count: 4284\n",
      "Epoch [358/750], Loss: 9.3201\n",
      "Count: 4296\n",
      "Epoch [359/750], Loss: 9.9666\n",
      "Count: 4308\n",
      "Epoch [360/750], Loss: 9.2030\n",
      "Count: 4320\n",
      "Epoch [361/750], Loss: 4.6720\n",
      "Count: 4332\n",
      "Epoch [362/750], Loss: 13.1169\n",
      "Count: 4344\n",
      "Epoch [363/750], Loss: 7.4556\n",
      "Count: 4356\n",
      "Epoch [364/750], Loss: 15.3137\n",
      "Count: 4368\n",
      "Epoch [365/750], Loss: 6.7615\n",
      "Count: 4380\n",
      "Epoch [366/750], Loss: 7.7971\n",
      "Count: 4392\n",
      "Epoch [367/750], Loss: 9.6981\n",
      "Count: 4404\n",
      "Epoch [368/750], Loss: 4.0211\n",
      "Count: 4416\n",
      "Epoch [369/750], Loss: 6.0688\n",
      "Count: 4428\n",
      "Epoch [370/750], Loss: 15.8284\n",
      "Count: 4440\n",
      "Epoch [371/750], Loss: 5.7257\n",
      "Count: 4452\n",
      "Epoch [372/750], Loss: 7.7377\n",
      "Count: 4464\n",
      "Epoch [373/750], Loss: 5.3774\n",
      "Count: 4476\n",
      "Epoch [374/750], Loss: 5.5851\n",
      "Count: 4488\n",
      "Epoch [375/750], Loss: 10.3829\n",
      "Count: 4500\n",
      "Epoch [376/750], Loss: 9.6301\n",
      "Count: 4512\n",
      "Epoch [377/750], Loss: 4.6430\n",
      "Count: 4524\n",
      "Epoch [378/750], Loss: 7.4546\n",
      "Count: 4536\n",
      "Epoch [379/750], Loss: 5.5965\n",
      "Count: 4548\n",
      "Epoch [380/750], Loss: 8.1933\n",
      "Count: 4560\n",
      "Epoch [381/750], Loss: 14.4327\n",
      "Count: 4572\n",
      "Epoch [382/750], Loss: 4.3753\n",
      "Count: 4584\n",
      "Epoch [383/750], Loss: 10.4935\n",
      "Count: 4596\n",
      "Epoch [384/750], Loss: 13.6066\n",
      "Count: 4608\n",
      "Epoch [385/750], Loss: 6.5179\n",
      "Count: 4620\n",
      "Epoch [386/750], Loss: 9.7914\n",
      "Count: 4632\n",
      "Epoch [387/750], Loss: 8.0472\n",
      "Count: 4644\n",
      "Epoch [388/750], Loss: 12.7203\n",
      "Count: 4656\n",
      "Epoch [389/750], Loss: 7.2468\n",
      "Count: 4668\n",
      "Epoch [390/750], Loss: 11.2206\n",
      "Count: 4680\n",
      "Epoch [391/750], Loss: 8.8667\n",
      "Count: 4692\n",
      "Epoch [392/750], Loss: 14.6492\n",
      "Count: 4704\n",
      "Epoch [393/750], Loss: 11.7434\n",
      "Count: 4716\n",
      "Epoch [394/750], Loss: 8.7874\n",
      "Count: 4728\n",
      "Epoch [395/750], Loss: 8.4482\n",
      "Count: 4740\n",
      "Epoch [396/750], Loss: 10.3965\n",
      "Count: 4752\n",
      "Epoch [397/750], Loss: 6.1165\n",
      "Count: 4764\n",
      "Epoch [398/750], Loss: 8.9424\n",
      "Count: 4776\n",
      "Epoch [399/750], Loss: 6.0051\n",
      "Count: 4788\n",
      "Epoch [400/750], Loss: 10.2615\n",
      "Count: 4800\n",
      "Epoch [401/750], Loss: 4.5438\n",
      "Count: 4812\n",
      "Epoch [402/750], Loss: 14.2018\n",
      "Count: 4824\n",
      "Epoch [403/750], Loss: 11.1239\n",
      "Count: 4836\n",
      "Epoch [404/750], Loss: 17.2527\n",
      "Count: 4848\n",
      "Epoch [405/750], Loss: 10.1940\n",
      "Count: 4860\n",
      "Epoch [406/750], Loss: 9.0418\n",
      "Count: 4872\n",
      "Epoch [407/750], Loss: 4.1048\n",
      "Count: 4884\n",
      "Epoch [408/750], Loss: 14.5865\n",
      "Count: 4896\n",
      "Epoch [409/750], Loss: 8.9222\n",
      "Count: 4908\n",
      "Epoch [410/750], Loss: 7.1867\n",
      "Count: 4920\n",
      "Epoch [411/750], Loss: 6.2771\n",
      "Count: 4932\n",
      "Epoch [412/750], Loss: 6.4682\n",
      "Count: 4944\n",
      "Epoch [413/750], Loss: 8.3375\n",
      "Count: 4956\n",
      "Epoch [414/750], Loss: 10.2192\n",
      "Count: 4968\n",
      "Epoch [415/750], Loss: 9.2454\n",
      "Count: 4980\n",
      "Epoch [416/750], Loss: 9.3343\n",
      "Count: 4992\n",
      "Epoch [417/750], Loss: 11.5342\n",
      "Count: 5004\n",
      "Epoch [418/750], Loss: 6.5953\n",
      "Count: 5016\n",
      "Epoch [419/750], Loss: 7.6798\n",
      "Count: 5028\n",
      "Epoch [420/750], Loss: 7.8568\n",
      "Count: 5040\n",
      "Epoch [421/750], Loss: 6.4849\n",
      "Count: 5052\n",
      "Epoch [422/750], Loss: 7.2456\n",
      "Count: 5064\n",
      "Epoch [423/750], Loss: 6.7451\n",
      "Count: 5076\n",
      "Epoch [424/750], Loss: 3.0505\n",
      "Count: 5088\n",
      "Epoch [425/750], Loss: 12.7044\n",
      "Count: 5100\n",
      "Epoch [426/750], Loss: 12.1705\n",
      "Count: 5112\n",
      "Epoch [427/750], Loss: 9.0199\n",
      "Count: 5124\n",
      "Epoch [428/750], Loss: 13.8796\n",
      "Count: 5136\n",
      "Epoch [429/750], Loss: 12.1856\n",
      "Count: 5148\n",
      "Epoch [430/750], Loss: 9.1133\n",
      "Count: 5160\n",
      "Epoch [431/750], Loss: 10.2870\n",
      "Count: 5172\n",
      "Epoch [432/750], Loss: 14.6429\n",
      "Count: 5184\n",
      "Epoch [433/750], Loss: 9.3746\n",
      "Count: 5196\n",
      "Epoch [434/750], Loss: 8.3034\n",
      "Count: 5208\n",
      "Epoch [435/750], Loss: 9.6717\n",
      "Count: 5220\n",
      "Epoch [436/750], Loss: 8.1006\n",
      "Count: 5232\n",
      "Epoch [437/750], Loss: 16.8417\n",
      "Count: 5244\n",
      "Epoch [438/750], Loss: 9.5706\n",
      "Count: 5256\n",
      "Epoch [439/750], Loss: 7.2950\n",
      "Count: 5268\n",
      "Epoch [440/750], Loss: 10.6922\n",
      "Count: 5280\n",
      "Epoch [441/750], Loss: 7.3507\n",
      "Count: 5292\n",
      "Epoch [442/750], Loss: 11.3914\n",
      "Count: 5304\n",
      "Epoch [443/750], Loss: 7.9506\n",
      "Count: 5316\n",
      "Epoch [444/750], Loss: 8.6315\n",
      "Count: 5328\n",
      "Epoch [445/750], Loss: 14.1561\n",
      "Count: 5340\n",
      "Epoch [446/750], Loss: 7.8297\n",
      "Count: 5352\n",
      "Epoch [447/750], Loss: 7.0535\n",
      "Count: 5364\n",
      "Epoch [448/750], Loss: 8.2410\n",
      "Count: 5376\n",
      "Epoch [449/750], Loss: 7.7486\n",
      "Count: 5388\n",
      "Epoch [450/750], Loss: 8.4171\n",
      "Count: 5400\n",
      "Epoch [451/750], Loss: 9.4570\n",
      "Count: 5412\n",
      "Epoch [452/750], Loss: 5.6701\n",
      "Count: 5424\n",
      "Epoch [453/750], Loss: 4.9064\n",
      "Count: 5436\n",
      "Epoch [454/750], Loss: 9.2196\n",
      "Count: 5448\n",
      "Epoch [455/750], Loss: 7.5685\n",
      "Count: 5460\n",
      "Epoch [456/750], Loss: 5.7775\n",
      "Count: 5472\n",
      "Epoch [457/750], Loss: 8.1402\n",
      "Count: 5484\n",
      "Epoch [458/750], Loss: 10.2845\n",
      "Count: 5496\n",
      "Epoch [459/750], Loss: 8.3432\n",
      "Count: 5508\n",
      "Epoch [460/750], Loss: 7.8834\n",
      "Count: 5520\n",
      "Epoch [461/750], Loss: 7.0333\n",
      "Count: 5532\n",
      "Epoch [462/750], Loss: 10.9741\n",
      "Count: 5544\n",
      "Epoch [463/750], Loss: 12.2507\n",
      "Count: 5556\n",
      "Epoch [464/750], Loss: 7.2350\n",
      "Count: 5568\n",
      "Epoch [465/750], Loss: 4.5931\n",
      "Count: 5580\n",
      "Epoch [466/750], Loss: 16.6093\n",
      "Count: 5592\n",
      "Epoch [467/750], Loss: 8.9409\n",
      "Count: 5604\n",
      "Epoch [468/750], Loss: 14.5991\n",
      "Count: 5616\n",
      "Epoch [469/750], Loss: 6.4547\n",
      "Count: 5628\n",
      "Epoch [470/750], Loss: 15.3289\n",
      "Count: 5640\n",
      "Epoch [471/750], Loss: 5.0824\n",
      "Count: 5652\n",
      "Epoch [472/750], Loss: 10.9251\n",
      "Count: 5664\n",
      "Epoch [473/750], Loss: 6.4239\n",
      "Count: 5676\n",
      "Epoch [474/750], Loss: 9.8554\n",
      "Count: 5688\n",
      "Epoch [475/750], Loss: 6.4790\n",
      "Count: 5700\n",
      "Epoch [476/750], Loss: 10.4942\n",
      "Count: 5712\n",
      "Epoch [477/750], Loss: 9.5340\n",
      "Count: 5724\n",
      "Epoch [478/750], Loss: 2.9313\n",
      "Count: 5736\n",
      "Epoch [479/750], Loss: 10.4208\n",
      "Count: 5748\n",
      "Epoch [480/750], Loss: 5.2088\n",
      "Count: 5760\n",
      "Epoch [481/750], Loss: 7.7453\n",
      "Count: 5772\n",
      "Epoch [482/750], Loss: 13.7218\n",
      "Count: 5784\n",
      "Epoch [483/750], Loss: 15.4944\n",
      "Count: 5796\n",
      "Epoch [484/750], Loss: 14.0990\n",
      "Count: 5808\n",
      "Epoch [485/750], Loss: 20.2022\n",
      "Count: 5820\n",
      "Epoch [486/750], Loss: 7.5615\n",
      "Count: 5832\n",
      "Epoch [487/750], Loss: 8.4432\n",
      "Count: 5844\n",
      "Epoch [488/750], Loss: 6.9028\n",
      "Count: 5856\n",
      "Epoch [489/750], Loss: 8.7731\n",
      "Count: 5868\n",
      "Epoch [490/750], Loss: 7.7516\n",
      "Count: 5880\n",
      "Epoch [491/750], Loss: 9.4186\n",
      "Count: 5892\n",
      "Epoch [492/750], Loss: 6.8328\n",
      "Count: 5904\n",
      "Epoch [493/750], Loss: 7.0402\n",
      "Count: 5916\n",
      "Epoch [494/750], Loss: 9.0339\n",
      "Count: 5928\n",
      "Epoch [495/750], Loss: 10.2237\n",
      "Count: 5940\n",
      "Epoch [496/750], Loss: 8.4810\n",
      "Count: 5952\n",
      "Epoch [497/750], Loss: 12.0053\n",
      "Count: 5964\n",
      "Epoch [498/750], Loss: 7.2647\n",
      "Count: 5976\n",
      "Epoch [499/750], Loss: 4.5446\n",
      "Count: 5988\n",
      "Epoch [500/750], Loss: 4.8898\n",
      "Count: 6000\n",
      "Epoch [501/750], Loss: 4.9183\n",
      "Count: 6012\n",
      "Epoch [502/750], Loss: 4.7868\n",
      "Count: 6024\n",
      "Epoch [503/750], Loss: 10.6029\n",
      "Count: 6036\n",
      "Epoch [504/750], Loss: 6.2036\n",
      "Count: 6048\n",
      "Epoch [505/750], Loss: 12.6359\n",
      "Count: 6060\n",
      "Epoch [506/750], Loss: 7.5085\n",
      "Count: 6072\n",
      "Epoch [507/750], Loss: 13.2463\n",
      "Count: 6084\n",
      "Epoch [508/750], Loss: 6.5729\n",
      "Count: 6096\n",
      "Epoch [509/750], Loss: 10.8224\n",
      "Count: 6108\n",
      "Epoch [510/750], Loss: 6.8547\n",
      "Count: 6120\n",
      "Epoch [511/750], Loss: 8.1958\n",
      "Count: 6132\n",
      "Epoch [512/750], Loss: 15.7548\n",
      "Count: 6144\n",
      "Epoch [513/750], Loss: 13.9116\n",
      "Count: 6156\n",
      "Epoch [514/750], Loss: 9.3106\n",
      "Count: 6168\n",
      "Epoch [515/750], Loss: 3.5241\n",
      "Count: 6180\n",
      "Epoch [516/750], Loss: 3.0607\n",
      "Count: 6192\n",
      "Epoch [517/750], Loss: 2.8839\n",
      "Count: 6204\n",
      "Epoch [518/750], Loss: 7.1059\n",
      "Count: 6216\n",
      "Epoch [519/750], Loss: 7.1886\n",
      "Count: 6228\n",
      "Epoch [520/750], Loss: 4.8515\n",
      "Count: 6240\n",
      "Epoch [521/750], Loss: 6.5339\n",
      "Count: 6252\n",
      "Epoch [522/750], Loss: 5.9467\n",
      "Count: 6264\n",
      "Epoch [523/750], Loss: 5.8633\n",
      "Count: 6276\n",
      "Epoch [524/750], Loss: 9.3514\n",
      "Count: 6288\n",
      "Epoch [525/750], Loss: 5.3017\n",
      "Count: 6300\n",
      "Epoch [526/750], Loss: 8.4422\n",
      "Count: 6312\n",
      "Epoch [527/750], Loss: 9.5617\n",
      "Count: 6324\n",
      "Epoch [528/750], Loss: 8.8519\n",
      "Count: 6336\n",
      "Epoch [529/750], Loss: 6.7429\n",
      "Count: 6348\n",
      "Epoch [530/750], Loss: 14.1837\n",
      "Count: 6360\n",
      "Epoch [531/750], Loss: 8.7593\n",
      "Count: 6372\n",
      "Epoch [532/750], Loss: 6.4124\n",
      "Count: 6384\n",
      "Epoch [533/750], Loss: 9.0554\n",
      "Count: 6396\n",
      "Epoch [534/750], Loss: 10.5707\n",
      "Count: 6408\n",
      "Epoch [535/750], Loss: 10.9034\n",
      "Count: 6420\n",
      "Epoch [536/750], Loss: 7.4260\n",
      "Count: 6432\n",
      "Epoch [537/750], Loss: 6.3814\n",
      "Count: 6444\n",
      "Epoch [538/750], Loss: 6.0512\n",
      "Count: 6456\n",
      "Epoch [539/750], Loss: 8.8502\n",
      "Count: 6468\n",
      "Epoch [540/750], Loss: 10.2076\n",
      "Count: 6480\n",
      "Epoch [541/750], Loss: 7.5625\n",
      "Count: 6492\n",
      "Epoch [542/750], Loss: 17.3133\n",
      "Count: 6504\n",
      "Epoch [543/750], Loss: 7.6174\n",
      "Count: 6516\n",
      "Epoch [544/750], Loss: 9.3286\n",
      "Count: 6528\n",
      "Epoch [545/750], Loss: 5.4891\n",
      "Count: 6540\n",
      "Epoch [546/750], Loss: 5.9659\n",
      "Count: 6552\n",
      "Epoch [547/750], Loss: 6.1371\n",
      "Count: 6564\n",
      "Epoch [548/750], Loss: 13.4464\n",
      "Count: 6576\n",
      "Epoch [549/750], Loss: 8.1458\n",
      "Count: 6588\n",
      "Epoch [550/750], Loss: 10.3077\n",
      "Count: 6600\n",
      "Epoch [551/750], Loss: 13.7849\n",
      "Count: 6612\n",
      "Epoch [552/750], Loss: 15.0302\n",
      "Count: 6624\n",
      "Epoch [553/750], Loss: 4.7639\n",
      "Count: 6636\n",
      "Epoch [554/750], Loss: 10.7524\n",
      "Count: 6648\n",
      "Epoch [555/750], Loss: 13.3768\n",
      "Count: 6660\n",
      "Epoch [556/750], Loss: 6.1343\n",
      "Count: 6672\n",
      "Epoch [557/750], Loss: 5.2399\n",
      "Count: 6684\n",
      "Epoch [558/750], Loss: 14.6345\n",
      "Count: 6696\n",
      "Epoch [559/750], Loss: 13.2336\n",
      "Count: 6708\n",
      "Epoch [560/750], Loss: 10.8322\n",
      "Count: 6720\n",
      "Epoch [561/750], Loss: 8.0232\n",
      "Count: 6732\n",
      "Epoch [562/750], Loss: 8.2814\n",
      "Count: 6744\n",
      "Epoch [563/750], Loss: 14.2460\n",
      "Count: 6756\n",
      "Epoch [564/750], Loss: 7.6567\n",
      "Count: 6768\n",
      "Epoch [565/750], Loss: 5.1592\n",
      "Count: 6780\n",
      "Epoch [566/750], Loss: 7.0938\n",
      "Count: 6792\n",
      "Epoch [567/750], Loss: 12.9456\n",
      "Count: 6804\n",
      "Epoch [568/750], Loss: 8.2257\n",
      "Count: 6816\n",
      "Epoch [569/750], Loss: 6.6317\n",
      "Count: 6828\n",
      "Epoch [570/750], Loss: 8.8195\n",
      "Count: 6840\n",
      "Epoch [571/750], Loss: 9.0731\n",
      "Count: 6852\n",
      "Epoch [572/750], Loss: 10.7436\n",
      "Count: 6864\n",
      "Epoch [573/750], Loss: 5.8507\n",
      "Count: 6876\n",
      "Epoch [574/750], Loss: 10.8873\n",
      "Count: 6888\n",
      "Epoch [575/750], Loss: 10.6754\n",
      "Count: 6900\n",
      "Epoch [576/750], Loss: 6.6227\n",
      "Count: 6912\n",
      "Epoch [577/750], Loss: 7.4682\n",
      "Count: 6924\n",
      "Epoch [578/750], Loss: 6.9841\n",
      "Count: 6936\n",
      "Epoch [579/750], Loss: 11.0471\n",
      "Count: 6948\n",
      "Epoch [580/750], Loss: 13.1446\n",
      "Count: 6960\n",
      "Epoch [581/750], Loss: 5.9766\n",
      "Count: 6972\n",
      "Epoch [582/750], Loss: 8.4695\n",
      "Count: 6984\n",
      "Epoch [583/750], Loss: 11.7819\n",
      "Count: 6996\n",
      "Epoch [584/750], Loss: 14.3492\n",
      "Count: 7008\n",
      "Epoch [585/750], Loss: 6.5808\n",
      "Count: 7020\n",
      "Epoch [586/750], Loss: 5.5167\n",
      "Count: 7032\n",
      "Epoch [587/750], Loss: 7.5275\n",
      "Count: 7044\n",
      "Epoch [588/750], Loss: 12.2621\n",
      "Count: 7056\n",
      "Epoch [589/750], Loss: 11.9404\n",
      "Count: 7068\n",
      "Epoch [590/750], Loss: 16.9826\n",
      "Count: 7080\n",
      "Epoch [591/750], Loss: 10.2374\n",
      "Count: 7092\n",
      "Epoch [592/750], Loss: 5.2055\n",
      "Count: 7104\n",
      "Epoch [593/750], Loss: 14.3281\n",
      "Count: 7116\n",
      "Epoch [594/750], Loss: 9.6280\n",
      "Count: 7128\n",
      "Epoch [595/750], Loss: 8.2200\n",
      "Count: 7140\n",
      "Epoch [596/750], Loss: 16.1278\n",
      "Count: 7152\n",
      "Epoch [597/750], Loss: 8.4879\n",
      "Count: 7164\n",
      "Epoch [598/750], Loss: 6.3699\n",
      "Count: 7176\n",
      "Epoch [599/750], Loss: 9.2352\n",
      "Count: 7188\n",
      "Epoch [600/750], Loss: 8.5555\n",
      "Count: 7200\n",
      "Epoch [601/750], Loss: 12.2613\n",
      "Count: 7212\n",
      "Epoch [602/750], Loss: 12.7856\n",
      "Count: 7224\n",
      "Epoch [603/750], Loss: 9.1747\n",
      "Count: 7236\n",
      "Epoch [604/750], Loss: 11.5134\n",
      "Count: 7248\n",
      "Epoch [605/750], Loss: 4.7415\n",
      "Count: 7260\n",
      "Epoch [606/750], Loss: 12.2672\n",
      "Count: 7272\n",
      "Epoch [607/750], Loss: 6.5828\n",
      "Count: 7284\n",
      "Epoch [608/750], Loss: 10.5608\n",
      "Count: 7296\n",
      "Epoch [609/750], Loss: 9.5216\n",
      "Count: 7308\n",
      "Epoch [610/750], Loss: 5.6700\n",
      "Count: 7320\n",
      "Epoch [611/750], Loss: 10.4643\n",
      "Count: 7332\n",
      "Epoch [612/750], Loss: 5.9045\n",
      "Count: 7344\n",
      "Epoch [613/750], Loss: 6.8413\n",
      "Count: 7356\n",
      "Epoch [614/750], Loss: 12.6973\n",
      "Count: 7368\n",
      "Epoch [615/750], Loss: 15.2534\n",
      "Count: 7380\n",
      "Epoch [616/750], Loss: 7.4997\n",
      "Count: 7392\n",
      "Epoch [617/750], Loss: 9.6073\n",
      "Count: 7404\n",
      "Epoch [618/750], Loss: 12.1020\n",
      "Count: 7416\n",
      "Epoch [619/750], Loss: 6.4680\n",
      "Count: 7428\n",
      "Epoch [620/750], Loss: 8.2673\n",
      "Count: 7440\n",
      "Epoch [621/750], Loss: 6.4388\n",
      "Count: 7452\n",
      "Epoch [622/750], Loss: 13.4200\n",
      "Count: 7464\n",
      "Epoch [623/750], Loss: 4.7722\n",
      "Count: 7476\n",
      "Epoch [624/750], Loss: 3.1391\n",
      "Count: 7488\n",
      "Epoch [625/750], Loss: 6.4873\n",
      "Count: 7500\n",
      "Epoch [626/750], Loss: 12.7942\n",
      "Count: 7512\n",
      "Epoch [627/750], Loss: 9.6616\n",
      "Count: 7524\n",
      "Epoch [628/750], Loss: 8.1051\n",
      "Count: 7536\n",
      "Epoch [629/750], Loss: 10.3608\n",
      "Count: 7548\n",
      "Epoch [630/750], Loss: 6.2412\n",
      "Count: 7560\n",
      "Epoch [631/750], Loss: 10.4564\n",
      "Count: 7572\n",
      "Epoch [632/750], Loss: 7.5020\n",
      "Count: 7584\n",
      "Epoch [633/750], Loss: 7.8548\n",
      "Count: 7596\n",
      "Epoch [634/750], Loss: 5.4187\n",
      "Count: 7608\n",
      "Epoch [635/750], Loss: 11.7099\n",
      "Count: 7620\n",
      "Epoch [636/750], Loss: 5.5361\n",
      "Count: 7632\n",
      "Epoch [637/750], Loss: 3.8844\n",
      "Count: 7644\n",
      "Epoch [638/750], Loss: 6.8631\n",
      "Count: 7656\n",
      "Epoch [639/750], Loss: 7.5965\n",
      "Count: 7668\n",
      "Epoch [640/750], Loss: 8.3025\n",
      "Count: 7680\n",
      "Epoch [641/750], Loss: 7.0876\n",
      "Count: 7692\n",
      "Epoch [642/750], Loss: 7.8183\n",
      "Count: 7704\n",
      "Epoch [643/750], Loss: 6.4912\n",
      "Count: 7716\n",
      "Epoch [644/750], Loss: 9.6565\n",
      "Count: 7728\n",
      "Epoch [645/750], Loss: 19.7478\n",
      "Count: 7740\n",
      "Epoch [646/750], Loss: 13.8831\n",
      "Count: 7752\n",
      "Epoch [647/750], Loss: 7.7603\n",
      "Count: 7764\n",
      "Epoch [648/750], Loss: 8.9361\n",
      "Count: 7776\n",
      "Epoch [649/750], Loss: 4.7487\n",
      "Count: 7788\n",
      "Epoch [650/750], Loss: 8.8558\n",
      "Count: 7800\n",
      "Epoch [651/750], Loss: 6.0598\n",
      "Count: 7812\n",
      "Epoch [652/750], Loss: 4.5680\n",
      "Count: 7824\n",
      "Epoch [653/750], Loss: 4.4975\n",
      "Count: 7836\n",
      "Epoch [654/750], Loss: 9.0066\n",
      "Count: 7848\n",
      "Epoch [655/750], Loss: 8.6519\n",
      "Count: 7860\n",
      "Epoch [656/750], Loss: 12.5200\n",
      "Count: 7872\n",
      "Epoch [657/750], Loss: 12.5365\n",
      "Count: 7884\n",
      "Epoch [658/750], Loss: 7.7870\n",
      "Count: 7896\n",
      "Epoch [659/750], Loss: 5.7815\n",
      "Count: 7908\n",
      "Epoch [660/750], Loss: 9.1244\n",
      "Count: 7920\n",
      "Epoch [661/750], Loss: 11.1434\n",
      "Count: 7932\n",
      "Epoch [662/750], Loss: 7.5266\n",
      "Count: 7944\n",
      "Epoch [663/750], Loss: 12.2250\n",
      "Count: 7956\n",
      "Epoch [664/750], Loss: 5.0684\n",
      "Count: 7968\n",
      "Epoch [665/750], Loss: 14.4166\n",
      "Count: 7980\n",
      "Epoch [666/750], Loss: 4.3735\n",
      "Count: 7992\n",
      "Epoch [667/750], Loss: 9.7806\n",
      "Count: 8004\n",
      "Epoch [668/750], Loss: 12.2037\n",
      "Count: 8016\n",
      "Epoch [669/750], Loss: 11.3438\n",
      "Count: 8028\n",
      "Epoch [670/750], Loss: 10.1340\n",
      "Count: 8040\n",
      "Epoch [671/750], Loss: 3.7611\n",
      "Count: 8052\n",
      "Epoch [672/750], Loss: 6.9485\n",
      "Count: 8064\n",
      "Epoch [673/750], Loss: 15.0130\n",
      "Count: 8076\n",
      "Epoch [674/750], Loss: 7.4801\n",
      "Count: 8088\n",
      "Epoch [675/750], Loss: 9.0707\n",
      "Count: 8100\n",
      "Epoch [676/750], Loss: 8.8528\n",
      "Count: 8112\n",
      "Epoch [677/750], Loss: 8.8316\n",
      "Count: 8124\n",
      "Epoch [678/750], Loss: 10.1866\n",
      "Count: 8136\n",
      "Epoch [679/750], Loss: 6.6816\n",
      "Count: 8148\n",
      "Epoch [680/750], Loss: 6.9823\n",
      "Count: 8160\n",
      "Epoch [681/750], Loss: 13.7649\n",
      "Count: 8172\n",
      "Epoch [682/750], Loss: 6.5599\n",
      "Count: 8184\n",
      "Epoch [683/750], Loss: 5.6247\n",
      "Count: 8196\n",
      "Epoch [684/750], Loss: 9.4388\n",
      "Count: 8208\n",
      "Epoch [685/750], Loss: 3.9299\n",
      "Count: 8220\n",
      "Epoch [686/750], Loss: 6.8695\n",
      "Count: 8232\n",
      "Epoch [687/750], Loss: 7.7595\n",
      "Count: 8244\n",
      "Epoch [688/750], Loss: 5.6918\n",
      "Count: 8256\n",
      "Epoch [689/750], Loss: 17.6715\n",
      "Count: 8268\n",
      "Epoch [690/750], Loss: 8.5353\n",
      "Count: 8280\n",
      "Epoch [691/750], Loss: 6.1191\n",
      "Count: 8292\n",
      "Epoch [692/750], Loss: 10.8944\n",
      "Count: 8304\n",
      "Epoch [693/750], Loss: 8.7205\n",
      "Count: 8316\n",
      "Epoch [694/750], Loss: 4.4686\n",
      "Count: 8328\n",
      "Epoch [695/750], Loss: 6.8287\n",
      "Count: 8340\n",
      "Epoch [696/750], Loss: 13.2476\n",
      "Count: 8352\n",
      "Epoch [697/750], Loss: 4.8999\n",
      "Count: 8364\n",
      "Epoch [698/750], Loss: 8.8714\n",
      "Count: 8376\n",
      "Epoch [699/750], Loss: 7.0203\n",
      "Count: 8388\n",
      "Epoch [700/750], Loss: 9.7436\n",
      "Count: 8400\n",
      "Epoch [701/750], Loss: 9.0295\n",
      "Count: 8412\n",
      "Epoch [702/750], Loss: 8.1176\n",
      "Count: 8424\n",
      "Epoch [703/750], Loss: 9.0849\n",
      "Count: 8436\n",
      "Epoch [704/750], Loss: 6.2712\n",
      "Count: 8448\n",
      "Epoch [705/750], Loss: 6.3375\n",
      "Count: 8460\n",
      "Epoch [706/750], Loss: 5.4092\n",
      "Count: 8472\n",
      "Epoch [707/750], Loss: 6.2482\n",
      "Count: 8484\n",
      "Epoch [708/750], Loss: 2.9890\n",
      "Count: 8496\n",
      "Epoch [709/750], Loss: 6.0759\n",
      "Count: 8508\n",
      "Epoch [710/750], Loss: 5.5597\n",
      "Count: 8520\n",
      "Epoch [711/750], Loss: 5.9563\n",
      "Count: 8532\n",
      "Epoch [712/750], Loss: 5.4014\n",
      "Count: 8544\n",
      "Epoch [713/750], Loss: 7.0784\n",
      "Count: 8556\n",
      "Epoch [714/750], Loss: 11.1512\n",
      "Count: 8568\n",
      "Epoch [715/750], Loss: 14.1868\n",
      "Count: 8580\n",
      "Epoch [716/750], Loss: 4.7327\n",
      "Count: 8592\n",
      "Epoch [717/750], Loss: 6.7307\n",
      "Count: 8604\n",
      "Epoch [718/750], Loss: 6.0839\n",
      "Count: 8616\n",
      "Epoch [719/750], Loss: 8.9803\n",
      "Count: 8628\n",
      "Epoch [720/750], Loss: 7.5186\n",
      "Count: 8640\n",
      "Epoch [721/750], Loss: 4.4344\n",
      "Count: 8652\n",
      "Epoch [722/750], Loss: 10.4798\n",
      "Count: 8664\n",
      "Epoch [723/750], Loss: 17.6444\n",
      "Count: 8676\n",
      "Epoch [724/750], Loss: 10.7602\n",
      "Count: 8688\n",
      "Epoch [725/750], Loss: 4.9445\n",
      "Count: 8700\n",
      "Epoch [726/750], Loss: 10.2451\n",
      "Count: 8712\n",
      "Epoch [727/750], Loss: 8.1073\n",
      "Count: 8724\n",
      "Epoch [728/750], Loss: 5.0039\n",
      "Count: 8736\n",
      "Epoch [729/750], Loss: 10.0296\n",
      "Count: 8748\n",
      "Epoch [730/750], Loss: 10.3673\n",
      "Count: 8760\n",
      "Epoch [731/750], Loss: 10.7245\n",
      "Count: 8772\n",
      "Epoch [732/750], Loss: 3.8693\n",
      "Count: 8784\n",
      "Epoch [733/750], Loss: 8.5947\n",
      "Count: 8796\n",
      "Epoch [734/750], Loss: 12.2867\n",
      "Count: 8808\n",
      "Epoch [735/750], Loss: 6.8944\n",
      "Count: 8820\n",
      "Epoch [736/750], Loss: 5.6248\n",
      "Count: 8832\n",
      "Epoch [737/750], Loss: 8.3902\n",
      "Count: 8844\n",
      "Epoch [738/750], Loss: 6.2745\n",
      "Count: 8856\n",
      "Epoch [739/750], Loss: 12.1409\n",
      "Count: 8868\n",
      "Epoch [740/750], Loss: 7.8603\n",
      "Count: 8880\n",
      "Epoch [741/750], Loss: 5.8447\n",
      "Count: 8892\n",
      "Epoch [742/750], Loss: 4.6518\n",
      "Count: 8904\n",
      "Epoch [743/750], Loss: 6.8572\n",
      "Count: 8916\n",
      "Epoch [744/750], Loss: 15.1722\n",
      "Count: 8928\n",
      "Epoch [745/750], Loss: 7.7326\n",
      "Count: 8940\n",
      "Epoch [746/750], Loss: 10.0705\n",
      "Count: 8952\n",
      "Epoch [747/750], Loss: 10.8385\n",
      "Count: 8964\n",
      "Epoch [748/750], Loss: 12.8179\n",
      "Count: 8976\n",
      "Epoch [749/750], Loss: 7.7191\n",
      "Count: 8988\n",
      "Epoch [750/750], Loss: 6.6337\n",
      "Count: 9000\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Train the model.\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(lstm.parameters())\n",
    "\n",
    "num_epochs = 750\n",
    "count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    lstm.train() # Set model to training mode\n",
    "    for inputs, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = lstm(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    print(f'Count: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation, Total Loss: 31.1009\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "lstm.eval() # Set model to eval mode\n",
    "total_loss = 0\n",
    "for inputs, labels in val_loader:\n",
    "    # Forward pass\n",
    "    outputs = lstm(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    total_loss += loss\n",
    "print(f'Evaluation, Total Loss: {total_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 2.9204, MAE: 2.2155, R²: 0.5565\n",
      "Testing RMSE: 3.2233, MAE: 2.4749, R²: 0.5042\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "y_train_pred = lstm(X_train_tensor).detach().numpy()\n",
    "y_test_pred = lstm(X_test_tensor).detach().numpy()\n",
    "\n",
    "# Get the diff values for evaluation.\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Training RMSE: {rmse_train:.4f}, MAE: {mae_train:.4f}, R²: {r2_train:.4f}')\n",
    "print(f'Testing RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}, R²: {r2_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Prediction              Player\n",
      "0     16.548477       Ja'Marr Chase\n",
      "1     16.039267    Justin Jefferson\n",
      "2     14.806870   Amon-Ra St. Brown\n",
      "3     12.582546        Brian Thomas\n",
      "4     14.714628      Terry McLaurin\n",
      "..          ...                 ...\n",
      "113    8.018454           DJ Turner\n",
      "114    4.933768  Jordan Whittington\n",
      "115    7.055645  Cedrick Wilson Jr.\n",
      "116    5.482774    Malik Washington\n",
      "117    5.606704        Derius Davis\n",
      "\n",
      "[118 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Return results using model.\n",
    "predictions = lstm(torch.tensor(X_2024, dtype=torch.float32)).detach().numpy()\n",
    "predictions_df = pd.DataFrame(predictions, columns=['Prediction'])\n",
    "predictions_df['Player'] = player_names_2024\n",
    "print(f'{predictions_df}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new DataFrame to an Excel file\n",
    "file_path = 'results/simple_lstm.xlsx'\n",
    "predictions_df.to_excel(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
